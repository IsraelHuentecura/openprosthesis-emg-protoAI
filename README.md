# ClasificaciÃ³n de Gestos sEMG con Modelos Ligeros de Deep Learning

Este repositorio contiene los modelos `.h5`, el cÃ³digo y las herramientas desarrolladas para clasificar 12 gestos de la mano a partir de seÃ±ales de **electromiografÃ­a de superficie (sEMG)**, como parte del proyecto de tÃ­tulo de **Israel Huentecura** en el contexto de **[ProtoIA](https://github.com/ProtoAI-cl/ProtoAI)**.

El objetivo es proveer **modelos de alto rendimiento y bajo costo computacional**, especialmente diseÃ±ados para ser desplegados en dispositivos de bajo consumo como Raspberry Pi o microcontroladores mÃ¡s potentes.

---

## ğŸ§  Â¿QuÃ© Modelo DeberÃ­as Usar?

La elecciÃ³n del modelo depende del hardware donde se quiera ejecutar:

### ğŸ”¹ Para Computadores Monoplaca (Ej. Raspberry Pi, Jetson Nano)

| Modelo              | PrecisiÃ³n (Test)  | TamaÃ±o `.h5` |
| ------------------- | ----------------- | ------------ |
| **HyT-Net**         | **99.83% Â± 0.02** | \~10.4 MB    |
| DualStream-Original | 99.82% Â± 0.03     | \~36.6 MB    |
| EMGHandNet-Original | 99.80% Â± 0.02     | \~19.8 MB    |

**âœ” Recomendado: HyT-Net**, por su precisiÃ³n mÃ¡xima con menor tamaÃ±o que los modelos de referencia.

---

### ğŸ”¹ Para Prototipos en Desarrollo y Pruebas Locales

| Modelo            | PrecisiÃ³n (Test)  | TamaÃ±o `.h5` |
| ----------------- | ----------------- | ------------ |
| **EMGHandNet-2D** | **99.78% Â± 0.03** | \~4.2 MB     |
| DualStream-Lite   | 99.41% Â± 0.03     | \~3.4 MB     |
| CRNN-Attn         | 98.55% Â± 0.15     | \~3.6 MB     |

**âœ” Recomendado: EMGHandNet-2D**, el mejor balance entre precisiÃ³n, arquitectura simple (*end-to-end*) y tamaÃ±o reducido.

> âš ï¸ Ten en cuenta que actualmente estos modelos no estÃ¡n preparados para microcontroladores sin conversiÃ³n a TFLite o cuantizaciÃ³n. Este repositorio se centra en desarrollo y evaluaciÃ³n en entorno de entrenamiento.

---

## ğŸ—‚ï¸ Contenido del Repositorio

```bash
ğŸ“ models_h5/               # Modelos pre-entrenados en formato .h5
ğŸ“ models_tflite/           # Modelos convertidos a TFLite
ğŸ“ saved_datasets/          # Dataset de entrenamiento y prueba (debes descargarlo)
ğŸ“ test_data_sample/        # Dataset de prueba (no debe ser descargado)
ğŸ“„ script_test_h5.py        # EvalÃºa todos los modelos .h5 con un dataset de muestra
ğŸ“„ ejemplo_finetuning.py    # Fine-tuning del modelo HyT-Net
ğŸ“„ notebook_entrenamiento.ipynb # Notebook para construir y entrenar modelos desde cero
ğŸ“„ requirements.txt         # Dependencias necesarias
```

---

## ğŸš€ CÃ³mo Empezar

### 1. Instala dependencias

Usa un entorno virtual y ejecuta:

```bash
pip install -r requirements.txt
```

> Este proyecto estÃ¡ probado en **Python 3.9** y usa **TensorFlow 2.10.0**.

---

### 2. Descarga el Dataset Procesado

Debes tener una carpeta `saved_datasets/` con los siguientes datasets:

* `train_ds_h/` y `test_ds_h/`: para entrenamiento y prueba
* `sample_raw_ds/` y `sample_hybrid_ds/`: para pruebas rÃ¡pidas

> ğŸ”— Agrega tu link de descarga aquÃ­ para que otros puedan acceder a estos datos.

---

## âš™ï¸ Opciones de Uso

### âœ… A. Evaluar Modelos `.h5` RÃ¡pidamente

```bash
python script_test_h5.py
```

Este script evalÃºa los modelos preentrenados con un dataset pequeÃ±o y muestra un resumen de precisiÃ³n por modelo.

---

### âœ… B. Entrenar Desde Cero

Abre el notebook:

```bash
jupyter lab
```

Edita y ejecuta `notebook_entrenamiento.ipynb` para construir modelos desde cero.

---

### âœ… C. Fine-tuning Personalizado

Para adaptar un modelo preentrenado (ej. `HyT-Net`) a nuevos datos:

```bash
python ejemplo_finetuning.py
```

El script:

1. Carga el modelo preentrenado
2. Congela las capas base
3. Reentrena las Ãºltimas capas con una tasa de aprendizaje baja (`1e-5`) por 10 Ã©pocas
4. EvalÃºa el nuevo rendimiento

> âœï¸ Puedes modificar `ejemplo_finetuning.py` para aplicar fine-tuning a otros modelos.

---

## ğŸ“Š Resultados TÃ©cnicos (Resumen)

| Modelo              | Test Accuracy (Â± Ïƒ) | TamaÃ±o `.h5` | Entradas Requeridas       |
| ------------------- | ------------------- | ------------ | ------------------------- |
| **HyT-Net**         | 0.9983 Â± 0.0002     | \~10.4 MB    | SeÃ±ales crudas + features |
| DualStream-Original | 0.9982 Â± 0.0003     | \~36.6 MB    | SeÃ±ales crudas + features |
| EMGHandNet-Original | 0.9980 Â± 0.0002     | \~19.8 MB    | SeÃ±ales crudas            |
| **EMGHandNet-2D**   | 0.9978 Â± 0.0003     | \~4.2 MB     | SeÃ±ales crudas            |
| DualStream-Lite     | 0.9941 Â± 0.0003     | \~3.4 MB     | SeÃ±ales crudas + features |
| CRNN-Attn           | 0.9855 Â± 0.0015     | \~3.6 MB     | SeÃ±ales crudas + features |

Fuente: EvaluaciÃ³n sobre NinaPro DB1 - Ejercicio A, siguiendo protocolo de validaciÃ³n cruzada 10-fold.

---

## ğŸ“„ Referencias

* Paper asociado: [`EMG-Based Gesture Recognition Using Hybrid and Transformer-Based Deep Learning Models`](./EMG_Israel_Huentecura_IEEE.pdf)
* Dataset base: [NinaPro DB1](http://ninapro.hevs.ch/DB1)
* Proyecto madre: [ProtoIA](https://github.com/ProtoAI-cl/ProtoAI)

---

## ğŸ§  AutorÃ­a

Desarrollado por **Israel Huentecura RodrÃ­guez**
---
