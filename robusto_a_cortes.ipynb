{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9371f58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 165258/165258 [13:14<00:00, 208.03it/s]\n",
      "Extracting features: 100%|██████████| 71353/71353 [04:59<00:00, 238.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#  EMG Gesture Classification – Stimulus-1  (Ninapro DB-1)\n",
    "#  SOTA pipeline (determinista) / Israel Huentecura ✨  • Mayo 2025\n",
    "# =============================================================================\n",
    "#  • Filtra únicamente los 12 primeros gestos (restimulus ∈ 1…12, Stimulus 1)\n",
    "#  • Segmenta en sub-ventanas (win_len=20) y agrupa T_SUBWIN=5 → una “secuencia”\n",
    "#  • Extrae 10 rasgos manuales × canal  (100 features/ventana)\n",
    "#  • Modelo híbrido:  CNN-2D por ventana  +  Dense(64) sobre rasgos  →\n",
    "#                     Concatenate → 2 bloques Transformer Encoder →\n",
    "#                     GlobalAvgPool → Dense → Softmax(12)\n",
    "#  • Buenas prácticas: determinismo, escalar sólo TRAIN, tf.data, EarlyStop,\n",
    "#                      ReduceLROnPlateau, checkpoints en ./models\n",
    "# =============================================================================\n",
    "import os, random, datetime as dt, shutil, json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import (Input, Dense, Conv2D, GlobalAveragePooling2D,\n",
    "                                     BatchNormalization, Activation, Dropout,\n",
    "                                     TimeDistributed, Concatenate,\n",
    "                                     LayerNormalization, MultiHeadAttention,\n",
    "                                     GlobalAveragePooling1D)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import signal\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "# ---------- 0. CONFIGURACIÓN GLOBAL ------------------------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"        # kernels cuDNN deterministas\n",
    "\n",
    "DATA_ROOT  = \"data/ninapro/db1_processed\"\n",
    "RUNS_DIR   = \"runs\"\n",
    "MODELS_DIR = \"models\"\n",
    "for d in (RUNS_DIR, MODELS_DIR):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "T_SUBWIN   = 5          # nº sub-ventanas por “secuencia” (gesto)\n",
    "WIN_LEN    = 20         # muestras por sub-ventana (200 ms si fs=100 Hz)\n",
    "HANDCRAFT_PER_CH = 10   # número de rasgos tiempo-dominio por canal\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS     = 100\n",
    "TEST_PCT   = 0.2\n",
    "SUBJECTS   = list(range(1, 28))   # 27 sujetos de DB-1\n",
    "FS         = 100                  # Hz\n",
    "\n",
    "# ---------- 1. PREPROCESADO ---------------------------------------------------\n",
    "def butter_lowpass_1hz(fs):\n",
    "    return signal.butter(1, 1/(0.5*fs), btype=\"low\")\n",
    "B_LP, A_LP = butter_lowpass_1hz(FS)\n",
    "\n",
    "def mu_law(x, u=256):\n",
    "    return np.sign(x) * np.log1p(u*np.abs(x)) / np.log1p(u)\n",
    "\n",
    "def compute_handcrafted_features(segment, thr=0.01):\n",
    "    \"\"\"10 rasgos básicos por canal (std, RMS, min, max, ZC, MAV-diff, max 1/4,\n",
    "       MAV, WL, Count(Larger than thr).\"\"\"\n",
    "    f = []\n",
    "    for ch in range(segment.shape[1]):\n",
    "        s = segment[:, ch]\n",
    "        f.extend([\n",
    "            np.std(s), np.sqrt(np.mean(s**2)), np.min(s), np.max(s),\n",
    "            np.sum(np.diff(np.sign(s)) != 0), np.mean(np.abs(np.diff(s))),\n",
    "            np.max(s[:max(1, len(s)//4)]), np.mean(np.abs(s)),\n",
    "            np.sum(np.abs(np.diff(s))), np.sum(np.abs(np.diff(s)) > thr)\n",
    "        ])\n",
    "    return np.asarray(f, dtype=np.float32)\n",
    "\n",
    "def extract_features(X_seq):\n",
    "    n_seq, T, win, n_ch, _ = X_seq.shape   # X_seq siempre 5-D\n",
    "    feats = np.zeros((n_seq, T, n_ch*HANDCRAFT_PER_CH), np.float32)\n",
    "    for i in tqdm(range(n_seq), desc=\"Extracting features\"):\n",
    "        for t in range(T):\n",
    "            seg = X_seq[i, t, :, :, 0]     # (win, ch)\n",
    "            feats[i, t] = compute_handcrafted_features(seg)\n",
    "    return feats\n",
    "\n",
    "def load_subject(path):\n",
    "    emgs        = np.loadtxt(os.path.join(path, \"emg.txt\"))\n",
    "    labels      = np.loadtxt(os.path.join(path, \"restimulus.txt\"))\n",
    "    repetitions = np.loadtxt(os.path.join(path, \"rerepetition.txt\"))\n",
    "\n",
    "    # pre-filtrado por gesto (solo Stimulus 1 → restimulus 1-12)\n",
    "    mask = (labels >= 1) & (labels <= 12)\n",
    "    emgs, labels, repetitions = emgs[mask], labels[mask], repetitions[mask]\n",
    "\n",
    "    # filtrado y companding\n",
    "    emgs = signal.filtfilt(B_LP, A_LP, emgs, axis=0)\n",
    "    emgs = mu_law(emgs)\n",
    "\n",
    "    data_tr, lbl_tr, data_val, lbl_val = [], [], [], []\n",
    "    for i in range(0, len(labels) - WIN_LEN, 1):      # step=1\n",
    "        lab = int(labels[i])\n",
    "        # requiere que las WIN_LEN muestras pertenezcan al mismo gesto\n",
    "        if lab != int(labels[i + WIN_LEN - 1]): \n",
    "            continue\n",
    "        win = emgs[i : i+WIN_LEN]                     # (20,10)\n",
    "        rep = int(repetitions[i])\n",
    "        (data_val if rep in (2,5,7) else data_tr).append(win)\n",
    "        (lbl_val  if rep in (2,5,7) else lbl_tr ).append(lab)\n",
    "    return (np.asarray(data_tr), np.asarray(lbl_tr)), \\\n",
    "           (np.asarray(data_val), np.asarray(lbl_val))\n",
    "\n",
    "def load_all_subjects(sids):\n",
    "    tr_d, tr_l, va_d, va_l = [], [], [], []\n",
    "    for sid in sids:\n",
    "        path = os.path.join(DATA_ROOT, f\"s{sid}\")\n",
    "        (dt, lb), (dv, lv) = load_subject(path)\n",
    "        tr_d.append(dt); tr_l.append(lb)\n",
    "        va_d.append(dv); va_l.append(lv)\n",
    "    tr_d, tr_l = np.concatenate(tr_d), np.concatenate(tr_l)\n",
    "    va_d, va_l = np.concatenate(va_d), np.concatenate(va_l)\n",
    "    return (tr_d, tr_l), (va_d, va_l)\n",
    "\n",
    "# ---------- 2. CARGA + SEGMENTACIÓN A SECUENCIAS -----------------------------\n",
    "(train_data, train_lbl), (val_data, val_lbl) = load_all_subjects(SUBJECTS)\n",
    "\n",
    "# Añadir eje canal-extra para Conv2D más adelante → (N, win, ch, 1)\n",
    "train_data = train_data[..., np.newaxis]\n",
    "val_data   = val_data  [..., np.newaxis]\n",
    "\n",
    "def to_sequences(segs, lbls, T=T_SUBWIN):\n",
    "    n_seq = segs.shape[0] // T\n",
    "    seqs = segs[:n_seq*T].reshape(n_seq, T, *segs.shape[1:]).astype(np.float32)\n",
    "    # etiqueta de la secuencia = modo de las T etiquetas\n",
    "    seq_labels = np.array([np.bincount(lbls[i*T : (i+1)*T]).argmax()\n",
    "                           for i in range(n_seq)])\n",
    "    return seqs, seq_labels\n",
    "\n",
    "train_X, train_y_lbl = to_sequences(train_data, train_lbl)\n",
    "val_X,   val_y_lbl   = to_sequences(val_data,   val_lbl)\n",
    "\n",
    "# ---------- 3. CARACTERÍSTICAS MANUALES --------------------------------------\n",
    "train_feats = extract_features(train_X)\n",
    "val_feats   = extract_features(val_X)\n",
    "\n",
    "# ---------- 4. SPLIT TRAIN/TEST  + ESCALADO ROBUSTO --------------------------\n",
    "X_tr_raw, X_te_raw, F_tr, F_te, y_tr_lbl, y_te_lbl = train_test_split(\n",
    "    train_X, train_feats, train_y_lbl,\n",
    "    test_size=TEST_PCT, stratify=train_y_lbl, random_state=SEED\n",
    ")\n",
    "feat_dim = F_tr.shape[-1]                          # 100 (=10×10)\n",
    "scaler   = StandardScaler().fit(F_tr.reshape(-1, feat_dim))\n",
    "def scale(F): return scaler.transform(F.reshape(-1, feat_dim)).reshape(F.shape)\n",
    "F_tr, F_te, val_feats = scale(F_tr), scale(F_te), scale(val_feats)\n",
    "\n",
    "# ---------- 5. ETIQUETAS ONE-HOT --------------------------------------------\n",
    "le = LabelEncoder().fit(np.concatenate([y_tr_lbl, y_te_lbl, val_y_lbl]))\n",
    "NUM_CLASSES = len(le.classes_)                    # = 12\n",
    "y_tr = to_categorical(le.transform(y_tr_lbl), NUM_CLASSES)\n",
    "y_val= to_categorical(le.transform(val_y_lbl), NUM_CLASSES)\n",
    "y_te = to_categorical(le.transform(y_te_lbl), NUM_CLASSES)\n",
    "\n",
    "# ---------- 6. tf.data Pipelines ---------------------------------------------\n",
    "def make_ds(inputs, labels, shuffle=False):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((inputs, labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(len(labels), seed=SEED, reshuffle_each_iteration=True)\n",
    "    return ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "def dictify(ds):\n",
    "    \"\"\"Convierte ((raw, feats), y) → ({raw_input:raw, feat_input:feats}, y).\"\"\"\n",
    "    return ds.map(lambda x, y: ({\"raw_input\": x[0], \"feat_input\": x[1]}, y),\n",
    "                  num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = dictify(make_ds((X_tr_raw, F_tr), y_tr, shuffle=True))\n",
    "val_ds   = dictify(make_ds((val_X, val_feats), y_val))\n",
    "test_ds  = dictify(make_ds((X_te_raw, F_te), y_te))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30275eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 100%|██████████| 165258/165258 [13:17<00:00, 207.24it/s]\n",
      "Features: 100%|██████████| 71353/71353 [05:49<00:00, 204.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#  EMG Gesture Recognition – Stimulus-1  (Ninapro DB-1)\n",
    "#  Multi-model benchmark  •  Israel Huentecura ✨  •  May 2025\n",
    "# =============================================================================\n",
    "#  - Pre-procesado y split idénticos a tu pipeline\n",
    "#  - Compara 4 arquitecturas (ver tabla arriba)\n",
    "# =============================================================================\n",
    "import os, random, datetime as dt, json, shutil, math\n",
    "import numpy as np, pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau,\n",
    "                                        ModelCheckpoint, TensorBoard)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from scipy import signal\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "# ---------- 0. GLOBAL CFG -----------------------------------------------------\n",
    "SEED          = 42\n",
    "np.random.seed(SEED); random.seed(SEED); tf.random.set_seed(SEED)\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "DATA_ROOT     = \"data/ninapro/db1_processed\"\n",
    "SPLIT_DIR     = \"splits\"; RUNS_DIR = \"runs\"; MODELS_DIR = \"models\"\n",
    "for d in (SPLIT_DIR, RUNS_DIR, MODELS_DIR): os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# ---------- 1. PRE-PROCESADO --------------------------------------------------\n",
    "WIN_LEN   = 20          # 200 ms\n",
    "T_SUBWIN  = 5\n",
    "HANDCRAFT_PER_CH = 10\n",
    "FS        = 100\n",
    "TEST_PCT  = 0.20\n",
    "\n",
    "def butter_lowpass_1hz(fs):  return signal.butter(1, 1/(0.5*fs), \"low\")\n",
    "B_LP, A_LP = butter_lowpass_1hz(FS)\n",
    "def mu_law(x, u=256):  return np.sign(x)*np.log1p(u*np.abs(x))/np.log1p(u)\n",
    "\n",
    "def compute_handcrafted(seg, thr=0.01):\n",
    "    f = []\n",
    "    for s in seg.T:\n",
    "        f += [\n",
    "            np.std(s), math.sqrt(np.mean(s**2)), s.min(), s.max(),\n",
    "            np.sum(np.diff(np.sign(s))!=0), np.mean(np.abs(np.diff(s))),\n",
    "            s[:max(1,len(s)//4)].max(), np.mean(np.abs(s)),\n",
    "            np.sum(np.abs(np.diff(s))), np.sum(np.abs(np.diff(s))>thr)\n",
    "        ]\n",
    "    return np.asarray(f, np.float32)\n",
    "\n",
    "def extract_features(X5d):\n",
    "    n, T, _, _, _ = X5d.shape\n",
    "    feats = np.zeros((n, T, 10*HANDCRAFT_PER_CH), np.float32)\n",
    "    for i in tqdm(range(n), desc=\"Features\"):\n",
    "        for t in range(T):\n",
    "            feats[i, t] = compute_handcrafted(X5d[i,t,:,:,0])\n",
    "    return feats\n",
    "\n",
    "def load_subject(path):\n",
    "    emg   = np.loadtxt(os.path.join(path,\"emg.txt\"))\n",
    "    label = np.loadtxt(os.path.join(path,\"restimulus.txt\"))\n",
    "    rep   = np.loadtxt(os.path.join(path,\"rerepetition.txt\"))\n",
    "    mask  = (label>=1)&(label<=12)           # Stimulus-1\n",
    "    emg, label, rep = emg[mask], label[mask], rep[mask]\n",
    "\n",
    "    emg = mu_law(signal.filtfilt(B_LP,A_LP,emg,axis=0))\n",
    "    d_tr,l_tr,d_v,l_v=[],[],[],[]\n",
    "    for i in range(0,len(label)-WIN_LEN):\n",
    "        if label[i]!=label[i+WIN_LEN-1]: continue\n",
    "        w  = emg[i:i+WIN_LEN]\n",
    "        r  = int(rep[i])\n",
    "        (d_v if r in (2,5,7) else d_tr).append(w)\n",
    "        (l_v if r in (2,5,7) else l_tr).append(int(label[i]))\n",
    "    return (np.asarray(d_tr),np.asarray(l_tr)),(np.asarray(d_v),np.asarray(l_v))\n",
    "\n",
    "SUBJECTS = list(range(1,28))\n",
    "tr_d,tr_l,va_d,va_l=[],[],[],[]\n",
    "for s in SUBJECTS:\n",
    "    (dt,lb),(dv,lv) = load_subject(os.path.join(DATA_ROOT,f\"s{s}\"))\n",
    "    tr_d.append(dt); tr_l.append(lb); va_d.append(dv); va_l.append(lv)\n",
    "train_data, train_lbl = np.concatenate(tr_d), np.concatenate(tr_l)\n",
    "val_data,   val_lbl   = np.concatenate(va_d), np.concatenate(va_l)\n",
    "\n",
    "train_data = train_data[...,None]; val_data = val_data[...,None]\n",
    "\n",
    "def to_sequences(segs,lbls,T):\n",
    "    n = segs.shape[0]//T\n",
    "    seq = segs[:n*T].reshape(n,T,*segs.shape[1:])\n",
    "    lbl = np.array([np.bincount(lbls[i*T:(i+1)*T]).argmax() for i in range(n)])\n",
    "    return seq.astype(np.float32), lbl\n",
    "train_X, train_y_lbl = to_sequences(train_data,train_lbl,T_SUBWIN)\n",
    "val_X,   val_y_lbl   = to_sequences(val_data,  val_lbl,  T_SUBWIN)\n",
    "\n",
    "train_feats, val_feats = extract_features(train_X), extract_features(val_X)\n",
    "\n",
    "# ---------- 2. SPLIT TRAIN/TEST CON ÍNDICES FIJOS ----------------------------\n",
    "SPLIT_FILE = os.path.join(SPLIT_DIR,\"stim1_seed42.npz\")\n",
    "if os.path.exists(SPLIT_FILE):\n",
    "    idx = np.load(SPLIT_FILE); tr_idx, te_idx = idx[\"tr\"], idx[\"te\"]\n",
    "else:\n",
    "    idx_all = np.arange(train_X.shape[0])\n",
    "    tr_idx, te_idx = train_test_split(idx_all,test_size=TEST_PCT,\n",
    "                                      stratify=train_y_lbl,random_state=SEED)\n",
    "    np.savez(SPLIT_FILE,tr=tr_idx,te=te_idx)\n",
    "X_tr_raw,X_te_raw = train_X[tr_idx],train_X[te_idx]\n",
    "F_tr,F_te         = train_feats[tr_idx],train_feats[te_idx]\n",
    "y_tr_lbl,y_te_lbl = train_y_lbl[tr_idx],train_y_lbl[te_idx]\n",
    "\n",
    "# ---------- 3. ESCALADO FEATURES Y ONE-HOT -----------------------------------\n",
    "feat_dim = F_tr.shape[-1]\n",
    "scaler = StandardScaler().fit(F_tr.reshape(-1,feat_dim))\n",
    "def scale(F): return scaler.transform(F.reshape(-1,feat_dim)).reshape(F.shape)\n",
    "F_tr,F_te,val_feats = scale(F_tr),scale(F_te),scale(val_feats)\n",
    "\n",
    "le = LabelEncoder().fit(np.concatenate([y_tr_lbl,y_te_lbl,val_y_lbl]))\n",
    "NUM_CLASSES = len(le.classes_)          # 12\n",
    "y_tr = to_categorical(le.transform(y_tr_lbl),NUM_CLASSES)\n",
    "y_val= to_categorical(le.transform(val_y_lbl),NUM_CLASSES)\n",
    "y_te = to_categorical(le.transform(y_te_lbl),NUM_CLASSES)\n",
    "\n",
    "# ---------- 4. tf.data --------------------------------------------------------\n",
    "BATCH_SIZE = 128\n",
    "def make_ds(x,y,shuffle=False):\n",
    "    ds=tf.data.Dataset.from_tensor_slices((x,y))\n",
    "    if shuffle: ds=ds.shuffle(len(y),seed=SEED,reshuffle_each_iteration=True)\n",
    "    return ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "def dictify(ds):\n",
    "    return ds.map(lambda x,y: ({\"raw\":x[0],\"feat\":x[1]},y),\n",
    "                  num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds_h = dictify(make_ds((X_tr_raw,F_tr),y_tr,True))\n",
    "val_ds_h   = dictify(make_ds((val_X,val_feats),y_val))\n",
    "test_ds_h  = dictify(make_ds((X_te_raw,F_te),y_te))\n",
    "\n",
    "train_ds_raw = make_ds(X_tr_raw,y_tr,True)\n",
    "val_ds_raw   = make_ds(val_X,y_val)\n",
    "test_ds_raw  = make_ds(X_te_raw,y_te)\n",
    "\n",
    "RAW_SHAPE = X_tr_raw.shape[2:]   # (20,10,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c3228a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  train_ds_h ya existe → omitido\n",
      "⚠️  val_ds_h ya existe → omitido\n",
      "⚠️  test_ds_h ya existe → omitido\n",
      "⚠️  train_ds_raw ya existe → omitido\n",
      "⚠️  val_ds_raw ya existe → omitido\n",
      "⚠️  test_ds_raw ya existe → omitido\n",
      "✅ Array train_X_raw.npy guardado\n",
      "✅ Array train_X_feats.npy guardado\n",
      "✅ Array train_y_lbl.npy guardado\n",
      "✅ Array val_X_raw.npy guardado\n",
      "✅ Array val_X_feats.npy guardado\n",
      "✅ Array val_y_lbl.npy guardado\n",
      "✅ Array test_X_raw.npy guardado\n",
      "✅ Array test_X_feats.npy guardado\n",
      "✅ Array test_y_lbl.npy guardado\n",
      "✅ Array y_tr.npy guardado\n",
      "✅ Array y_val.npy guardado\n",
      "✅ Array y_te.npy guardado\n",
      "✅ meta.json guardado\n"
     ]
    }
   ],
   "source": [
    "# ╔══════════════════════════════════════════════════════════════════════════╗\n",
    "# ║  CELDA 1 · GUARDADO COMPLETO                                             ║\n",
    "# ║  (ejecútala una vez, justo después de generar los datasets y arrays)     ║\n",
    "# ╚══════════════════════════════════════════════════════════════════════════╝\n",
    "import os, json, numpy as np, tensorflow as tf\n",
    "\n",
    "SAVE_ROOT = \"saved_datasets\"\n",
    "os.makedirs(SAVE_ROOT, exist_ok=True)\n",
    "\n",
    "# ---------- utilidades ----------\n",
    "def save_tf_dataset(ds, name):\n",
    "    path = os.path.join(SAVE_ROOT, name)\n",
    "    if os.path.exists(path):\n",
    "        print(f\"⚠️  {name} ya existe → omitido\")\n",
    "    else:\n",
    "        ds.save(path)\n",
    "        print(f\"✅ Dataset {name} guardado en {path}\")\n",
    "\n",
    "def save_np(name, array):\n",
    "    path = os.path.join(SAVE_ROOT, f\"{name}.npy\")\n",
    "    np.save(path, array)\n",
    "    print(f\"✅ Array {name}.npy guardado\")\n",
    "\n",
    "# ---------- datasets ----------\n",
    "save_tf_dataset(train_ds_h,   \"train_ds_h\")\n",
    "save_tf_dataset(val_ds_h,     \"val_ds_h\")\n",
    "save_tf_dataset(test_ds_h,    \"test_ds_h\")\n",
    "save_tf_dataset(train_ds_raw, \"train_ds_raw\")\n",
    "save_tf_dataset(val_ds_raw,   \"val_ds_raw\")\n",
    "save_tf_dataset(test_ds_raw,  \"test_ds_raw\")\n",
    "\n",
    "# ---------- arrays numpy ----------\n",
    "to_save = {\n",
    "    \"train_X_raw\":   X_tr_raw,\n",
    "    \"train_X_feats\": F_tr,\n",
    "    \"train_y_lbl\":   y_tr_lbl,\n",
    "    \"val_X_raw\":     val_X,\n",
    "    \"val_X_feats\":   val_feats,\n",
    "    \"val_y_lbl\":     val_y_lbl,\n",
    "    \"test_X_raw\":    X_te_raw,\n",
    "    \"test_X_feats\":  F_te,\n",
    "    \"test_y_lbl\":    y_te_lbl,\n",
    "    \"y_tr\":          y_tr,\n",
    "    \"y_val\":         y_val,\n",
    "    \"y_te\":          y_te,\n",
    "}\n",
    "for k, v in to_save.items():\n",
    "    save_np(k, v)\n",
    "\n",
    "# ---------- metadatos ----------\n",
    "meta = {\n",
    "    \"RAW_SHAPE\":  list(RAW_SHAPE),\n",
    "    \"feat_dim\":   feat_dim,\n",
    "    \"num_classes\": NUM_CLASSES,\n",
    "}\n",
    "with open(os.path.join(SAVE_ROOT, \"meta.json\"), \"w\") as fp:\n",
    "    json.dump(meta, fp)\n",
    "print(\"✅ meta.json guardado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a324e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Todos los datasets, arrays y metadatos cargados correctamente\n"
     ]
    }
   ],
   "source": [
    "# ╔══════════════════════════════════════════════════════════════════════════╗\n",
    "# ║  CELDA 2 · CARGA COMPLETA                                                ║\n",
    "# ║  (ejecútala al inicio de cualquier notebook/script que ya parte          ║\n",
    "# ║   del dataset procesado)                                                 ║\n",
    "# ╚══════════════════════════════════════════════════════════════════════════╝\n",
    "import os, json, numpy as np, tensorflow as tf\n",
    "\n",
    "SAVE_ROOT = \"saved_datasets\"\n",
    "\n",
    "def load_np(name, mmap_mode=None):\n",
    "    path = os.path.join(SAVE_ROOT, f\"{name}.npy\")\n",
    "    return np.load(path, allow_pickle=True, mmap_mode=mmap_mode)\n",
    "\n",
    "# ---------- metadatos ----------\n",
    "with open(os.path.join(SAVE_ROOT, \"meta.json\")) as fp:\n",
    "    meta = json.load(fp)\n",
    "RAW_SHAPE   = tuple(meta[\"RAW_SHAPE\"])\n",
    "feat_dim    = meta[\"feat_dim\"]\n",
    "NUM_CLASSES = meta[\"num_classes\"]\n",
    "\n",
    "# ---------- datasets ----------\n",
    "train_ds_h   = tf.data.Dataset.load(os.path.join(SAVE_ROOT, \"train_ds_h\"))\n",
    "val_ds_h     = tf.data.Dataset.load(os.path.join(SAVE_ROOT, \"val_ds_h\"))\n",
    "test_ds_h    = tf.data.Dataset.load(os.path.join(SAVE_ROOT, \"test_ds_h\"))\n",
    "train_ds_raw = tf.data.Dataset.load(os.path.join(SAVE_ROOT, \"train_ds_raw\"))\n",
    "val_ds_raw   = tf.data.Dataset.load(os.path.join(SAVE_ROOT, \"val_ds_raw\"))\n",
    "test_ds_raw  = tf.data.Dataset.load(os.path.join(SAVE_ROOT, \"test_ds_raw\"))\n",
    "\n",
    "# ---------- arrays numpy ----------\n",
    "X_tr_raw   = load_np(\"train_X_raw\")\n",
    "F_tr       = load_np(\"train_X_feats\")\n",
    "y_tr_lbl   = load_np(\"train_y_lbl\")\n",
    "\n",
    "val_X      = load_np(\"val_X_raw\")\n",
    "val_feats  = load_np(\"val_X_feats\")\n",
    "y_val_lbl  = load_np(\"val_y_lbl\")\n",
    "\n",
    "X_te_raw   = load_np(\"test_X_raw\")\n",
    "F_te       = load_np(\"test_X_feats\")\n",
    "y_te_lbl   = load_np(\"test_y_lbl\")\n",
    "\n",
    "y_tr = load_np(\"y_tr\")\n",
    "y_val = load_np(\"y_val\")\n",
    "y_te = load_np(\"y_te\")\n",
    "\n",
    "print(\"✅ Todos los datasets, arrays y metadatos cargados correctamente\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dee203b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_dim = 100    NUM_CLASSES = 12\n",
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\n",
      "🧮  Parámetros por modelo\n",
      "DualStr-Lite: 274,700  (~1.05 MB)\n",
      "DualStr-Original: 3,039,148  (~11.59 MB)\n",
      "EMGHandNet-2D: 341,516  (~1.30 MB)\n",
      "EMGHandNet-Original: 1,637,132  (~6.25 MB)\n",
      "HyT-Net   : 846,348  (~3.23 MB)\n",
      "CRNN-Attn : 291,021  (~1.11 MB)\n",
      "✅  Train+Val: (203559, 5, 20, 10, 1)  Test: (33052, 5, 20, 10, 1)\n",
      "⏭️  DualStream-Lite_fold1 ya entrenado, se salta\n",
      "⏭️  DualStream-Original_fold1 ya entrenado, se salta\n",
      "⏭️  CRNN-Attn_fold1 ya entrenado, se salta\n",
      "⏭️  EMGHandNet-2D_fold1 ya entrenado, se salta\n",
      "⏭️  EMGHandNet-Original_fold1 ya entrenado, se salta\n",
      "⏭️  HyT-Net_fold1 ya entrenado, se salta\n",
      "⏭️  DualStream-Lite_fold2 ya entrenado, se salta\n",
      "⏭️  DualStream-Original_fold2 ya entrenado, se salta\n",
      "⏭️  CRNN-Attn_fold2 ya entrenado, se salta\n",
      "⏭️  EMGHandNet-2D_fold2 ya entrenado, se salta\n",
      "⏭️  EMGHandNet-Original_fold2 ya entrenado, se salta\n",
      "⏭️  HyT-Net_fold2 ya entrenado, se salta\n",
      "⏭️  DualStream-Lite_fold3 ya entrenado, se salta\n",
      "⏭️  DualStream-Original_fold3 ya entrenado, se salta\n",
      "⏭️  CRNN-Attn_fold3 ya entrenado, se salta\n",
      "⏭️  EMGHandNet-2D_fold3 ya entrenado, se salta\n",
      "⏭️  EMGHandNet-Original_fold3 ya entrenado, se salta\n",
      "⏭️  HyT-Net_fold3 ya entrenado, se salta\n",
      "⏭️  DualStream-Lite_fold4 ya entrenado, se salta\n",
      "⏭️  DualStream-Original_fold4 ya entrenado, se salta\n",
      "⏭️  CRNN-Attn_fold4 ya entrenado, se salta\n",
      "⏭️  EMGHandNet-2D_fold4 ya entrenado, se salta\n",
      "⏭️  EMGHandNet-Original_fold4 ya entrenado, se salta\n",
      "⏭️  HyT-Net_fold4 ya entrenado, se salta\n",
      "⏭️  DualStream-Lite_fold5 ya entrenado, se salta\n",
      "⏭️  DualStream-Original_fold5 ya entrenado, se salta\n",
      "⏭️  CRNN-Attn_fold5 ya entrenado, se salta\n",
      "⏭️  EMGHandNet-2D_fold5 ya entrenado, se salta\n",
      "⏭️  EMGHandNet-Original_fold5 ya entrenado, se salta\n",
      "⏭️  HyT-Net_fold5 ya entrenado, se salta\n",
      "⏭️  DualStream-Lite_fold6 ya entrenado, se salta\n",
      "⏭️  DualStream-Original_fold6 ya entrenado, se salta\n",
      "⏭️  CRNN-Attn_fold6 ya entrenado, se salta\n",
      "⏭️  EMGHandNet-2D_fold6 ya entrenado, se salta\n",
      "⏭️  EMGHandNet-Original_fold6 ya entrenado, se salta\n",
      "⏭️  HyT-Net_fold6 ya entrenado, se salta\n",
      "⏭️  DualStream-Lite_fold7 ya entrenado, se salta\n",
      "⏭️  DualStream-Original_fold7 ya entrenado, se salta\n",
      "⏭️  CRNN-Attn_fold7 ya entrenado, se salta\n",
      "⏭️  EMGHandNet-2D_fold7 ya entrenado, se salta\n",
      "⏭️  EMGHandNet-Original_fold7 ya entrenado, se salta\n",
      "⏭️  HyT-Net_fold7 ya entrenado, se salta\n",
      "⏭️  DualStream-Lite_fold8 ya entrenado, se salta\n",
      "⏭️  DualStream-Original_fold8 ya entrenado, se salta\n",
      "⏭️  CRNN-Attn_fold8 ya entrenado, se salta\n",
      "⏭️  EMGHandNet-2D_fold8 ya entrenado, se salta\n",
      "⏭️  EMGHandNet-Original_fold8 ya entrenado, se salta\n",
      "⏭️  HyT-Net_fold8 ya entrenado, se salta\n",
      "⏭️  DualStream-Lite_fold9 ya entrenado, se salta\n",
      "⏭️  DualStream-Original_fold9 ya entrenado, se salta\n",
      "⏭️  CRNN-Attn_fold9 ya entrenado, se salta\n",
      "⏭️  EMGHandNet-2D_fold9 ya entrenado, se salta\n",
      "⏭️  EMGHandNet-Original_fold9 ya entrenado, se salta\n",
      "⏭️  HyT-Net_fold9 ya entrenado, se salta\n",
      "⏭️  DualStream-Lite_fold10 ya entrenado, se salta\n",
      "⏭️  DualStream-Original_fold10 ya entrenado, se salta\n",
      "⏭️  CRNN-Attn_fold10 ya entrenado, se salta\n",
      "⏭️  EMGHandNet-2D_fold10 ya entrenado, se salta\n",
      "⏭️  EMGHandNet-Original_fold10 ya entrenado, se salta\n",
      "⏭️  HyT-Net_fold10 ya entrenado, se salta\n",
      "\n",
      "📊  Resumen 10‑fold (Val_Acc)\n",
      "Empty DataFrame\n",
      "Columns: [mean, std]\n",
      "Index: []\n",
      "⚠️  DualStream-Lite: no se encontró ckpt; se omite\n",
      "⚠️  DualStream-Original: no se encontró ckpt; se omite\n",
      "⚠️  CRNN-Attn: no se encontró ckpt; se omite\n",
      "⚠️  EMGHandNet-2D: no se encontró ckpt; se omite\n",
      "⚠️  EMGHandNet-Original: no se encontró ckpt; se omite\n",
      "⚠️  HyT-Net: no se encontró ckpt; se omite\n",
      "\n",
      "🎯  Rendimiento en HOLD‑OUT Test\n",
      "Empty DataFrame\n",
      "Columns: [Model, Test_Acc, Test_Loss]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import os, random, datetime as dt, json, shutil, math\n",
    "import numpy as np, pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau,\n",
    "                                        ModelCheckpoint, TensorBoard)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from scipy import signal\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "# =============================================================================\n",
    "# Ninapro‑DB1 · 10‑Fold CV + Hold‑out Test\n",
    "# Israel Huentecura ✨ · Junio 2025\n",
    "# =============================================================================\n",
    "# ‑‑ IMPORTS ------------------------------------------------------------------\n",
    "import os, random, json, datetime as dt, shutil\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd, tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import datetime\n",
    "\n",
    "# ------------------------------------------------------------------------- #\n",
    "# 0️⃣  CFG GLOBAL\n",
    "# ------------------------------------------------------------------------- #\n",
    "SEED          = 42\n",
    "np.random.seed(SEED); random.seed(SEED); tf.random.set_seed(SEED)\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "\n",
    "DATA_ROOT     = \"data/ninapro/db1_processed\"\n",
    "RUNS_DIR      = Path(\"runs\")\n",
    "MODELS_DIR    = Path(\"models\")\n",
    "BACKUP_DIR    = RUNS_DIR / \"_backup\"\n",
    "for d in (RUNS_DIR, MODELS_DIR, BACKUP_DIR): d.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "N_FOLDS     = 10\n",
    "EPOCHS      = 100\n",
    "BATCH_SIZE  = 128\n",
    "TEST_PCT    = 0.20                    # proporción fija para el hold‑out\n",
    "\n",
    "\n",
    "\n",
    "SEED          = 42\n",
    "np.random.seed(SEED); random.seed(SEED); tf.random.set_seed(SEED)\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "DATA_ROOT     = \"data/ninapro/db1_processed\"\n",
    "SPLIT_DIR     = \"splits\"; RUNS_DIR = \"runs\"; MODELS_DIR = \"models\"\n",
    "for d in (SPLIT_DIR, RUNS_DIR, MODELS_DIR): os.makedirs(d, exist_ok=True)\n",
    "\n",
    "WIN_LEN   = 20          # 200 ms\n",
    "T_SUBWIN  = 5\n",
    "HANDCRAFT_PER_CH = 10\n",
    "FS        = 100\n",
    "TEST_PCT  = 0.20\n",
    "\n",
    "print(\"feat_dim =\", feat_dim, \"   NUM_CLASSES =\", NUM_CLASSES)\n",
    "# ---------- 5. MODELOS --------------------------------------------------------\n",
    "#\n",
    "# 5-A  Modelo propuesto   ------------------------------------------------------\n",
    "def build_sota(raw_shape,feat_dim,T,n_cls,heads=4,dim=128,dp=0.3):\n",
    "    seg_in = layers.Input(raw_shape)\n",
    "    x=layers.Conv2D(64,(5,1),padding=\"same\",activation=\"relu\")(seg_in)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.Conv2D(64,(3,1),padding=\"same\",activation=\"relu\")(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    seg_vec = layers.GlobalAveragePooling2D()(x)\n",
    "    seg_cnn=models.Model(seg_in,seg_vec)\n",
    "\n",
    "    in_raw  = layers.Input((T,*raw_shape),name=\"raw\")\n",
    "    in_feat = layers.Input((T,feat_dim),  name=\"feat\")\n",
    "    r = layers.TimeDistributed(seg_cnn)(in_raw)\n",
    "    f = layers.TimeDistributed(layers.Dense(64,activation=\"relu\"))(in_feat)\n",
    "    concat = layers.Concatenate()([r,f])\n",
    "    proj = layers.Dense(dim)(concat)\n",
    "\n",
    "    def trans_block(z):\n",
    "        a = layers.LayerNormalization(epsilon=1e-6)(z)\n",
    "        a = layers.MultiHeadAttention(num_heads=heads,key_dim=dim,dropout=dp)(a,a)\n",
    "        z = z+a\n",
    "        b = layers.LayerNormalization(epsilon=1e-6)(z)\n",
    "        b = layers.Dense(dim*4,activation=\"relu\")(b)\n",
    "        b = layers.Dense(dim)(b); b = layers.Dropout(dp)(b)\n",
    "        return z+b\n",
    "    z = trans_block(proj); z = trans_block(z)\n",
    "    z = layers.GlobalAveragePooling1D()(z)\n",
    "    z = layers.Dropout(dp)(z)\n",
    "    z = layers.Dense(128,activation=\"relu\")(z)\n",
    "    z = layers.Dropout(dp)(z)\n",
    "    out = layers.Dense(n_cls,activation=\"softmax\")(z)\n",
    "    m = models.Model([in_raw,in_feat],out,name=\"SOTA_Trans\")\n",
    "    m.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "    return m\n",
    "#\n",
    "# 5-B  Modelos del usuario  ----------------------------------------------------\n",
    "class Attention(layers.Layer):\n",
    "    def build(self,inp_shape):\n",
    "        u=inp_shape[-1]\n",
    "        self.W=self.add_weight(\"W\",(u,u),initializer=\"glorot_uniform\")\n",
    "        self.b=self.add_weight(\"b\",(u,),initializer=\"zeros\")\n",
    "        self.u=self.add_weight(\"u\",(u,1),initializer=\"glorot_uniform\")\n",
    "    def call(self,x):\n",
    "        v=tf.tanh(tf.tensordot(x,self.W,1)+self.b)\n",
    "        vu=tf.tensordot(v,self.u,1)\n",
    "        al=tf.nn.softmax(tf.squeeze(vu,-1),1)\n",
    "        return tf.reduce_sum(x*tf.expand_dims(al,-1),1)\n",
    "\n",
    "def mobile_cnn(raw_shape,alpha=.75,dp=.2):\n",
    "    inp=layers.Input(raw_shape)\n",
    "    x=layers.SeparableConv2D(int(32*alpha),3,padding=\"same\",activation=\"relu\")(inp)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.SeparableConv2D(int(64*alpha),3,padding=\"same\",activation=\"relu\")(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.GlobalAveragePooling2D()(x)\n",
    "    x=layers.Dropout(dp)(x)\n",
    "    return models.Model(inp,x)\n",
    "\n",
    "def build_hybrid_v2(raw_shape,feat_dim,T,n_cls,gru=128,dp=.3):\n",
    "    cnn=mobile_cnn(raw_shape)\n",
    "    in_r  = layers.Input((T,*raw_shape),name=\"raw\")\n",
    "    in_f  = layers.Input((T,feat_dim),  name=\"feat\")\n",
    "    r=layers.TimeDistributed(cnn)(in_r)\n",
    "    f=layers.TimeDistributed(layers.Dense(96,activation=\"relu\"))(in_f)\n",
    "    mrg=layers.Concatenate()([r,f])\n",
    "    x=layers.Bidirectional(layers.GRU(gru,return_sequences=True,dropout=dp,recurrent_dropout=dp*0.5))(mrg)\n",
    "    x=Attention()(x); x=layers.Dropout(dp)(x)\n",
    "    out=layers.Dense(n_cls,activation=\"softmax\",\n",
    "                     kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    m=models.Model([in_r,in_f],out,name=\"Hybrid_A2\")\n",
    "    m.compile(optimizer=tf.keras.optimizers.Adam(2e-3),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=.1),\n",
    "              metrics=[\"accuracy\"])\n",
    "    return m\n",
    "\n",
    "def build_emghandnet(raw_shape,T,n_cls,filters=(64,128),lstm=128,dp=.3):\n",
    "    inp=layers.Input((T,*raw_shape))\n",
    "    x=inp\n",
    "    for f in filters:\n",
    "        x=layers.TimeDistributed(layers.Conv2D(f,(3,3),padding=\"same\",activation=\"relu\"))(x)\n",
    "        x=layers.TimeDistributed(layers.BatchNormalization())(x)\n",
    "        x=layers.TimeDistributed(layers.MaxPool2D((2,2)))(x)\n",
    "    x=layers.TimeDistributed(layers.GlobalAveragePooling2D())(x)\n",
    "    x=layers.TimeDistributed(layers.Dropout(dp))(x)\n",
    "    x=layers.Bidirectional(layers.LSTM(lstm,return_sequences=False,dropout=dp))(x)\n",
    "    out=layers.Dense(n_cls,activation=\"softmax\")(x)\n",
    "    m=models.Model(inp,out,name=\"EMGHand\")\n",
    "    m.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "    return m\n",
    "\n",
    "def build_dualstream(raw_shape, feat_dim, T, n_cls,\n",
    "                     rf=64, ff=64, lstm=128, dp=.3):\n",
    "    # ⬇⬇  añadimos name=\"raw\" y name=\"feat\"\n",
    "    in_r = layers.Input((T, *raw_shape),     name=\"raw\")\n",
    "    in_f = layers.Input((T, feat_dim),       name=\"feat\")\n",
    "\n",
    "    r = layers.TimeDistributed(\n",
    "            layers.Reshape((raw_shape[0], raw_shape[1])))(in_r)\n",
    "    r = layers.TimeDistributed(\n",
    "            layers.Conv1D(rf, 3, padding=\"same\", activation=\"relu\"))(r)\n",
    "    r = layers.TimeDistributed(layers.GlobalAveragePooling1D())(r)\n",
    "\n",
    "    f = layers.TimeDistributed(\n",
    "            layers.Dense(ff, activation=\"relu\"))(in_f)\n",
    "\n",
    "    x = layers.Concatenate()([r, f])\n",
    "    x = layers.TimeDistributed(layers.Dropout(dp))(x)\n",
    "    x = layers.Bidirectional(\n",
    "            layers.LSTM(lstm, return_sequences=False, dropout=dp))(x)\n",
    "\n",
    "    out = layers.Dense(n_cls, activation=\"softmax\")(x)\n",
    "\n",
    "    m = models.Model([in_r, in_f], out, name=\"DualStr\")\n",
    "    m.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "    return m\n",
    "\n",
    "# ==============================================================================\n",
    "#  MODELO 1: DualStream - Versión Original (Fiel al Paper) - CORREGIDO\n",
    "# ==============================================================================\n",
    "\n",
    "def build_dualstream_original(raw_shape, feat_dim, T, n_cls, lstm_units=200, conv_filters=256, dp=0.3):\n",
    "    \"\"\"\n",
    "    Implementación fiel del modelo Dual Stream LSTM Feature Fusion de Zhang et al. (2024).\n",
    "    Referencia: https://doi.org/10.3390/s24113631\n",
    "    \n",
    "    Características principales:\n",
    "    - Flujo Raw: Conv1D -> LSTM -> Conv1D\n",
    "    - Flujo Features: Conv1D -> Conv1D\n",
    "    - Fusión y Bloque Temporal: Concatenate -> Bi-LSTM -> Bi-LSTM\n",
    "    \"\"\"\n",
    "    # --- Input Streams ---\n",
    "    in_raw = layers.Input(shape=(T, *raw_shape), name=\"raw\")\n",
    "    in_feat = layers.Input(shape=(T, feat_dim), name=\"feat\")\n",
    "\n",
    "    # --- Flujo de Datos Crudos (Raw Data Stream) ---\n",
    "    r = layers.TimeDistributed(layers.Reshape((raw_shape[0], raw_shape[1])))(in_raw)\n",
    "    r = layers.TimeDistributed(layers.Conv1D(conv_filters, 3, padding=\"same\", activation=\"relu\"))(r)\n",
    "    r = layers.TimeDistributed(layers.LSTM(lstm_units, return_sequences=True, dropout=dp))(r)\n",
    "    r = layers.TimeDistributed(layers.Conv1D(conv_filters, 3, padding=\"same\", activation=\"relu\"))(r)\n",
    "    r = layers.TimeDistributed(layers.GlobalAveragePooling1D())(r)\n",
    "    \n",
    "    # --- Flujo de Características (Feature Stream) ---\n",
    "    # ¡CORRECCIÓN AQUÍ! Añadimos una dimensión para que Conv1D funcione.\n",
    "    # La forma pasa de (T, feat_dim) a (T, feat_dim, 1).\n",
    "    f = layers.Reshape((T, feat_dim, 1))(in_feat)\n",
    "    \n",
    "    f = layers.TimeDistributed(layers.Conv1D(conv_filters, 3, padding=\"same\", activation=\"relu\"))(f)\n",
    "    f = layers.TimeDistributed(layers.Conv1D(conv_filters, 3, padding=\"same\", activation=\"relu\"))(f)\n",
    "    # GlobalAveragePooling1D reduce la dimensión de \"steps\" (la de 100), dejando (T, filters)\n",
    "    f = layers.TimeDistributed(layers.GlobalAveragePooling1D())(f)\n",
    "\n",
    "    # --- Fusión y Bloque Temporal ---\n",
    "    x = layers.Concatenate()([r, f])\n",
    "    x = layers.Bidirectional(layers.LSTM(lstm_units, return_sequences=True, dropout=dp))(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(lstm_units, return_sequences=False, dropout=dp))(x)\n",
    "\n",
    "    # --- Clasificador ---\n",
    "    x = layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dp)(x)\n",
    "    out = layers.Dense(n_cls, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = models.Model(inputs=[in_raw, in_feat], outputs=out, name=\"DualStream_Original\")\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# ==============================================================================\n",
    "#  MODELO 2: DualStream - Versión Adaptada y Ligera (Tu Implementación)\n",
    "# ==============================================================================\n",
    "\n",
    "def build_dualstream_adaptado(raw_shape, feat_dim, T, n_cls, rf=64, ff=64, lstm=128, dp=0.3):\n",
    "    \"\"\"\n",
    "    Versión adaptada y ligera del concepto DualStream, propuesta en esta tesis.\n",
    "    (Tu implementación original de 'build_dualstream').\n",
    "    \"\"\"\n",
    "    in_r = layers.Input((T, *raw_shape), name=\"raw\")\n",
    "    in_f = layers.Input((T, feat_dim), name=\"feat\")\n",
    "    r = layers.TimeDistributed(layers.Reshape((raw_shape[0], raw_shape[1])))(in_r)\n",
    "    r = layers.TimeDistributed(layers.Conv1D(rf, 3, padding=\"same\", activation=\"relu\"))(r)\n",
    "    r = layers.TimeDistributed(layers.GlobalAveragePooling1D())(r)\n",
    "    f = layers.TimeDistributed(layers.Dense(ff, activation=\"relu\"))(in_f)\n",
    "    x = layers.Concatenate()([r, f])\n",
    "    x = layers.TimeDistributed(layers.Dropout(dp))(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(lstm, return_sequences=False, dropout=dp))(x)\n",
    "    out = layers.Dense(n_cls, activation=\"softmax\")(x)\n",
    "    model = models.Model([in_r, in_f], out, name=\"DualStream_Adaptado\")\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "#  MODELO 3: EMGHandNet - Versión Original (Fiel al Paper)\n",
    "# ==============================================================================\n",
    "\n",
    "def build_emghandnet_original(raw_shape, T, n_cls, filters=(64, 64, 64, 64), lstm_units=200, dp=0.3):\n",
    "    \"\"\"\n",
    "    Implementación fiel del modelo EMGHandNet de Karnam et al. (2022).\n",
    "    Referencia: https://www.sciencedirect.com/science/article/abs/pii/S0208521622000080\n",
    "    \n",
    "    Características principales:\n",
    "    - Utiliza exclusivamente convoluciones 1D (Conv1D) para los canales de EMG.\n",
    "    - Dos capas Bi-LSTM apiladas para el procesamiento temporal.\n",
    "    \"\"\"\n",
    "    inp = layers.Input(shape=(T, *raw_shape), name=\"raw\")\n",
    "    x = layers.TimeDistributed(layers.Reshape((raw_shape[0], raw_shape[1])))(inp)\n",
    "\n",
    "    for i, f in enumerate(filters):\n",
    "        x = layers.TimeDistributed(layers.Conv1D(f, 3, padding=\"same\", activation=\"relu\"), name=f'td_conv1d_{i}')(x)\n",
    "        x = layers.TimeDistributed(layers.BatchNormalization(), name=f'td_bn_{i}')(x)\n",
    "        x = layers.TimeDistributed(layers.MaxPool1D(2), name=f'td_pool_{i}')(x)\n",
    "        \n",
    "    x = layers.TimeDistributed(layers.Flatten(), name='td_flatten')(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(lstm_units, return_sequences=True, dropout=dp))(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(lstm_units, return_sequences=False, dropout=dp))(x)\n",
    "    x = layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dp)(x)\n",
    "    out = layers.Dense(n_cls, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = models.Model(inputs=inp, outputs=out, name=\"EMGHandNet_Original\")\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# ==============================================================================\n",
    "#  MODELO 4: EMGHandNet - Versión Adaptada con Conv2D (Tu Implementación)\n",
    "# ==============================================================================\n",
    "\n",
    "def build_emghandnet_adaptado(raw_shape, T, n_cls, filters=(64,128), lstm=128, dp=.3):\n",
    "    \"\"\"\n",
    "    Versión adaptada de EMGHandNet que utiliza Conv2D para tratar las ventanas como imágenes.\n",
    "    (Tu implementación original de 'build_emghandnet').\n",
    "    \"\"\"\n",
    "    inp = layers.Input((T, *raw_shape), name=\"raw\")\n",
    "    x = inp\n",
    "    for f in filters:\n",
    "        x = layers.TimeDistributed(layers.Conv2D(f, (3, 3), padding=\"same\", activation=\"relu\"))(x)\n",
    "        x = layers.TimeDistributed(layers.BatchNormalization())(x)\n",
    "        x = layers.TimeDistributed(layers.MaxPool2D((2, 2)))(x)\n",
    "    x = layers.TimeDistributed(layers.GlobalAveragePooling2D())(x)\n",
    "    x = layers.TimeDistributed(layers.Dropout(dp))(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(lstm, return_sequences=False, dropout=dp))(x)\n",
    "    out = layers.Dense(n_cls, activation=\"softmax\")(x)\n",
    "    model = models.Model(inp, out, name=\"EMGHandNet_Adaptado\")\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                  loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "#  MODELO 5: HyT-Net - Modelo Híbrido CNN-Transformer (Propuesto por ti)\n",
    "# ==============================================================================\n",
    "\n",
    "def build_hyt_net_propuesto(raw_shape, feat_dim, T, n_cls, heads=4, dim=128, dp=0.3):\n",
    "    \"\"\"\n",
    "    Arquitectura Híbrida CNN-Transformer (HyT-Net) propuesta en esta tesis.\n",
    "    (Tu implementación original de 'build_sota').\n",
    "    \"\"\"\n",
    "    # --- Rama CNN para ventanas 2D ---\n",
    "    seg_in = layers.Input(raw_shape, name=\"seg_input\")\n",
    "    x_cnn = layers.Conv2D(64, (5,1), padding=\"same\", activation=\"relu\")(seg_in)\n",
    "    x_cnn = layers.BatchNormalization()(x_cnn)\n",
    "    x_cnn = layers.Conv2D(64, (3,1), padding=\"same\", activation=\"relu\")(x_cnn)\n",
    "    x_cnn = layers.BatchNormalization()(x_cnn)\n",
    "    seg_vec = layers.GlobalAveragePooling2D()(x_cnn)\n",
    "    seg_cnn_model = models.Model(seg_in, seg_vec, name=\"segment_cnn\")\n",
    "\n",
    "    # --- Entradas y Procesamiento de Secuencias ---\n",
    "    in_raw = layers.Input((T, *raw_shape), name=\"raw\")\n",
    "    in_feat = layers.Input((T, feat_dim), name=\"feat\")\n",
    "    raw_seq = layers.TimeDistributed(seg_cnn_model)(in_raw)\n",
    "    feat_seq = layers.TimeDistributed(layers.Dense(64, activation=\"relu\"))(in_feat)\n",
    "    \n",
    "    # --- Fusión y Proyección ---\n",
    "    fusion = layers.Concatenate(axis=-1)([raw_seq, feat_seq])\n",
    "    projection = layers.Dense(dim, activation=\"linear\")(fusion)\n",
    "\n",
    "    # --- Bloques Transformer ---\n",
    "    def transformer_encoder_block(seq_input, key_dim, num_heads, dropout_rate):\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(seq_input)\n",
    "        x = layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim, dropout=dropout_rate)(x, x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        res = x + seq_input\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "        x = layers.Dense(key_dim * 4, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        x = layers.Dense(key_dim)(x)\n",
    "        return x + res\n",
    "\n",
    "    z = transformer_encoder_block(projection, dim, heads, dp)\n",
    "    z = transformer_encoder_block(z, dim, heads, dp)\n",
    "\n",
    "    # --- Clasificador ---\n",
    "    z = layers.GlobalAveragePooling1D()(z)\n",
    "    z = layers.Dropout(dp)(z)\n",
    "    z = layers.Dense(128, activation=\"relu\")(z)\n",
    "    z = layers.Dropout(dp)(z)\n",
    "    out = layers.Dense(n_cls, activation=\"softmax\", name=\"output\")(z)\n",
    "    \n",
    "    model = models.Model(inputs=[in_raw, in_feat], outputs=out, name=\"HyT-Net_Propuesto\")\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# ---------- 6. CALLBACKS  & EPOCHS -------------------------------------------\n",
    "def cb(model_name):\n",
    "    ts= datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    ck=os.path.join(MODELS_DIR,f\"{model_name}_{ts}.keras\")\n",
    "    return [\n",
    "        EarlyStopping(monitor=\"val_loss\",patience=15,restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor=\"val_loss\",factor=.5,patience=5,min_lr=1e-6),\n",
    "        ModelCheckpoint(ck,monitor=\"val_accuracy\",save_best_only=True,verbose=0),\n",
    "        TensorBoard(log_dir=os.path.join(RUNS_DIR,f\"{model_name}_{ts}\"))\n",
    "    ]\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "# ---------- 7. TRAIN ----------------------------------------------------------\n",
    "# models_to_train=[\n",
    "#     (\"DualStr\"   , build_dualstream(RAW_SHAPE,feat_dim,T_SUBWIN,NUM_CLASSES),True,  EPOCHS,  train_ds_h, val_ds_h),\n",
    "#     (\"SOTA_Trans\", build_sota   (RAW_SHAPE,feat_dim,T_SUBWIN,NUM_CLASSES), True,  EPOCHS,   train_ds_h, val_ds_h),\n",
    "#     (\"Hybrid_A2\" , build_hybrid_v2(RAW_SHAPE,feat_dim,T_SUBWIN,NUM_CLASSES), True,  EPOCHS, train_ds_h, val_ds_h),\n",
    "#     (\"EMGHand\"   , build_emghandnet(RAW_SHAPE,T_SUBWIN,NUM_CLASSES),        False, EPOCHS,  train_ds_raw,val_ds_raw),\n",
    "# ]\n",
    "\n",
    "models_to_train=[\n",
    "    (\"DualStr-Lite\", build_dualstream_adaptado(RAW_SHAPE, feat_dim, T_SUBWIN, NUM_CLASSES), True, EPOCHS, train_ds_h, val_ds_h),\n",
    "    (\"DualStr-Original\", build_dualstream_original(RAW_SHAPE, feat_dim, T_SUBWIN, NUM_CLASSES), True, EPOCHS, train_ds_h, val_ds_h),\n",
    "    (\"EMGHandNet-2D\", build_emghandnet(RAW_SHAPE, T_SUBWIN, NUM_CLASSES), False, EPOCHS, train_ds_raw, val_ds_raw),\n",
    "    (\"EMGHandNet-Original\", build_emghandnet_original(RAW_SHAPE, T_SUBWIN, NUM_CLASSES), False, EPOCHS, train_ds_raw, val_ds_raw),\n",
    "    (\"HyT-Net\", build_hyt_net_propuesto(RAW_SHAPE, feat_dim, T_SUBWIN, NUM_CLASSES), True, EPOCHS, train_ds_h, val_ds_h),\n",
    "    (\"CRNN-Attn\", build_hybrid_v2(RAW_SHAPE,feat_dim,T_SUBWIN,NUM_CLASSES), True,  EPOCHS, train_ds_h, val_ds_h),\n",
    "]\n",
    "\n",
    "# ---------- EXTRA: REPORTE DE PARÁMETROS -------------------------------------\n",
    "def print_model_params(models):\n",
    "    \"\"\"Imprime nº de parámetros y tamaño aprox. en memoria para cada modelo.\"\"\"\n",
    "    print(\"\\n🧮  Parámetros por modelo\")\n",
    "    for name, model, *_ in models:\n",
    "        params = model.count_params()\n",
    "        size_mb = params * 4 / (1024 ** 2)          # 4 bytes por parámetro fp32\n",
    "        print(f\"{name:10s}: {params:,}  (~{size_mb:.2f} MB)\")\n",
    "\n",
    "# Llama a la función para ver el reporte\n",
    "print_model_params(models_to_train)\n",
    "\n",
    "# =============================================================================\n",
    "# cv_pipeline.py · 10‑Fold CV + Resumable Training for Ninapro‑DB1\n",
    "# Israel Huentecura ✨ · Mayo 2025\n",
    "# =============================================================================\n",
    "import os, json, datetime as dt, numpy as np, pandas as pd, tensorflow as tf\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# ------------------------------------------------------------------------- #\n",
    "# 0️⃣  RUTAS Y CONSTANTES GLOBALES\n",
    "# ------------------------------------------------------------------------- #\n",
    "SEED        = 42\n",
    "N_FOLDS     = 10\n",
    "EPOCHS      = 100\n",
    "BATCH_SIZE  = 128\n",
    "\n",
    "RUNS_DIR    = Path(\"runs\")\n",
    "MODELS_DIR  = Path(\"models\")\n",
    "BACKUP_DIR  = RUNS_DIR / \"_backup\"          # aquí se guardan estados por batch\n",
    "STATS_FILE  = RUNS_DIR / \"cv_progress.json\" # bitácora para saltar folds/‑modelos\n",
    "\n",
    "for d in (RUNS_DIR, MODELS_DIR, BACKUP_DIR):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------- #\n",
    "# 1️⃣  CARGA / SPLIT DE LOS ARRAYS EN MEMORIA\n",
    "# ------------------------------------------------------------------------- #\n",
    "def assemble_arrays_holdout():\n",
    "    \"\"\"\n",
    "    Construye tres juegos:\n",
    "      • (X_raw, F, y)           → train+val  (para la CV)\n",
    "      • (X_test_raw, F_test, y_test) → test  (hold‑out)\n",
    "    A partir de los arrays pre‑procesados que ya tengas en memoria\n",
    "    (X_tr_raw, F_tr, y_tr, val_X, val_feats, y_val, X_te_raw, F_te, y_te).\n",
    "    \"\"\"\n",
    "    g = globals()\n",
    "    # --- train+val (se usará dentro de los folds) -------------------------\n",
    "    tr_val_partsX = []; tr_val_partsF = []; tr_val_partsY = []\n",
    "\n",
    "    def _add_tv(x, f, y):\n",
    "        if x in g and y in g:                          # sólo si existen\n",
    "            tr_val_partsX.append(g[x]); tr_val_partsY.append(g[y])\n",
    "            if f in g: tr_val_partsF.append(g[f])\n",
    "\n",
    "    _add_tv('X_tr_raw', 'F_tr',  'y_tr')\n",
    "    _add_tv('val_X',    'val_feats', 'y_val')\n",
    "\n",
    "    if not tr_val_partsX:\n",
    "        raise RuntimeError(\"❌ No se encontraron arrays de train+val en memoria\")\n",
    "\n",
    "    global X_raw_all, F_all, y_all\n",
    "    X_raw_all = np.concatenate(tr_val_partsX, 0)\n",
    "    y_all     = np.concatenate(tr_val_partsY,  0)\n",
    "    F_all     = (np.concatenate(tr_val_partsF, 0)\n",
    "                 if tr_val_partsF else None)\n",
    "\n",
    "    # --- test -------------------------------------------------------------\n",
    "    global X_raw_test, F_test, y_test\n",
    "    if 'X_te_raw' not in g or 'y_te' not in g:\n",
    "        # → Si no tenías test pre‑calculado, házlo con train_test_split\n",
    "        #   (estratificado y sin reemplazo)\n",
    "        idx_trval = np.arange(len(y_all))\n",
    "        X_raw_all, X_raw_test, y_all, y_test, idx_trval, idx_test = \\\n",
    "            train_test_split(X_raw_all, y_all,\n",
    "                             np.arange(len(y_all)),\n",
    "                             test_size=TEST_PCT, random_state=SEED,\n",
    "                             stratify=np.argmax(y_all, 1))\n",
    "        if F_all is not None:\n",
    "            F_all, F_test = F_all[idx_trval], F_all[idx_test]\n",
    "        else:\n",
    "            F_test = None\n",
    "    else:\n",
    "        X_raw_test = g['X_te_raw']; y_test = g['y_te']\n",
    "        F_test     = g.get('F_te', None)\n",
    "\n",
    "    print(f\"✅  Train+Val: {X_raw_all.shape}  Test: {X_raw_test.shape}\")\n",
    "\n",
    "# ------------------------------------------------------------------------- #\n",
    "# 2️⃣  tf.data WRAPPER (sin cambios salvo docstring)\n",
    "# ------------------------------------------------------------------------- #\n",
    "def make_ds(x_raw, feats, y, uses_feat, shuffle):\n",
    "    \"\"\"\n",
    "    • uses_feat=True  → se crea dict{'raw':…, 'feat':…}\n",
    "    • uses_feat=False → sólo la rama raw\n",
    "    \"\"\"\n",
    "    if uses_feat and feats is None:\n",
    "        raise ValueError(\"El modelo requiere features pero feats=None\")\n",
    "    if uses_feat:\n",
    "        ds = tf.data.Dataset.from_tensor_slices(({\"raw\": x_raw, \"feat\": feats},\n",
    "                                                 y))\n",
    "    else:\n",
    "        ds = tf.data.Dataset.from_tensor_slices((x_raw, y))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(len(y), seed=SEED, reshuffle_each_iteration=True)\n",
    "    return ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# ------------------------------------------------------------------------- #\n",
    "# 3️⃣  CALLBACKS\n",
    "# ------------------------------------------------------------------------- #\n",
    "def make_callbacks(tag):\n",
    "    ck_path   = MODELS_DIR / f\"{tag}_BEST.keras\"\n",
    "    backup_to = BACKUP_DIR / tag\n",
    "    log_dir   = RUNS_DIR  / f\"{tag}_{dt.datetime.now():%Y%m%d-%H%M%S}\"\n",
    "\n",
    "    return [\n",
    "        tf.keras.callbacks.BackupAndRestore(\n",
    "            backup_to, delete_checkpoint=False),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            ck_path, monitor=\"val_accuracy\", save_best_only=True,\n",
    "            save_weights_only=False, verbose=0),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=15, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", patience=5, factor=0.5, min_lr=1e-6),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir=log_dir),\n",
    "    ]\n",
    "\n",
    "# ------------------------------------------------------------------------- #\n",
    "# 4️⃣  BITÁCORA DE CURSOS TERMINADOS\n",
    "# ------------------------------------------------------------------------- #\n",
    "STATS_FILE  = RUNS_DIR / \"cv_progress.json\"\n",
    "def load_stats():\n",
    "    return json.loads(STATS_FILE.read_text()) if STATS_FILE.exists() else {}\n",
    "\n",
    "def mark_done(tag, val_acc):\n",
    "    stats = load_stats()\n",
    "    stats[tag] = {\"val_acc\": float(val_acc)}\n",
    "    STATS_FILE.write_text(json.dumps(stats, indent=2))\n",
    "\n",
    "# ------------------------------------------------------------------------- #\n",
    "# 5️⃣  K‑FOLD  · GUARDA EL MEJOR CKPT POR ARQUITECTURA  🆕\n",
    "# ------------------------------------------------------------------------- #\n",
    "def run_kfold(models_spec):\n",
    "    \"\"\"\n",
    "    models_spec = [\n",
    "        (\"Nombre\", build_fn, uses_feat_bool),\n",
    "        ...\n",
    "    ]\n",
    "    Devuelve:\n",
    "      • df_folds    → métrica de cada (modelo, fold)\n",
    "      • summary_cv  → media ± std por modelo\n",
    "      • best_ckpts  → {'Nombre': {'ckpt': Path, 'val_acc':…, 'uses_feat':…}}\n",
    "    \"\"\"\n",
    "    skf        = StratifiedKFold(n_splits=N_FOLDS,\n",
    "                                 shuffle=True, random_state=SEED)\n",
    "    rows       = []\n",
    "    done       = load_stats()\n",
    "    best_ckpts = {name: {\"val_acc\": -np.inf, \"ckpt\": None,\n",
    "                         \"uses_feat\": uses_feat}\n",
    "                  for name, _, uses_feat in models_spec}\n",
    "\n",
    "    for fold, (tr, va) in enumerate(skf.split(X_raw_all,\n",
    "                                              np.argmax(y_all, 1)), 1):\n",
    "        X_tr, X_va   = X_raw_all[tr], X_raw_all[va]\n",
    "        y_tr, y_va   = y_all[tr],     y_all[va]\n",
    "        F_tr = F_all[tr] if F_all is not None else None\n",
    "        F_va = F_all[va] if F_all is not None else None\n",
    "\n",
    "        for name, build_fn, uses_feat in models_spec:\n",
    "            tag = f\"{name}_fold{fold}\"\n",
    "            if tag in done:\n",
    "                print(f\"⏭️  {tag} ya entrenado, se salta\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\n📚  Entrenando {tag}\")\n",
    "            # --- construcción del modelo ----------------------------------\n",
    "            if uses_feat:\n",
    "                model = build_fn(RAW_SHAPE, feat_dim,\n",
    "                                 T_SUBWIN, NUM_CLASSES)\n",
    "            else:\n",
    "                model = build_fn(RAW_SHAPE, T_SUBWIN, NUM_CLASSES)\n",
    "\n",
    "            train_ds = make_ds(X_tr, F_tr, y_tr, uses_feat, shuffle=True)\n",
    "            val_ds   = make_ds(X_va, F_va, y_va, uses_feat, shuffle=False)\n",
    "\n",
    "            history  = model.fit(\n",
    "                train_ds, validation_data=val_ds,\n",
    "                epochs=EPOCHS, callbacks=make_callbacks(tag), verbose=1).history\n",
    "            best_va = max(history[\"val_accuracy\"])\n",
    "            rows.append([name, fold, best_va])\n",
    "\n",
    "            # --- ¿Mejor ckpt de la arquitectura? -------------------------\n",
    "            ck_file = MODELS_DIR / f\"{tag}_BEST.keras\"\n",
    "            if best_va > best_ckpts[name][\"val_acc\"]:\n",
    "                best_ckpts[name][\"val_acc\"] = best_va\n",
    "                best_ckpts[name][\"ckpt\"]    = ck_file\n",
    "\n",
    "            mark_done(tag, best_va)\n",
    "            tf.keras.backend.clear_session()\n",
    "\n",
    "    df_folds = pd.DataFrame(rows, columns=[\"Model\", \"Fold\", \"Val_Acc\"])\n",
    "    summary  = df_folds.groupby(\"Model\").Val_Acc.agg(['mean','std']).round(4)\n",
    "\n",
    "    print(\"\\n📊  Resumen 10‑fold (Val_Acc)\")\n",
    "    print(summary)\n",
    "    return df_folds, summary, best_ckpts\n",
    "\n",
    "# ------------------------------------------------------------------------- #\n",
    "# 6️⃣  EVALUACIÓN FINAL EN HOLD‑OUT TEST  🆕\n",
    "# ------------------------------------------------------------------------- #\n",
    "def evaluate_on_test(best_ckpts):\n",
    "    \"\"\"\n",
    "    Carga el mejor checkpoint de cada arquitectura y lo evalúa sobre el test.\n",
    "    Devuelve df_test con columnas: Model · Test_Acc · Test_Loss\n",
    "    \"\"\"\n",
    "    test_results = []\n",
    "    for name, meta in best_ckpts.items():\n",
    "        ck = meta[\"ckpt\"]\n",
    "        if ck is None or not ck.exists():\n",
    "            print(f\"⚠️  {name}: no se encontró ckpt; se omite\")\n",
    "            continue\n",
    "        print(f\"🧪  Testing {name}  (ckpt={ck.name})\")\n",
    "        model = tf.keras.models.load_model(ck, compile=True)\n",
    "        test_ds = make_ds(X_raw_test, F_test, y_test,\n",
    "                          meta[\"uses_feat\"], shuffle=False)\n",
    "        loss, acc = model.evaluate(test_ds, verbose=0)\n",
    "        test_results.append([name, acc, loss])\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "    df_test = (pd.DataFrame(test_results,\n",
    "                            columns=[\"Model\", \"Test_Acc\", \"Test_Loss\"])\n",
    "               .sort_values(\"Test_Acc\", ascending=False)\n",
    "               .reset_index(drop=True))\n",
    "    print(\"\\n🎯  Rendimiento en HOLD‑OUT Test\")\n",
    "    print(df_test)\n",
    "    return df_test\n",
    "\n",
    "# ------------------------------------------------------------------------- #\n",
    "# 7️⃣  EJECUCIÓN PRINCIPAL (ejemplo)\n",
    "# ------------------------------------------------------------------------- #\n",
    "# 1. Ensambla arrays → genera train+val y test\n",
    "assemble_arrays_holdout()\n",
    "\n",
    "# 2. Catálogo de modelos (tus constructores sin tocar)\n",
    "models_spec = [\n",
    "    (\"DualStream-Lite\",      build_dualstream_adaptado,  True),\n",
    "    (\"DualStream-Original\",      build_dualstream_original,  True),\n",
    "    (\"CRNN-Attn\",             build_hybrid_v2,            True),\n",
    "    (\"EMGHandNet-2D\",   build_emghandnet_adaptado,  False),\n",
    "    (\"EMGHandNet-Original\",   build_emghandnet_original,  False),\n",
    "    (\"HyT-Net\",  build_hyt_net_propuesto,    True),\n",
    "]\n",
    "\n",
    "# 3. 10‑fold\n",
    "df_folds, df_summary, best_ckpts = run_kfold(models_spec)\n",
    "\n",
    "# 4. Evaluación en test externo\n",
    "df_test = evaluate_on_test(best_ckpts)\n",
    "\n",
    "# 5. Guarda DataFrames de resultados\n",
    "df_folds.to_csv(RUNS_DIR / \"folds_val_acc.csv\",    index=False)\n",
    "df_summary.to_csv(RUNS_DIR / \"cv_summary.csv\")\n",
    "df_test.to_csv(RUNS_DIR / \"test_summary.csv\",      index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2554e6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feat_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m FS        \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     42\u001b[0m TEST_PCT  \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.20\u001b[39m\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeat_dim =\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mfeat_dim\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   NUM_CLASSES =\u001b[39m\u001b[38;5;124m\"\u001b[39m, NUM_CLASSES)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# ---------- 5. MODELOS --------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# 5-A  Modelo propuesto   ------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbuild_sota\u001b[39m(raw_shape,feat_dim,T,n_cls,heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,dp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feat_dim' is not defined"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ninapro‑DB1 · 10‑Fold CV + Hold‑out Test\n",
    "# Israel Huentecura ✨ · Junio 2025\n",
    "# =============================================================================\n",
    "# ‑‑ IMPORTS ------------------------------------------------------------------\n",
    "import os, random, json, datetime as dt, shutil\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd, tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import datetime\n",
    "\n",
    "# ------------------------------------------------------------------------- #\n",
    "# 0️⃣  CFG GLOBAL\n",
    "# ------------------------------------------------------------------------- #\n",
    "SEED          = 42\n",
    "np.random.seed(SEED); random.seed(SEED); tf.random.set_seed(SEED)\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "\n",
    "DATA_ROOT     = \"data/ninapro/db1_processed\"\n",
    "RUNS_DIR      = Path(\"runs\")\n",
    "MODELS_DIR    = Path(\"models\")\n",
    "BACKUP_DIR    = RUNS_DIR / \"_backup\"\n",
    "for d in (RUNS_DIR, MODELS_DIR, BACKUP_DIR): d.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "N_FOLDS     = 10\n",
    "EPOCHS      = 100\n",
    "BATCH_SIZE  = 128\n",
    "TEST_PCT    = 0.20                    # proporción fija para el hold‑out\n",
    "\n",
    "# ---------- 0. GLOBAL CFG -----------------------------------------------------\n",
    "SEED          = 42\n",
    "np.random.seed(SEED); random.seed(SEED); tf.random.set_seed(SEED)\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "DATA_ROOT     = \"data/ninapro/db1_processed\"\n",
    "SPLIT_DIR     = \"splits\"; RUNS_DIR = \"runs\"; MODELS_DIR = \"models\"\n",
    "for d in (SPLIT_DIR, RUNS_DIR, MODELS_DIR): os.makedirs(d, exist_ok=True)\n",
    "\n",
    "WIN_LEN   = 20          # 200 ms\n",
    "T_SUBWIN  = 5\n",
    "HANDCRAFT_PER_CH = 10\n",
    "FS        = 100\n",
    "TEST_PCT  = 0.20\n",
    "\n",
    "print(\"feat_dim =\", feat_dim, \"   NUM_CLASSES =\", NUM_CLASSES)\n",
    "# ---------- 5. MODELOS --------------------------------------------------------\n",
    "#\n",
    "# 5-A  Modelo propuesto   ------------------------------------------------------\n",
    "def build_sota(raw_shape,feat_dim,T,n_cls,heads=4,dim=128,dp=0.3):\n",
    "    seg_in = layers.Input(raw_shape)\n",
    "    x=layers.Conv2D(64,(5,1),padding=\"same\",activation=\"relu\")(seg_in)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.Conv2D(64,(3,1),padding=\"same\",activation=\"relu\")(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    seg_vec = layers.GlobalAveragePooling2D()(x)\n",
    "    seg_cnn=models.Model(seg_in,seg_vec)\n",
    "\n",
    "    in_raw  = layers.Input((T,*raw_shape),name=\"raw\")\n",
    "    in_feat = layers.Input((T,feat_dim),  name=\"feat\")\n",
    "    r = layers.TimeDistributed(seg_cnn)(in_raw)\n",
    "    f = layers.TimeDistributed(layers.Dense(64,activation=\"relu\"))(in_feat)\n",
    "    concat = layers.Concatenate()([r,f])\n",
    "    proj = layers.Dense(dim)(concat)\n",
    "\n",
    "    def trans_block(z):\n",
    "        a = layers.LayerNormalization(epsilon=1e-6)(z)\n",
    "        a = layers.MultiHeadAttention(num_heads=heads,key_dim=dim,dropout=dp)(a,a)\n",
    "        z = z+a\n",
    "        b = layers.LayerNormalization(epsilon=1e-6)(z)\n",
    "        b = layers.Dense(dim*4,activation=\"relu\")(b)\n",
    "        b = layers.Dense(dim)(b); b = layers.Dropout(dp)(b)\n",
    "        return z+b\n",
    "    z = trans_block(proj); z = trans_block(z)\n",
    "    z = layers.GlobalAveragePooling1D()(z)\n",
    "    z = layers.Dropout(dp)(z)\n",
    "    z = layers.Dense(128,activation=\"relu\")(z)\n",
    "    z = layers.Dropout(dp)(z)\n",
    "    out = layers.Dense(n_cls,activation=\"softmax\")(z)\n",
    "    m = models.Model([in_raw,in_feat],out,name=\"SOTA_Trans\")\n",
    "    m.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "    return m\n",
    "#\n",
    "# 5-B  Modelos del usuario  ----------------------------------------------------\n",
    "class Attention(layers.Layer):\n",
    "    def build(self,inp_shape):\n",
    "        u=inp_shape[-1]\n",
    "        self.W=self.add_weight(\"W\",(u,u),initializer=\"glorot_uniform\")\n",
    "        self.b=self.add_weight(\"b\",(u,),initializer=\"zeros\")\n",
    "        self.u=self.add_weight(\"u\",(u,1),initializer=\"glorot_uniform\")\n",
    "    def call(self,x):\n",
    "        v=tf.tanh(tf.tensordot(x,self.W,1)+self.b)\n",
    "        vu=tf.tensordot(v,self.u,1)\n",
    "        al=tf.nn.softmax(tf.squeeze(vu,-1),1)\n",
    "        return tf.reduce_sum(x*tf.expand_dims(al,-1),1)\n",
    "\n",
    "def mobile_cnn(raw_shape,alpha=.75,dp=.2):\n",
    "    inp=layers.Input(raw_shape)\n",
    "    x=layers.SeparableConv2D(int(32*alpha),3,padding=\"same\",activation=\"relu\")(inp)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.SeparableConv2D(int(64*alpha),3,padding=\"same\",activation=\"relu\")(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.GlobalAveragePooling2D()(x)\n",
    "    x=layers.Dropout(dp)(x)\n",
    "    return models.Model(inp,x)\n",
    "\n",
    "def build_hybrid_v2(raw_shape,feat_dim,T,n_cls,gru=128,dp=.3):\n",
    "    cnn=mobile_cnn(raw_shape)\n",
    "    in_r  = layers.Input((T,*raw_shape),name=\"raw\")\n",
    "    in_f  = layers.Input((T,feat_dim),  name=\"feat\")\n",
    "    r=layers.TimeDistributed(cnn)(in_r)\n",
    "    f=layers.TimeDistributed(layers.Dense(96,activation=\"relu\"))(in_f)\n",
    "    mrg=layers.Concatenate()([r,f])\n",
    "    x=layers.Bidirectional(layers.GRU(gru,return_sequences=True,dropout=dp,recurrent_dropout=dp*0.5))(mrg)\n",
    "    x=Attention()(x); x=layers.Dropout(dp)(x)\n",
    "    out=layers.Dense(n_cls,activation=\"softmax\",\n",
    "                     kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    m=models.Model([in_r,in_f],out,name=\"Hybrid_A2\")\n",
    "    m.compile(optimizer=tf.keras.optimizers.Adam(2e-3),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=.1),\n",
    "              metrics=[\"accuracy\"])\n",
    "    return m\n",
    "\n",
    "def build_emghandnet(raw_shape,T,n_cls,filters=(64,128),lstm=128,dp=.3):\n",
    "    inp=layers.Input((T,*raw_shape))\n",
    "    x=inp\n",
    "    for f in filters:\n",
    "        x=layers.TimeDistributed(layers.Conv2D(f,(3,3),padding=\"same\",activation=\"relu\"))(x)\n",
    "        x=layers.TimeDistributed(layers.BatchNormalization())(x)\n",
    "        x=layers.TimeDistributed(layers.MaxPool2D((2,2)))(x)\n",
    "    x=layers.TimeDistributed(layers.GlobalAveragePooling2D())(x)\n",
    "    x=layers.TimeDistributed(layers.Dropout(dp))(x)\n",
    "    x=layers.Bidirectional(layers.LSTM(lstm,return_sequences=False,dropout=dp))(x)\n",
    "    out=layers.Dense(n_cls,activation=\"softmax\")(x)\n",
    "    m=models.Model(inp,out,name=\"EMGHand\")\n",
    "    m.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "    return m\n",
    "\n",
    "def build_dualstream(raw_shape, feat_dim, T, n_cls,\n",
    "                     rf=64, ff=64, lstm=128, dp=.3):\n",
    "    # ⬇⬇  añadimos name=\"raw\" y name=\"feat\"\n",
    "    in_r = layers.Input((T, *raw_shape),     name=\"raw\")\n",
    "    in_f = layers.Input((T, feat_dim),       name=\"feat\")\n",
    "\n",
    "    r = layers.TimeDistributed(\n",
    "            layers.Reshape((raw_shape[0], raw_shape[1])))(in_r)\n",
    "    r = layers.TimeDistributed(\n",
    "            layers.Conv1D(rf, 3, padding=\"same\", activation=\"relu\"))(r)\n",
    "    r = layers.TimeDistributed(layers.GlobalAveragePooling1D())(r)\n",
    "\n",
    "    f = layers.TimeDistributed(\n",
    "            layers.Dense(ff, activation=\"relu\"))(in_f)\n",
    "\n",
    "    x = layers.Concatenate()([r, f])\n",
    "    x = layers.TimeDistributed(layers.Dropout(dp))(x)\n",
    "    x = layers.Bidirectional(\n",
    "            layers.LSTM(lstm, return_sequences=False, dropout=dp))(x)\n",
    "\n",
    "    out = layers.Dense(n_cls, activation=\"softmax\")(x)\n",
    "\n",
    "    m = models.Model([in_r, in_f], out, name=\"DualStr\")\n",
    "    m.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "    return m\n",
    "\n",
    "# ==============================================================================\n",
    "#  MODELO 1: DualStream - Versión Original (Fiel al Paper) - CORREGIDO\n",
    "# ==============================================================================\n",
    "\n",
    "def build_dualstream_original(raw_shape, feat_dim, T, n_cls, lstm_units=200, conv_filters=256, dp=0.3):\n",
    "    \"\"\"\n",
    "    Implementación fiel del modelo Dual Stream LSTM Feature Fusion de Zhang et al. (2024).\n",
    "    Referencia: https://doi.org/10.3390/s24113631\n",
    "    \n",
    "    Características principales:\n",
    "    - Flujo Raw: Conv1D -> LSTM -> Conv1D\n",
    "    - Flujo Features: Conv1D -> Conv1D\n",
    "    - Fusión y Bloque Temporal: Concatenate -> Bi-LSTM -> Bi-LSTM\n",
    "    \"\"\"\n",
    "    # --- Input Streams ---\n",
    "    in_raw = layers.Input(shape=(T, *raw_shape), name=\"raw\")\n",
    "    in_feat = layers.Input(shape=(T, feat_dim), name=\"feat\")\n",
    "\n",
    "    # --- Flujo de Datos Crudos (Raw Data Stream) ---\n",
    "    r = layers.TimeDistributed(layers.Reshape((raw_shape[0], raw_shape[1])))(in_raw)\n",
    "    r = layers.TimeDistributed(layers.Conv1D(conv_filters, 3, padding=\"same\", activation=\"relu\"))(r)\n",
    "    r = layers.TimeDistributed(layers.LSTM(lstm_units, return_sequences=True, dropout=dp))(r)\n",
    "    r = layers.TimeDistributed(layers.Conv1D(conv_filters, 3, padding=\"same\", activation=\"relu\"))(r)\n",
    "    r = layers.TimeDistributed(layers.GlobalAveragePooling1D())(r)\n",
    "    \n",
    "    # --- Flujo de Características (Feature Stream) ---\n",
    "    # ¡CORRECCIÓN AQUÍ! Añadimos una dimensión para que Conv1D funcione.\n",
    "    # La forma pasa de (T, feat_dim) a (T, feat_dim, 1).\n",
    "    f = layers.Reshape((T, feat_dim, 1))(in_feat)\n",
    "    \n",
    "    f = layers.TimeDistributed(layers.Conv1D(conv_filters, 3, padding=\"same\", activation=\"relu\"))(f)\n",
    "    f = layers.TimeDistributed(layers.Conv1D(conv_filters, 3, padding=\"same\", activation=\"relu\"))(f)\n",
    "    # GlobalAveragePooling1D reduce la dimensión de \"steps\" (la de 100), dejando (T, filters)\n",
    "    f = layers.TimeDistributed(layers.GlobalAveragePooling1D())(f)\n",
    "\n",
    "    # --- Fusión y Bloque Temporal ---\n",
    "    x = layers.Concatenate()([r, f])\n",
    "    x = layers.Bidirectional(layers.LSTM(lstm_units, return_sequences=True, dropout=dp))(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(lstm_units, return_sequences=False, dropout=dp))(x)\n",
    "\n",
    "    # --- Clasificador ---\n",
    "    x = layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dp)(x)\n",
    "    out = layers.Dense(n_cls, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = models.Model(inputs=[in_raw, in_feat], outputs=out, name=\"DualStream_Original\")\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# ==============================================================================\n",
    "#  MODELO 2: DualStream - Versión Adaptada y Ligera (Tu Implementación)\n",
    "# ==============================================================================\n",
    "\n",
    "def build_dualstream_adaptado(raw_shape, feat_dim, T, n_cls, rf=64, ff=64, lstm=128, dp=0.3):\n",
    "    \"\"\"\n",
    "    Versión adaptada y ligera del concepto DualStream, propuesta en esta tesis.\n",
    "    (Tu implementación original de 'build_dualstream').\n",
    "    \"\"\"\n",
    "    in_r = layers.Input((T, *raw_shape), name=\"raw\")\n",
    "    in_f = layers.Input((T, feat_dim), name=\"feat\")\n",
    "    r = layers.TimeDistributed(layers.Reshape((raw_shape[0], raw_shape[1])))(in_r)\n",
    "    r = layers.TimeDistributed(layers.Conv1D(rf, 3, padding=\"same\", activation=\"relu\"))(r)\n",
    "    r = layers.TimeDistributed(layers.GlobalAveragePooling1D())(r)\n",
    "    f = layers.TimeDistributed(layers.Dense(ff, activation=\"relu\"))(in_f)\n",
    "    x = layers.Concatenate()([r, f])\n",
    "    x = layers.TimeDistributed(layers.Dropout(dp))(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(lstm, return_sequences=False, dropout=dp))(x)\n",
    "    out = layers.Dense(n_cls, activation=\"softmax\")(x)\n",
    "    model = models.Model([in_r, in_f], out, name=\"DualStream_Adaptado\")\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "#  MODELO 3: EMGHandNet - Versión Original (Fiel al Paper)\n",
    "# ==============================================================================\n",
    "\n",
    "def build_emghandnet_original(raw_shape, T, n_cls, filters=(64, 64, 64, 64), lstm_units=200, dp=0.3):\n",
    "    \"\"\"\n",
    "    Implementación fiel del modelo EMGHandNet de Karnam et al. (2022).\n",
    "    Referencia: https://www.sciencedirect.com/science/article/abs/pii/S0208521622000080\n",
    "    \n",
    "    Características principales:\n",
    "    - Utiliza exclusivamente convoluciones 1D (Conv1D) para los canales de EMG.\n",
    "    - Dos capas Bi-LSTM apiladas para el procesamiento temporal.\n",
    "    \"\"\"\n",
    "    inp = layers.Input(shape=(T, *raw_shape), name=\"raw\")\n",
    "    x = layers.TimeDistributed(layers.Reshape((raw_shape[0], raw_shape[1])))(inp)\n",
    "\n",
    "    for i, f in enumerate(filters):\n",
    "        x = layers.TimeDistributed(layers.Conv1D(f, 3, padding=\"same\", activation=\"relu\"), name=f'td_conv1d_{i}')(x)\n",
    "        x = layers.TimeDistributed(layers.BatchNormalization(), name=f'td_bn_{i}')(x)\n",
    "        x = layers.TimeDistributed(layers.MaxPool1D(2), name=f'td_pool_{i}')(x)\n",
    "        \n",
    "    x = layers.TimeDistributed(layers.Flatten(), name='td_flatten')(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(lstm_units, return_sequences=True, dropout=dp))(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(lstm_units, return_sequences=False, dropout=dp))(x)\n",
    "    x = layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dp)(x)\n",
    "    out = layers.Dense(n_cls, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = models.Model(inputs=inp, outputs=out, name=\"EMGHandNet_Original\")\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# ==============================================================================\n",
    "#  MODELO 4: EMGHandNet - Versión Adaptada con Conv2D (Tu Implementación)\n",
    "# ==============================================================================\n",
    "\n",
    "def build_emghandnet_adaptado(raw_shape, T, n_cls, filters=(64,128), lstm=128, dp=.3):\n",
    "    \"\"\"\n",
    "    Versión adaptada de EMGHandNet que utiliza Conv2D para tratar las ventanas como imágenes.\n",
    "    (Tu implementación original de 'build_emghandnet').\n",
    "    \"\"\"\n",
    "    inp = layers.Input((T, *raw_shape), name=\"raw\")\n",
    "    x = inp\n",
    "    for f in filters:\n",
    "        x = layers.TimeDistributed(layers.Conv2D(f, (3, 3), padding=\"same\", activation=\"relu\"))(x)\n",
    "        x = layers.TimeDistributed(layers.BatchNormalization())(x)\n",
    "        x = layers.TimeDistributed(layers.MaxPool2D((2, 2)))(x)\n",
    "    x = layers.TimeDistributed(layers.GlobalAveragePooling2D())(x)\n",
    "    x = layers.TimeDistributed(layers.Dropout(dp))(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(lstm, return_sequences=False, dropout=dp))(x)\n",
    "    out = layers.Dense(n_cls, activation=\"softmax\")(x)\n",
    "    model = models.Model(inp, out, name=\"EMGHandNet_Adaptado\")\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                  loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "#  MODELO 5: HyT-Net - Modelo Híbrido CNN-Transformer (Propuesto por ti)\n",
    "# ==============================================================================\n",
    "\n",
    "def build_hyt_net_propuesto(raw_shape, feat_dim, T, n_cls, heads=4, dim=128, dp=0.3):\n",
    "    \"\"\"\n",
    "    Arquitectura Híbrida CNN-Transformer (HyT-Net) propuesta en esta tesis.\n",
    "    (Tu implementación original de 'build_sota').\n",
    "    \"\"\"\n",
    "    # --- Rama CNN para ventanas 2D ---\n",
    "    seg_in = layers.Input(raw_shape, name=\"seg_input\")\n",
    "    x_cnn = layers.Conv2D(64, (5,1), padding=\"same\", activation=\"relu\")(seg_in)\n",
    "    x_cnn = layers.BatchNormalization()(x_cnn)\n",
    "    x_cnn = layers.Conv2D(64, (3,1), padding=\"same\", activation=\"relu\")(x_cnn)\n",
    "    x_cnn = layers.BatchNormalization()(x_cnn)\n",
    "    seg_vec = layers.GlobalAveragePooling2D()(x_cnn)\n",
    "    seg_cnn_model = models.Model(seg_in, seg_vec, name=\"segment_cnn\")\n",
    "\n",
    "    # --- Entradas y Procesamiento de Secuencias ---\n",
    "    in_raw = layers.Input((T, *raw_shape), name=\"raw\")\n",
    "    in_feat = layers.Input((T, feat_dim), name=\"feat\")\n",
    "    raw_seq = layers.TimeDistributed(seg_cnn_model)(in_raw)\n",
    "    feat_seq = layers.TimeDistributed(layers.Dense(64, activation=\"relu\"))(in_feat)\n",
    "    \n",
    "    # --- Fusión y Proyección ---\n",
    "    fusion = layers.Concatenate(axis=-1)([raw_seq, feat_seq])\n",
    "    projection = layers.Dense(dim, activation=\"linear\")(fusion)\n",
    "\n",
    "    # --- Bloques Transformer ---\n",
    "    def transformer_encoder_block(seq_input, key_dim, num_heads, dropout_rate):\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(seq_input)\n",
    "        x = layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim, dropout=dropout_rate)(x, x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        res = x + seq_input\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "        x = layers.Dense(key_dim * 4, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        x = layers.Dense(key_dim)(x)\n",
    "        return x + res\n",
    "\n",
    "    z = transformer_encoder_block(projection, dim, heads, dp)\n",
    "    z = transformer_encoder_block(z, dim, heads, dp)\n",
    "\n",
    "    # --- Clasificador ---\n",
    "    z = layers.GlobalAveragePooling1D()(z)\n",
    "    z = layers.Dropout(dp)(z)\n",
    "    z = layers.Dense(128, activation=\"relu\")(z)\n",
    "    z = layers.Dropout(dp)(z)\n",
    "    out = layers.Dense(n_cls, activation=\"softmax\", name=\"output\")(z)\n",
    "    \n",
    "    model = models.Model(inputs=[in_raw, in_feat], outputs=out, name=\"HyT-Net_Propuesto\")\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# ---------- 6. CALLBACKS  & EPOCHS -------------------------------------------\n",
    "def cb(model_name):\n",
    "    ts= datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    ck=os.path.join(MODELS_DIR,f\"{model_name}_{ts}.keras\")\n",
    "    return [\n",
    "        EarlyStopping(monitor=\"val_loss\",patience=15,restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor=\"val_loss\",factor=.5,patience=5,min_lr=1e-6),\n",
    "        ModelCheckpoint(ck,monitor=\"val_accuracy\",save_best_only=True,verbose=0),\n",
    "        TensorBoard(log_dir=os.path.join(RUNS_DIR,f\"{model_name}_{ts}\"))\n",
    "    ]\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "# ---------- 7. TRAIN ----------------------------------------------------------\n",
    "# models_to_train=[\n",
    "#     (\"DualStr\"   , build_dualstream(RAW_SHAPE,feat_dim,T_SUBWIN,NUM_CLASSES),True,  EPOCHS,  train_ds_h, val_ds_h),\n",
    "#     (\"SOTA_Trans\", build_sota   (RAW_SHAPE,feat_dim,T_SUBWIN,NUM_CLASSES), True,  EPOCHS,   train_ds_h, val_ds_h),\n",
    "#     (\"Hybrid_A2\" , build_hybrid_v2(RAW_SHAPE,feat_dim,T_SUBWIN,NUM_CLASSES), True,  EPOCHS, train_ds_h, val_ds_h),\n",
    "#     (\"EMGHand\"   , build_emghandnet(RAW_SHAPE,T_SUBWIN,NUM_CLASSES),        False, EPOCHS,  train_ds_raw,val_ds_raw),\n",
    "# ]\n",
    "\n",
    "models_to_train=[\n",
    "    (\"DualStr_Adaptado\", build_dualstream_adaptado(RAW_SHAPE, feat_dim, T_SUBWIN, NUM_CLASSES), True, EPOCHS, train_ds_h, val_ds_h),\n",
    "    (\"DualStr_Original\", build_dualstream_original(RAW_SHAPE, feat_dim, T_SUBWIN, NUM_CLASSES), True, EPOCHS, train_ds_h, val_ds_h),\n",
    "    (\"EMGHandNet_Adaptado\", build_emghandnet(RAW_SHAPE, T_SUBWIN, NUM_CLASSES), False, EPOCHS, train_ds_raw, val_ds_raw),\n",
    "    (\"EMGHandNet_Original\", build_emghandnet_original(RAW_SHAPE, T_SUBWIN, NUM_CLASSES), False, EPOCHS, train_ds_raw, val_ds_raw),\n",
    "    (\"HyT-Net_Propuesto\", build_hyt_net_propuesto(RAW_SHAPE, feat_dim, T_SUBWIN, NUM_CLASSES), True, EPOCHS, train_ds_h, val_ds_h),\n",
    "    # Modelos antiguos (opcional):\n",
    "    (\"DualStr_Adaptado_v1\"   , build_dualstream(RAW_SHAPE,feat_dim,T_SUBWIN,NUM_CLASSES),True,  EPOCHS,  train_ds_h, val_ds_h),\n",
    "    (\"SOTA_Trans\", build_sota   (RAW_SHAPE,feat_dim,T_SUBWIN,NUM_CLASSES), True,  EPOCHS,   train_ds_h, val_ds_h),\n",
    "    (\"Hybrid_A2\" , build_hybrid_v2(RAW_SHAPE,feat_dim,T_SUBWIN,NUM_CLASSES), True,  EPOCHS, train_ds_h, val_ds_h),\n",
    "    (\"EMGHand_Adaptado_v1\"   , build_emghandnet(RAW_SHAPE,T_SUBWIN,NUM_CLASSES),        False, EPOCHS,  train_ds_raw,val_ds_raw),\n",
    "]\n",
    "\n",
    "# ---------- EXTRA: REPORTE DE PARÁMETROS -------------------------------------\n",
    "def print_model_params(models_spec): # Changed parameter name for clarity\n",
    "    \"\"\"\n",
    "    Imprime nº de parámetros y tamaño aprox. en memoria para cada modelo.\n",
    "    Además, genera y guarda la imagen de la arquitectura del modelo.\n",
    "    \"\"\"\n",
    "    print(\"\\n🧮   Parámetros por modelo y diagramas de arquitectura\")\n",
    "    for name, build_fn, uses_feat in models_spec: # Iterate through the models_spec\n",
    "        # Instantiate the model to get its parameters and plot it\n",
    "        # We need to pass the correct arguments to the build_fn\n",
    "        # This assumes RAW_SHAPE, feat_dim, T_SUBWIN, NUM_CLASSES are globally accessible or passed\n",
    "        try:\n",
    "            if uses_feat:\n",
    "                model = build_fn(RAW_SHAPE, feat_dim, T_SUBWIN, NUM_CLASSES)\n",
    "            else:\n",
    "                model = build_fn(RAW_SHAPE, T_SUBWIN, NUM_CLASSES)\n",
    "            \n",
    "            params = model.count_params()\n",
    "            size_mb = params * 4 / (1024 ** 2)          # 4 bytes por parámetro fp32\n",
    "            print(f\"{name:25s}: {params:10,}   (~{size_mb:.2f} MB)\")\n",
    "\n",
    "            # Generate and save the model plot\n",
    "            plot_path = PLOTS_DIR / f\"{name}_architecture.png\"\n",
    "            plot_model(model, to_file=plot_path, show_shapes=True, show_layer_names=True, dpi=96)\n",
    "            print(f\"      Diagrama guardado en: {plot_path}\")\n",
    "            tf.keras.backend.clear_session() # Clear session after plotting\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error al procesar el modelo {name}: {e}\")\n",
    "            print(\"   Asegúrate de que RAW_SHAPE, feat_dim, T_SUBWIN, NUM_CLASSES estén definidos correctamente.\")\n",
    "\n",
    "\n",
    "# Llama a la función para ver el reporte\n",
    "print_model_params(models_to_train)\n",
    "\n",
    "# =============================================================================\n",
    "# cv_pipeline.py · 10‑Fold CV + Resumable Training for Ninapro‑DB1\n",
    "# Israel Huentecura ✨ · Mayo 2025\n",
    "# =============================================================================\n",
    "import os, json, datetime as dt, numpy as np, pandas as pd, tensorflow as tf\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# ------------------------------------------------------------------------- #\n",
    "# 0️⃣  RUTAS Y CONSTANTES GLOBALES\n",
    "# ------------------------------------------------------------------------- #\n",
    "SEED        = 42\n",
    "N_FOLDS     = 10\n",
    "EPOCHS      = 100\n",
    "BATCH_SIZE  = 128\n",
    "\n",
    "RUNS_DIR    = Path(\"runs\")\n",
    "MODELS_DIR  = Path(\"models\")\n",
    "BACKUP_DIR  = RUNS_DIR / \"_backup\"          # aquí se guardan estados por batch\n",
    "STATS_FILE  = RUNS_DIR / \"cv_progress.json\" # bitácora para saltar folds/‑modelos\n",
    "\n",
    "for d in (RUNS_DIR, MODELS_DIR, BACKUP_DIR):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------- #\n",
    "# 1️⃣  CARGA / SPLIT DE LOS ARRAYS EN MEMORIA\n",
    "# ------------------------------------------------------------------------- #\n",
    "def assemble_arrays_holdout():\n",
    "    \"\"\"\n",
    "    Construye tres juegos:\n",
    "      • (X_raw, F, y)           → train+val  (para la CV)\n",
    "      • (X_test_raw, F_test, y_test) → test  (hold‑out)\n",
    "    A partir de los arrays pre‑procesados que ya tengas en memoria\n",
    "    (X_tr_raw, F_tr, y_tr, val_X, val_feats, y_val, X_te_raw, F_te, y_te).\n",
    "    \"\"\"\n",
    "    g = globals()\n",
    "    # --- train+val (se usará dentro de los folds) -------------------------\n",
    "    tr_val_partsX = []; tr_val_partsF = []; tr_val_partsY = []\n",
    "\n",
    "    def _add_tv(x, f, y):\n",
    "        if x in g and y in g:                          # sólo si existen\n",
    "            tr_val_partsX.append(g[x]); tr_val_partsY.append(g[y])\n",
    "            if f in g: tr_val_partsF.append(g[f])\n",
    "\n",
    "    _add_tv('X_tr_raw', 'F_tr',  'y_tr')\n",
    "    _add_tv('val_X',    'val_feats', 'y_val')\n",
    "\n",
    "    if not tr_val_partsX:\n",
    "        raise RuntimeError(\"❌ No se encontraron arrays de train+val en memoria\")\n",
    "\n",
    "    global X_raw_all, F_all, y_all\n",
    "    X_raw_all = np.concatenate(tr_val_partsX, 0)\n",
    "    y_all     = np.concatenate(tr_val_partsY,  0)\n",
    "    F_all     = (np.concatenate(tr_val_partsF, 0)\n",
    "                 if tr_val_partsF else None)\n",
    "\n",
    "    # --- test -------------------------------------------------------------\n",
    "    global X_raw_test, F_test, y_test\n",
    "    if 'X_te_raw' not in g or 'y_te' not in g:\n",
    "        # → Si no tenías test pre‑calculado, házlo con train_test_split\n",
    "        #   (estratificado y sin reemplazo)\n",
    "        idx_trval = np.arange(len(y_all))\n",
    "        X_raw_all, X_raw_test, y_all, y_test, idx_trval, idx_test = \\\n",
    "            train_test_split(X_raw_all, y_all,\n",
    "                             np.arange(len(y_all)),\n",
    "                             test_size=TEST_PCT, random_state=SEED,\n",
    "                             stratify=np.argmax(y_all, 1))\n",
    "        if F_all is not None:\n",
    "            F_all, F_test = F_all[idx_trval], F_all[idx_test]\n",
    "        else:\n",
    "            F_test = None\n",
    "    else:\n",
    "        X_raw_test = g['X_te_raw']; y_test = g['y_te']\n",
    "        F_test     = g.get('F_te', None)\n",
    "\n",
    "    print(f\"✅  Train+Val: {X_raw_all.shape}  Test: {X_raw_test.shape}\")\n",
    "\n",
    "# ------------------------------------------------------------------------- #\n",
    "# 2️⃣  tf.data WRAPPER (sin cambios salvo docstring)\n",
    "# ------------------------------------------------------------------------- #\n",
    "def make_ds(x_raw, feats, y, uses_feat, shuffle):\n",
    "    \"\"\"\n",
    "    • uses_feat=True  → se crea dict{'raw':…, 'feat':…}\n",
    "    • uses_feat=False → sólo la rama raw\n",
    "    \"\"\"\n",
    "    if uses_feat and feats is None:\n",
    "        raise ValueError(\"El modelo requiere features pero feats=None\")\n",
    "    if uses_feat:\n",
    "        ds = tf.data.Dataset.from_tensor_slices(({\"raw\": x_raw, \"feat\": feats},\n",
    "                                                 y))\n",
    "    else:\n",
    "        ds = tf.data.Dataset.from_tensor_slices((x_raw, y))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(len(y), seed=SEED, reshuffle_each_iteration=True)\n",
    "    return ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# ------------------------------------------------------------------------- #\n",
    "# 3️⃣  CALLBACKS\n",
    "# ------------------------------------------------------------------------- #\n",
    "def make_callbacks(tag):\n",
    "    ck_path   = MODELS_DIR / f\"{tag}_BEST.keras\"\n",
    "    backup_to = BACKUP_DIR / tag\n",
    "    log_dir   = RUNS_DIR  / f\"{tag}_{dt.datetime.now():%Y%m%d-%H%M%S}\"\n",
    "\n",
    "    return [\n",
    "        tf.keras.callbacks.BackupAndRestore(\n",
    "            backup_to, delete_checkpoint=False),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            ck_path, monitor=\"val_accuracy\", save_best_only=True,\n",
    "            save_weights_only=False, verbose=0),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=15, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", patience=5, factor=0.5, min_lr=1e-6),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir=log_dir),\n",
    "    ]\n",
    "\n",
    "# ------------------------------------------------------------------------- #\n",
    "# 4️⃣  BITÁCORA DE CURSOS TERMINADOS\n",
    "# ------------------------------------------------------------------------- #\n",
    "STATS_FILE  = RUNS_DIR / \"cv_progress.json\"\n",
    "def load_stats():\n",
    "    return json.loads(STATS_FILE.read_text()) if STATS_FILE.exists() else {}\n",
    "\n",
    "def mark_done(tag, val_acc):\n",
    "    stats = load_stats()\n",
    "    stats[tag] = {\"val_acc\": float(val_acc)}\n",
    "    STATS_FILE.write_text(json.dumps(stats, indent=2))\n",
    "\n",
    "# ------------------------------------------------------------------------- #\n",
    "# 5️⃣  K‑FOLD  · GUARDA EL MEJOR CKPT POR ARQUITECTURA  🆕\n",
    "# ------------------------------------------------------------------------- #\n",
    "def run_kfold(models_spec):\n",
    "    \"\"\"\n",
    "    models_spec = [\n",
    "        (\"Nombre\", build_fn, uses_feat_bool),\n",
    "        ...\n",
    "    ]\n",
    "    Devuelve:\n",
    "      • df_folds    → métrica de cada (modelo, fold)\n",
    "      • summary_cv  → media ± std por modelo\n",
    "      • best_ckpts  → {'Nombre': {'ckpt': Path, 'val_acc':…, 'uses_feat':…}}\n",
    "    \"\"\"\n",
    "    skf        = StratifiedKFold(n_splits=N_FOLDS,\n",
    "                                 shuffle=True, random_state=SEED)\n",
    "    rows       = []\n",
    "    done       = load_stats()\n",
    "    best_ckpts = {name: {\"val_acc\": -np.inf, \"ckpt\": None,\n",
    "                         \"uses_feat\": uses_feat}\n",
    "                  for name, _, uses_feat in models_spec}\n",
    "\n",
    "    for fold, (tr, va) in enumerate(skf.split(X_raw_all,\n",
    "                                              np.argmax(y_all, 1)), 1):\n",
    "        X_tr, X_va   = X_raw_all[tr], X_raw_all[va]\n",
    "        y_tr, y_va   = y_all[tr],     y_all[va]\n",
    "        F_tr = F_all[tr] if F_all is not None else None\n",
    "        F_va = F_all[va] if F_all is not None else None\n",
    "\n",
    "        for name, build_fn, uses_feat in models_spec:\n",
    "            tag = f\"{name}_fold{fold}\"\n",
    "            if tag in done:\n",
    "                print(f\"⏭️  {tag} ya entrenado, se salta\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\n📚  Entrenando {tag}\")\n",
    "            # --- construcción del modelo ----------------------------------\n",
    "            if uses_feat:\n",
    "                model = build_fn(RAW_SHAPE, feat_dim,\n",
    "                                 T_SUBWIN, NUM_CLASSES)\n",
    "            else:\n",
    "                model = build_fn(RAW_SHAPE, T_SUBWIN, NUM_CLASSES)\n",
    "\n",
    "            train_ds = make_ds(X_tr, F_tr, y_tr, uses_feat, shuffle=True)\n",
    "            val_ds   = make_ds(X_va, F_va, y_va, uses_feat, shuffle=False)\n",
    "\n",
    "            history  = model.fit(\n",
    "                train_ds, validation_data=val_ds,\n",
    "                epochs=EPOCHS, callbacks=make_callbacks(tag), verbose=1).history\n",
    "            best_va = max(history[\"val_accuracy\"])\n",
    "            rows.append([name, fold, best_va])\n",
    "\n",
    "            # --- ¿Mejor ckpt de la arquitectura? -------------------------\n",
    "            ck_file = MODELS_DIR / f\"{tag}_BEST.keras\"\n",
    "            if best_va > best_ckpts[name][\"val_acc\"]:\n",
    "                best_ckpts[name][\"val_acc\"] = best_va\n",
    "                best_ckpts[name][\"ckpt\"]    = ck_file\n",
    "\n",
    "            mark_done(tag, best_va)\n",
    "            tf.keras.backend.clear_session()\n",
    "\n",
    "    df_folds = pd.DataFrame(rows, columns=[\"Model\", \"Fold\", \"Val_Acc\"])\n",
    "    summary  = df_folds.groupby(\"Model\").Val_Acc.agg(['mean','std']).round(4)\n",
    "\n",
    "    print(\"\\n📊  Resumen 10‑fold (Val_Acc)\")\n",
    "    print(summary)\n",
    "    return df_folds, summary, best_ckpts\n",
    "\n",
    "# ------------------------------------------------------------------------- #\n",
    "# 6️⃣  EVALUACIÓN FINAL EN HOLD‑OUT TEST  🆕\n",
    "# ------------------------------------------------------------------------- #\n",
    "def evaluate_on_test(best_ckpts):\n",
    "    \"\"\"\n",
    "    Carga el mejor checkpoint de cada arquitectura y lo evalúa sobre el test.\n",
    "    Devuelve df_test con columnas: Model · Test_Acc · Test_Loss\n",
    "    \"\"\"\n",
    "    test_results = []\n",
    "    for name, meta in best_ckpts.items():\n",
    "        ck = meta[\"ckpt\"]\n",
    "        if ck is None or not ck.exists():\n",
    "            print(f\"⚠️  {name}: no se encontró ckpt; se omite\")\n",
    "            continue\n",
    "        print(f\"🧪  Testing {name}  (ckpt={ck.name})\")\n",
    "        model = tf.keras.models.load_model(ck, compile=True)\n",
    "        test_ds = make_ds(X_raw_test, F_test, y_test,\n",
    "                          meta[\"uses_feat\"], shuffle=False)\n",
    "        loss, acc = model.evaluate(test_ds, verbose=0)\n",
    "        test_results.append([name, acc, loss])\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "    df_test = (pd.DataFrame(test_results,\n",
    "                            columns=[\"Model\", \"Test_Acc\", \"Test_Loss\"])\n",
    "               .sort_values(\"Test_Acc\", ascending=False)\n",
    "               .reset_index(drop=True))\n",
    "    print(\"\\n🎯  Rendimiento en HOLD‑OUT Test\")\n",
    "    print(df_test)\n",
    "    return df_test\n",
    "\n",
    "# ------------------------------------------------------------------------- #\n",
    "# 7️⃣  EJECUCIÓN PRINCIPAL (ejemplo)\n",
    "# ------------------------------------------------------------------------- #\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Ensambla arrays → genera train+val y test\n",
    "    assemble_arrays_holdout()\n",
    "\n",
    "    # 2. Catálogo de modelos (tus constructores sin tocar)\n",
    "    models_spec = [\n",
    "        (\"DualStr_Adaptado\",      build_dualstream_adaptado,  True),\n",
    "        (\"DualStr_Original\",      build_dualstream_original,  True),\n",
    "        (\"DualStr_Adaptado_v1\",   build_dualstream,           True),\n",
    "        (\"HyT_Net_v1\",            build_sota,                 True),\n",
    "        (\"Hybrid_A2\",             build_hybrid_v2,            True),\n",
    "        (\"EMGHandNet_Adaptado\",   build_emghandnet_adaptado,  False),\n",
    "        (\"EMGHandNet_Original\",   build_emghandnet_original,  False),\n",
    "        (\"EMGHand_Adaptado_v1\",   build_emghandnet,           False),\n",
    "        (\"HyT_Net_Propuesto_v2\",  build_hyt_net_propuesto,    True),\n",
    "    ]\n",
    "\n",
    "    # 3. 10‑fold CV\n",
    "    df_folds, df_summary, best_ckpts = run_kfold(models_spec)\n",
    "\n",
    "    # 4. Evaluación en test externo\n",
    "    df_test = evaluate_on_test(best_ckpts)\n",
    "\n",
    "    # 5. Guarda DataFrames de resultados\n",
    "    df_folds.to_csv(RUNS_DIR / \"folds_val_acc.csv\",    index=False)\n",
    "    df_summary.to_csv(RUNS_DIR / \"cv_summary.csv\")\n",
    "    df_test.to_csv(RUNS_DIR / \"test_summary.csv\",      index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b92243bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Assembled arrays → X_raw_all (236611, 5, 20, 10, 1) | F_all (236611, 5, 100) | y_all (236611, 12)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "run_kfold() got an unexpected keyword argument 'progress_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 64\u001b[0m\n\u001b[0;32m     50\u001b[0m assemble_full_arrays()               \u001b[38;5;66;03m# run once per session\u001b[39;00m\n\u001b[0;32m     52\u001b[0m models_spec \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     53\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDualStr_Adaptado\u001b[39m\u001b[38;5;124m\"\u001b[39m,      build_dualstream_adaptado,  \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     54\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDualStr_Original\u001b[39m\u001b[38;5;124m\"\u001b[39m,      build_dualstream_original,  \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyT_Net_Propuesto\u001b[39m\u001b[38;5;124m\"\u001b[39m,     build_hyt_net_propuesto,    \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     62\u001b[0m ]\n\u001b[1;32m---> 64\u001b[0m \u001b[43mrun_kfold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_raw_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_all\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m          \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m          \u001b[49m\u001b[43mprogress_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcv_progress.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m collect_best_checkpoints()            \u001b[38;5;66;03m# optional, after CV finishes\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: run_kfold() got an unexpected keyword argument 'progress_file'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Extension of existing EMG training pipeline to support **10-fold cross-validation with resumability**.\n",
    "\n",
    "🔄 **What’s new (v3)**\n",
    "-------------------------------------------------\n",
    "* **Automatic checkpoint collection** already handled by `ModelCheckpoint`.\n",
    "* Added **incremental persistence & resume**:\n",
    "  * Metrics for every *(model, fold)* are appended to `cv_progress.csv` **immediately after training**.\n",
    "  * If you rerun the script (e.g. after un corte de luz) it **skips** the folds that are already in the CSV and resumes where it left off.\n",
    "* Helper `collect_best_checkpoints()` remains to gather the *.keras* files once all folds are done.\n",
    "\n",
    "\"\"\"\n",
    "def assemble_full_arrays():\n",
    "    \"\"\"Concatenate the existing pre-processed splits into *X_raw_all*, *F_all*, *y_all*.\n",
    "\n",
    "    Looks for the following globals and concatenates them if present:\n",
    "        • X_tr_raw , F_tr , y_tr  (train)\n",
    "        • val_X    , val_feats , y_val  (validation)\n",
    "        • X_te_raw , F_te , y_te  (test)\n",
    "\n",
    "    Prints shapes once done. Call exactly once **before** `run_kfold()` if you\n",
    "    haven’t already defined *X_raw_all* / *F_all* / *y_all*.\n",
    "    \"\"\"\n",
    "    g = globals()\n",
    "    parts_raw, parts_feat, parts_y = [], [], []\n",
    "\n",
    "    def _add(raw_name, feat_name, y_name):\n",
    "        if raw_name in g and y_name in g:\n",
    "            parts_raw.append(g[raw_name])\n",
    "            parts_y.append(g[y_name])\n",
    "            if feat_name in g:\n",
    "                parts_feat.append(g[feat_name])\n",
    "\n",
    "    _add('X_tr_raw', 'F_tr', 'y_tr')\n",
    "    _add('val_X',    'val_feats', 'y_val')\n",
    "    _add('X_te_raw', 'F_te', 'y_te')\n",
    "\n",
    "    if not parts_raw:\n",
    "        raise RuntimeError(\"No pre-split arrays found. Define X_raw_all, F_all, y_all manually or ensure X_tr_raw / val_X / X_te_raw are in scope.\")\n",
    "\n",
    "    global X_raw_all, F_all, y_all\n",
    "    X_raw_all = np.concatenate(parts_raw, axis=0)\n",
    "    y_all     = np.concatenate(parts_y,   axis=0)\n",
    "    F_all     = np.concatenate(parts_feat, axis=0) if parts_feat else None\n",
    "\n",
    "    print(f\"✅  Assembled arrays → X_raw_all {X_raw_all.shape} | \"\n",
    "          f\"F_all {'None' if F_all is None else F_all.shape} | \"\n",
    "          f\"y_all {y_all.shape}\")\n",
    "    \n",
    "assemble_full_arrays()               # run once per session\n",
    "\n",
    "models_spec = [\n",
    "    (\"DualStr_Adaptado\",      build_dualstream_adaptado,  True),\n",
    "    (\"DualStr_Original\",      build_dualstream_original,  True),\n",
    "    (\"DualStr_Adaptado_v1\",   build_dualstream,           True),\n",
    "    (\"SOTA_Trans\",            build_sota,                 True),\n",
    "    (\"Hybrid_A2\",             build_hybrid_v2,            True),\n",
    "    (\"EMGHandNet_Adaptado\",   build_emghandnet_adaptado,  False),\n",
    "    (\"EMGHandNet_Original\",   build_emghandnet_original,  False),\n",
    "    (\"EMGHand_Adaptado_v1\",   build_emghandnet,           False),\n",
    "    (\"HyT_Net_Propuesto\",     build_hyt_net_propuesto,    True),\n",
    "]\n",
    "\n",
    "run_kfold(models_spec, X_raw_all, F_all, y_all,\n",
    "          n_splits=10, batch=128, epochs=EPOCHS,\n",
    "          progress_file=\"cv_progress.csv\")\n",
    "\n",
    "collect_best_checkpoints()            # optional, after CV finishes\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 🧰  DATA HELPERS\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def assemble_full_arrays():\n",
    "    \"\"\"Concatenate the existing pre-processed splits into *X_raw_all*, *F_all*, *y_all*.\"\"\"\n",
    "    g = globals()\n",
    "    parts_raw, parts_feat, parts_y = [], [], []\n",
    "\n",
    "    def _add(raw_name, feat_name, y_name):\n",
    "        if raw_name in g and y_name in g:\n",
    "            parts_raw.append(g[raw_name])\n",
    "            parts_y.append(g[y_name])\n",
    "            if feat_name in g:\n",
    "                parts_feat.append(g[feat_name])\n",
    "\n",
    "    _add('X_tr_raw', 'F_tr', 'y_tr')\n",
    "    _add('val_X',    'val_feats', 'y_val')\n",
    "    _add('X_te_raw', 'F_te', 'y_te')\n",
    "\n",
    "    if not parts_raw:\n",
    "        raise RuntimeError(\"No pre-split arrays found. Define the raw/feat/label arrays or ensure X_tr_raw / val_X / X_te_raw are in scope.\")\n",
    "\n",
    "    global X_raw_all, F_all, y_all\n",
    "    X_raw_all = np.concatenate(parts_raw, axis=0)\n",
    "    y_all     = np.concatenate(parts_y,   axis=0)\n",
    "    F_all     = np.concatenate(parts_feat, axis=0) if parts_feat else None\n",
    "\n",
    "    print(f\"✅  Assembled arrays → X_raw_all {X_raw_all.shape} | \"\n",
    "          f\"F_all {'None' if F_all is None else F_all.shape} | \"\n",
    "          f\"y_all {y_all.shape}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 🏗️  DATASET CONSTRUCTION\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def make_tf_dataset(x_raw, f, y, uses_feat, batch=64, shuffle=True):\n",
    "    if uses_feat and f is None:\n",
    "        raise ValueError(\"Feature array is None but the model expects features (uses_feat=True).\")\n",
    "\n",
    "    if uses_feat:\n",
    "        ds = tf.data.Dataset.from_tensor_slices(({\"raw\": x_raw, \"feat\": f}, y))\n",
    "    else:\n",
    "        ds = tf.data.Dataset.from_tensor_slices((x_raw, y))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(y), seed=SEED)\n",
    "    return ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 🔁  K-FOLD CROSS-VALIDATION WITH RESUME\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def run_kfold(models_spec,\n",
    "              X_raw_all,\n",
    "              F_all,\n",
    "              y_all,\n",
    "              *,\n",
    "              n_splits=10,\n",
    "              batch=64,\n",
    "              epochs=EPOCHS,\n",
    "              progress_file=\"cv_progress.csv\"):\n",
    "    \"\"\"Train each model with Stratified K-fold CV and **resume** if interrupted.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    models_spec : list of (name, builder_fn, uses_feat)\n",
    "    progress_file : str\n",
    "        CSV file that stores completed (model, fold) pairs with their metrics.\n",
    "    \"\"\"\n",
    "    # Load existing progress ---------------------------------------------------\n",
    "    if os.path.exists(progress_file):\n",
    "        df_prog = pd.read_csv(progress_file)\n",
    "        print(f\"🔄  Resuming from {progress_file} (completed rows = {len(df_prog)})\")\n",
    "    else:\n",
    "        df_prog = pd.DataFrame(columns=['Model', 'Fold', 'Val_Acc', 'Val_Loss', 'Best_Epoch'])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    new_rows = []\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(skf.split(X_raw_all, np.argmax(y_all, axis=1)), start=1):\n",
    "        print(f\"\\n📂  Fold {fold}/{n_splits}: train={len(tr_idx)}  val={len(val_idx)}\")\n",
    "\n",
    "        X_tr_raw, X_val_raw = X_raw_all[tr_idx], X_raw_all[val_idx]\n",
    "        y_tr, y_val         = y_all[tr_idx],   y_all[val_idx]\n",
    "        F_tr = F_all[tr_idx] if F_all is not None else None\n",
    "        F_val = F_all[val_idx] if F_all is not None else None\n",
    "\n",
    "        for name, build_fn, uses_feat in models_spec:\n",
    "            if ((df_prog['Model'] == name) & (df_prog['Fold'] == fold)).any():\n",
    "                print(f\"⏩  Skipping {name} (fold {fold}) — already completed.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\n─── Training {name} (fold {fold}) ───\")\n",
    "\n",
    "            model = (build_fn(RAW_SHAPE, feat_dim, T_SUBWIN, NUM_CLASSES)\n",
    "                     if uses_feat else build_fn(RAW_SHAPE, T_SUBWIN, NUM_CLASSES))\n",
    "\n",
    "            train_ds = make_tf_dataset(X_tr_raw, F_tr, y_tr, uses_feat, batch, shuffle=True)\n",
    "            val_ds   = make_tf_dataset(X_val_raw, F_val, y_val, uses_feat, batch, shuffle=False)\n",
    "\n",
    "            cbs = cb(f\"{name}_fold{fold}\")\n",
    "\n",
    "            hist = model.fit(train_ds,\n",
    "                             validation_data=val_ds,\n",
    "                             epochs=epochs,\n",
    "                             callbacks=cbs,\n",
    "                             verbose=1).history\n",
    "\n",
    "            best_val_acc  = max(hist['val_accuracy'])\n",
    "            best_val_loss = min(hist['val_loss'])\n",
    "            best_epoch    = int(np.argmin(hist['val_loss']) + 1)\n",
    "\n",
    "            row = {\"Model\": name, \"Fold\": fold, \"Val_Acc\": best_val_acc,\n",
    "                   \"Val_Loss\": best_val_loss, \"Best_Epoch\": best_epoch}\n",
    "            df_prog = pd.concat([df_prog, pd.DataFrame([row])], ignore_index=True)\n",
    "            df_prog.to_csv(progress_file, index=False)\n",
    "            print(f\"💾  Progress saved → {progress_file}\")\n",
    "\n",
    "            new_rows.append(row)\n",
    "            tf.keras.backend.clear_session()\n",
    "\n",
    "    # summary -----------------------------------------------------------------\n",
    "    if not df_prog.empty:\n",
    "        summary = df_prog.groupby('Model').agg(Mean_Val_Acc=('Val_Acc', 'mean'),\n",
    "                                               Std_Val_Acc=('Val_Acc', 'std'))\n",
    "        print(\"\\n📊  Cross-validation summary (Val_Acc)\")\n",
    "        print(summary.round(4))\n",
    "        return df_prog, summary\n",
    "    else:\n",
    "        print(\"⚠️  Nothing trained.\")\n",
    "        return df_prog, None\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 💾  COLLECT & SAVE BEST MODELS FOR FUTURE FINE-TUNING\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def collect_best_checkpoints(src_dir=MODELS_DIR, dest_dir=\"fine_tune_models\"):\n",
    "    \"\"\"Copy all *.keras checkpoints saved during CV to *dest_dir* for later fine-tuning.\"\"\"\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "    ckpts = sorted(glob.glob(os.path.join(src_dir, \"*.keras\")))\n",
    "    for ck in ckpts:\n",
    "        tgt = os.path.join(dest_dir, os.path.basename(ck))\n",
    "        shutil.copy2(ck, tgt)\n",
    "        print(f\"📦  {os.path.basename(ck)} → {dest_dir}\")\n",
    "    print(f\"✅  Copied {len(ckpts)} models ready for fine-tuning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9669a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 💾  COLLECT & SAVE BEST MODELS FOR FUTURE FINE-TUNING\n",
    "import glob, shutil, os\n",
    "\n",
    "def collect_best_checkpoints(src_dir=MODELS_DIR, dest_dir=\"fine_tune_models\"):\n",
    "    \"\"\"Copy all *.keras checkpoints saved during CV to *dest_dir* for later fine-tuning.\"\"\"\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "    ckpts = sorted(glob.glob(os.path.join(src_dir, \"*.keras\")))\n",
    "    for ck in ckpts:\n",
    "        tgt = os.path.join(dest_dir, os.path.basename(ck))\n",
    "        shutil.copy2(ck, tgt)\n",
    "        print(f\"📦  {os.path.basename(ck)} → {dest_dir}\")\n",
    "    print(f\"✅  Copied {len(ckpts)} models ready for fine-tuning.\")\n",
    "collect_best_checkpoints()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b30c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################ DualStr_Adaptado – 10-fold CV ################\n",
      "\n",
      "── Fold 1/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 12s 10ms/step - loss: 1.4531 - accuracy: 0.5040 - val_loss: 0.8733 - val_accuracy: 0.7124 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.8599 - accuracy: 0.7094 - val_loss: 0.5673 - val_accuracy: 0.8126 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.6491 - accuracy: 0.7803 - val_loss: 0.4371 - val_accuracy: 0.8583 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.5336 - accuracy: 0.8169 - val_loss: 0.3605 - val_accuracy: 0.8812 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.4568 - accuracy: 0.8432 - val_loss: 0.2949 - val_accuracy: 0.9035 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.4007 - accuracy: 0.8619 - val_loss: 0.2677 - val_accuracy: 0.9134 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.3613 - accuracy: 0.8746 - val_loss: 0.2202 - val_accuracy: 0.9287 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.3262 - accuracy: 0.8869 - val_loss: 0.2048 - val_accuracy: 0.9325 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.3034 - accuracy: 0.8956 - val_loss: 0.1833 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.2813 - accuracy: 0.9013 - val_loss: 0.1778 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.2607 - accuracy: 0.9092 - val_loss: 0.1538 - val_accuracy: 0.9481 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.2481 - accuracy: 0.9130 - val_loss: 0.1425 - val_accuracy: 0.9516 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.2350 - accuracy: 0.9184 - val_loss: 0.1272 - val_accuracy: 0.9592 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.2253 - accuracy: 0.9205 - val_loss: 0.1235 - val_accuracy: 0.9589 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.2135 - accuracy: 0.9249 - val_loss: 0.1145 - val_accuracy: 0.9626 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.2029 - accuracy: 0.9283 - val_loss: 0.1113 - val_accuracy: 0.9624 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1971 - accuracy: 0.9317 - val_loss: 0.1005 - val_accuracy: 0.9660 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1923 - accuracy: 0.9321 - val_loss: 0.1009 - val_accuracy: 0.9684 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1861 - accuracy: 0.9346 - val_loss: 0.0965 - val_accuracy: 0.9675 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1791 - accuracy: 0.9366 - val_loss: 0.0907 - val_accuracy: 0.9695 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1739 - accuracy: 0.9380 - val_loss: 0.0869 - val_accuracy: 0.9729 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1679 - accuracy: 0.9410 - val_loss: 0.0865 - val_accuracy: 0.9708 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1644 - accuracy: 0.9418 - val_loss: 0.0833 - val_accuracy: 0.9732 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1604 - accuracy: 0.9430 - val_loss: 0.0871 - val_accuracy: 0.9716 - lr: 0.0010\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1591 - accuracy: 0.9441 - val_loss: 0.0805 - val_accuracy: 0.9743 - lr: 0.0010\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1516 - accuracy: 0.9463 - val_loss: 0.0776 - val_accuracy: 0.9722 - lr: 0.0010\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1516 - accuracy: 0.9461 - val_loss: 0.0765 - val_accuracy: 0.9745 - lr: 0.0010\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1470 - accuracy: 0.9478 - val_loss: 0.0672 - val_accuracy: 0.9793 - lr: 0.0010\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1443 - accuracy: 0.9485 - val_loss: 0.0714 - val_accuracy: 0.9753 - lr: 0.0010\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1422 - accuracy: 0.9494 - val_loss: 0.0649 - val_accuracy: 0.9783 - lr: 0.0010\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1407 - accuracy: 0.9503 - val_loss: 0.0704 - val_accuracy: 0.9759 - lr: 0.0010\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1355 - accuracy: 0.9517 - val_loss: 0.0688 - val_accuracy: 0.9765 - lr: 0.0010\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1349 - accuracy: 0.9519 - val_loss: 0.0642 - val_accuracy: 0.9782 - lr: 0.0010\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1322 - accuracy: 0.9530 - val_loss: 0.0627 - val_accuracy: 0.9774 - lr: 0.0010\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1301 - accuracy: 0.9539 - val_loss: 0.0654 - val_accuracy: 0.9787 - lr: 0.0010\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1298 - accuracy: 0.9540 - val_loss: 0.0590 - val_accuracy: 0.9806 - lr: 0.0010\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1285 - accuracy: 0.9541 - val_loss: 0.0608 - val_accuracy: 0.9805 - lr: 0.0010\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1270 - accuracy: 0.9557 - val_loss: 0.0592 - val_accuracy: 0.9806 - lr: 0.0010\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1237 - accuracy: 0.9562 - val_loss: 0.0626 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0939 - accuracy: 0.9673 - val_loss: 0.0440 - val_accuracy: 0.9867 - lr: 5.0000e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0867 - accuracy: 0.9692 - val_loss: 0.0419 - val_accuracy: 0.9874 - lr: 5.0000e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0855 - accuracy: 0.9698 - val_loss: 0.0406 - val_accuracy: 0.9867 - lr: 5.0000e-04\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0843 - accuracy: 0.9707 - val_loss: 0.0419 - val_accuracy: 0.9865 - lr: 5.0000e-04\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0833 - accuracy: 0.9704 - val_loss: 0.0337 - val_accuracy: 0.9899 - lr: 5.0000e-04\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0816 - accuracy: 0.9707 - val_loss: 0.0358 - val_accuracy: 0.9897 - lr: 5.0000e-04\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0808 - accuracy: 0.9712 - val_loss: 0.0346 - val_accuracy: 0.9896 - lr: 5.0000e-04\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0788 - accuracy: 0.9719 - val_loss: 0.0381 - val_accuracy: 0.9877 - lr: 5.0000e-04\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0688 - accuracy: 0.9760 - val_loss: 0.0309 - val_accuracy: 0.9902 - lr: 2.5000e-04\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0638 - accuracy: 0.9779 - val_loss: 0.0297 - val_accuracy: 0.9903 - lr: 2.5000e-04\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0643 - accuracy: 0.9778 - val_loss: 0.0299 - val_accuracy: 0.9906 - lr: 2.5000e-04\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0614 - accuracy: 0.9788 - val_loss: 0.0286 - val_accuracy: 0.9916 - lr: 2.5000e-04\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0600 - accuracy: 0.9792 - val_loss: 0.0307 - val_accuracy: 0.9902 - lr: 2.5000e-04\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0610 - accuracy: 0.9787 - val_loss: 0.0295 - val_accuracy: 0.9900 - lr: 2.5000e-04\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0620 - accuracy: 0.9787 - val_loss: 0.0264 - val_accuracy: 0.9913 - lr: 2.5000e-04\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0591 - accuracy: 0.9796 - val_loss: 0.0278 - val_accuracy: 0.9911 - lr: 2.5000e-04\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0588 - accuracy: 0.9797 - val_loss: 0.0272 - val_accuracy: 0.9909 - lr: 2.5000e-04\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0580 - accuracy: 0.9802 - val_loss: 0.0288 - val_accuracy: 0.9911 - lr: 2.5000e-04\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0539 - accuracy: 0.9809 - val_loss: 0.0254 - val_accuracy: 0.9917 - lr: 1.2500e-04\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0516 - accuracy: 0.9822 - val_loss: 0.0247 - val_accuracy: 0.9922 - lr: 1.2500e-04\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0521 - accuracy: 0.9822 - val_loss: 0.0254 - val_accuracy: 0.9924 - lr: 1.2500e-04\n",
      "1033/1033 [==============================] - 4s 4ms/step - loss: 0.0242 - accuracy: 0.9924\n",
      "\n",
      "── Fold 2/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 12s 11ms/step - loss: 1.4434 - accuracy: 0.5086 - val_loss: 0.8515 - val_accuracy: 0.7187 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.8510 - accuracy: 0.7125 - val_loss: 0.5508 - val_accuracy: 0.8180 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.6427 - accuracy: 0.7839 - val_loss: 0.4260 - val_accuracy: 0.8542 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.5266 - accuracy: 0.8218 - val_loss: 0.3440 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.4526 - accuracy: 0.8466 - val_loss: 0.2952 - val_accuracy: 0.9002 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.3974 - accuracy: 0.8634 - val_loss: 0.2492 - val_accuracy: 0.9154 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.3561 - accuracy: 0.8767 - val_loss: 0.2163 - val_accuracy: 0.9257 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.3262 - accuracy: 0.8864 - val_loss: 0.1917 - val_accuracy: 0.9322 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2994 - accuracy: 0.8957 - val_loss: 0.1779 - val_accuracy: 0.9399 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2790 - accuracy: 0.9028 - val_loss: 0.1652 - val_accuracy: 0.9430 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.2587 - accuracy: 0.9098 - val_loss: 0.1579 - val_accuracy: 0.9453 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.2471 - accuracy: 0.9133 - val_loss: 0.1410 - val_accuracy: 0.9520 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.2348 - accuracy: 0.9177 - val_loss: 0.1259 - val_accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.2216 - accuracy: 0.9219 - val_loss: 0.1173 - val_accuracy: 0.9600 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.2114 - accuracy: 0.9260 - val_loss: 0.1113 - val_accuracy: 0.9613 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.2022 - accuracy: 0.9297 - val_loss: 0.1029 - val_accuracy: 0.9645 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1946 - accuracy: 0.9307 - val_loss: 0.1042 - val_accuracy: 0.9637 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1900 - accuracy: 0.9329 - val_loss: 0.0937 - val_accuracy: 0.9675 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1804 - accuracy: 0.9363 - val_loss: 0.0973 - val_accuracy: 0.9666 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1788 - accuracy: 0.9366 - val_loss: 0.0902 - val_accuracy: 0.9683 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1737 - accuracy: 0.9382 - val_loss: 0.0964 - val_accuracy: 0.9667 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1674 - accuracy: 0.9409 - val_loss: 0.0905 - val_accuracy: 0.9690 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1615 - accuracy: 0.9425 - val_loss: 0.0784 - val_accuracy: 0.9736 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1593 - accuracy: 0.9434 - val_loss: 0.0758 - val_accuracy: 0.9728 - lr: 0.0010\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1559 - accuracy: 0.9447 - val_loss: 0.0719 - val_accuracy: 0.9747 - lr: 0.0010\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1542 - accuracy: 0.9453 - val_loss: 0.0786 - val_accuracy: 0.9736 - lr: 0.0010\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1496 - accuracy: 0.9467 - val_loss: 0.0725 - val_accuracy: 0.9759 - lr: 0.0010\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1482 - accuracy: 0.9475 - val_loss: 0.0752 - val_accuracy: 0.9732 - lr: 0.0010\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1118 - accuracy: 0.9610 - val_loss: 0.0497 - val_accuracy: 0.9841 - lr: 5.0000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1056 - accuracy: 0.9629 - val_loss: 0.0484 - val_accuracy: 0.9839 - lr: 5.0000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1019 - accuracy: 0.9642 - val_loss: 0.0467 - val_accuracy: 0.9837 - lr: 5.0000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0997 - accuracy: 0.9650 - val_loss: 0.0440 - val_accuracy: 0.9855 - lr: 5.0000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0997 - accuracy: 0.9647 - val_loss: 0.0437 - val_accuracy: 0.9855 - lr: 5.0000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0962 - accuracy: 0.9666 - val_loss: 0.0424 - val_accuracy: 0.9864 - lr: 5.0000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0941 - accuracy: 0.9672 - val_loss: 0.0386 - val_accuracy: 0.9876 - lr: 5.0000e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0939 - accuracy: 0.9669 - val_loss: 0.0363 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0911 - accuracy: 0.9677 - val_loss: 0.0380 - val_accuracy: 0.9869 - lr: 5.0000e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0919 - accuracy: 0.9674 - val_loss: 0.0396 - val_accuracy: 0.9878 - lr: 5.0000e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0885 - accuracy: 0.9695 - val_loss: 0.0393 - val_accuracy: 0.9868 - lr: 5.0000e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0766 - accuracy: 0.9736 - val_loss: 0.0315 - val_accuracy: 0.9900 - lr: 2.5000e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0738 - accuracy: 0.9744 - val_loss: 0.0301 - val_accuracy: 0.9902 - lr: 2.5000e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0705 - accuracy: 0.9756 - val_loss: 0.0300 - val_accuracy: 0.9902 - lr: 2.5000e-04\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0708 - accuracy: 0.9759 - val_loss: 0.0292 - val_accuracy: 0.9905 - lr: 2.5000e-04\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0699 - accuracy: 0.9757 - val_loss: 0.0292 - val_accuracy: 0.9913 - lr: 2.5000e-04\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0696 - accuracy: 0.9759 - val_loss: 0.0274 - val_accuracy: 0.9915 - lr: 2.5000e-04\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0674 - accuracy: 0.9770 - val_loss: 0.0275 - val_accuracy: 0.9905 - lr: 2.5000e-04\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0673 - accuracy: 0.9765 - val_loss: 0.0277 - val_accuracy: 0.9896 - lr: 2.5000e-04\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0673 - accuracy: 0.9761 - val_loss: 0.0280 - val_accuracy: 0.9906 - lr: 2.5000e-04\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0607 - accuracy: 0.9789 - val_loss: 0.0237 - val_accuracy: 0.9925 - lr: 1.2500e-04\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0583 - accuracy: 0.9803 - val_loss: 0.0246 - val_accuracy: 0.9924 - lr: 1.2500e-04\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0585 - accuracy: 0.9802 - val_loss: 0.0248 - val_accuracy: 0.9921 - lr: 1.2500e-04\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0588 - accuracy: 0.9799 - val_loss: 0.0246 - val_accuracy: 0.9920 - lr: 1.2500e-04\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0563 - accuracy: 0.9812 - val_loss: 0.0227 - val_accuracy: 0.9926 - lr: 6.2500e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0542 - accuracy: 0.9816 - val_loss: 0.0233 - val_accuracy: 0.9930 - lr: 6.2500e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0538 - accuracy: 0.9819 - val_loss: 0.0232 - val_accuracy: 0.9927 - lr: 6.2500e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0539 - accuracy: 0.9817 - val_loss: 0.0234 - val_accuracy: 0.9928 - lr: 6.2500e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0519 - accuracy: 0.9830 - val_loss: 0.0230 - val_accuracy: 0.9927 - lr: 3.1250e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0510 - accuracy: 0.9826 - val_loss: 0.0221 - val_accuracy: 0.9933 - lr: 3.1250e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0514 - accuracy: 0.9828 - val_loss: 0.0219 - val_accuracy: 0.9931 - lr: 3.1250e-05\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0507 - accuracy: 0.9834 - val_loss: 0.0226 - val_accuracy: 0.9927 - lr: 3.1250e-05\n",
      "1033/1033 [==============================] - 5s 5ms/step - loss: 0.0238 - accuracy: 0.9929\n",
      "\n",
      "── Fold 3/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 12s 10ms/step - loss: 1.4616 - accuracy: 0.5020 - val_loss: 0.8577 - val_accuracy: 0.7198 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.8567 - accuracy: 0.7119 - val_loss: 0.5589 - val_accuracy: 0.8177 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.6385 - accuracy: 0.7848 - val_loss: 0.4279 - val_accuracy: 0.8558 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.5256 - accuracy: 0.8222 - val_loss: 0.3384 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.4468 - accuracy: 0.8472 - val_loss: 0.2750 - val_accuracy: 0.9073 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.3934 - accuracy: 0.8639 - val_loss: 0.2365 - val_accuracy: 0.9195 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.3527 - accuracy: 0.8787 - val_loss: 0.2094 - val_accuracy: 0.9295 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.3212 - accuracy: 0.8881 - val_loss: 0.1934 - val_accuracy: 0.9354 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2926 - accuracy: 0.8978 - val_loss: 0.1791 - val_accuracy: 0.9387 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2710 - accuracy: 0.9053 - val_loss: 0.1601 - val_accuracy: 0.9473 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.2555 - accuracy: 0.9108 - val_loss: 0.1495 - val_accuracy: 0.9511 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.2419 - accuracy: 0.9155 - val_loss: 0.1425 - val_accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.2258 - accuracy: 0.9213 - val_loss: 0.1342 - val_accuracy: 0.9537 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2158 - accuracy: 0.9244 - val_loss: 0.1266 - val_accuracy: 0.9566 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2083 - accuracy: 0.9261 - val_loss: 0.1154 - val_accuracy: 0.9623 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1971 - accuracy: 0.9308 - val_loss: 0.1052 - val_accuracy: 0.9659 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1903 - accuracy: 0.9331 - val_loss: 0.1026 - val_accuracy: 0.9654 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1833 - accuracy: 0.9351 - val_loss: 0.0952 - val_accuracy: 0.9669 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1741 - accuracy: 0.9383 - val_loss: 0.0986 - val_accuracy: 0.9666 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1692 - accuracy: 0.9393 - val_loss: 0.0864 - val_accuracy: 0.9690 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1652 - accuracy: 0.9412 - val_loss: 0.0848 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1604 - accuracy: 0.9433 - val_loss: 0.0770 - val_accuracy: 0.9731 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1580 - accuracy: 0.9437 - val_loss: 0.0794 - val_accuracy: 0.9739 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1516 - accuracy: 0.9459 - val_loss: 0.0773 - val_accuracy: 0.9735 - lr: 0.0010\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1501 - accuracy: 0.9470 - val_loss: 0.0727 - val_accuracy: 0.9737 - lr: 0.0010\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1465 - accuracy: 0.9486 - val_loss: 0.0749 - val_accuracy: 0.9761 - lr: 0.0010\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1438 - accuracy: 0.9495 - val_loss: 0.0709 - val_accuracy: 0.9755 - lr: 0.0010\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1406 - accuracy: 0.9503 - val_loss: 0.0684 - val_accuracy: 0.9769 - lr: 0.0010\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1367 - accuracy: 0.9514 - val_loss: 0.0670 - val_accuracy: 0.9774 - lr: 0.0010\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1358 - accuracy: 0.9518 - val_loss: 0.0674 - val_accuracy: 0.9763 - lr: 0.0010\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1309 - accuracy: 0.9536 - val_loss: 0.0653 - val_accuracy: 0.9781 - lr: 0.0010\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1315 - accuracy: 0.9527 - val_loss: 0.0688 - val_accuracy: 0.9746 - lr: 0.0010\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1302 - accuracy: 0.9538 - val_loss: 0.0586 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1269 - accuracy: 0.9548 - val_loss: 0.0685 - val_accuracy: 0.9765 - lr: 0.0010\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1232 - accuracy: 0.9568 - val_loss: 0.0596 - val_accuracy: 0.9790 - lr: 0.0010\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1236 - accuracy: 0.9554 - val_loss: 0.0638 - val_accuracy: 0.9763 - lr: 0.0010\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0918 - accuracy: 0.9680 - val_loss: 0.0397 - val_accuracy: 0.9869 - lr: 5.0000e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0858 - accuracy: 0.9698 - val_loss: 0.0407 - val_accuracy: 0.9873 - lr: 5.0000e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0838 - accuracy: 0.9708 - val_loss: 0.0410 - val_accuracy: 0.9862 - lr: 5.0000e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0809 - accuracy: 0.9718 - val_loss: 0.0369 - val_accuracy: 0.9877 - lr: 5.0000e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0800 - accuracy: 0.9719 - val_loss: 0.0391 - val_accuracy: 0.9862 - lr: 5.0000e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0784 - accuracy: 0.9723 - val_loss: 0.0400 - val_accuracy: 0.9864 - lr: 5.0000e-04\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0784 - accuracy: 0.9726 - val_loss: 0.0404 - val_accuracy: 0.9869 - lr: 5.0000e-04\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0648 - accuracy: 0.9777 - val_loss: 0.0310 - val_accuracy: 0.9893 - lr: 2.5000e-04\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0625 - accuracy: 0.9785 - val_loss: 0.0297 - val_accuracy: 0.9897 - lr: 2.5000e-04\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0622 - accuracy: 0.9787 - val_loss: 0.0307 - val_accuracy: 0.9902 - lr: 2.5000e-04\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0604 - accuracy: 0.9794 - val_loss: 0.0305 - val_accuracy: 0.9895 - lr: 2.5000e-04\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0596 - accuracy: 0.9797 - val_loss: 0.0300 - val_accuracy: 0.9898 - lr: 2.5000e-04\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0542 - accuracy: 0.9813 - val_loss: 0.0272 - val_accuracy: 0.9912 - lr: 1.2500e-04\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0520 - accuracy: 0.9823 - val_loss: 0.0267 - val_accuracy: 0.9915 - lr: 1.2500e-04\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0525 - accuracy: 0.9823 - val_loss: 0.0248 - val_accuracy: 0.9924 - lr: 1.2500e-04\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0523 - accuracy: 0.9821 - val_loss: 0.0261 - val_accuracy: 0.9914 - lr: 1.2500e-04\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0511 - accuracy: 0.9827 - val_loss: 0.0249 - val_accuracy: 0.9921 - lr: 1.2500e-04\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0500 - accuracy: 0.9831 - val_loss: 0.0249 - val_accuracy: 0.9912 - lr: 1.2500e-04\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0477 - accuracy: 0.9841 - val_loss: 0.0232 - val_accuracy: 0.9930 - lr: 6.2500e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0476 - accuracy: 0.9842 - val_loss: 0.0241 - val_accuracy: 0.9926 - lr: 6.2500e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0468 - accuracy: 0.9838 - val_loss: 0.0230 - val_accuracy: 0.9928 - lr: 6.2500e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0465 - accuracy: 0.9847 - val_loss: 0.0239 - val_accuracy: 0.9924 - lr: 6.2500e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0475 - accuracy: 0.9840 - val_loss: 0.0238 - val_accuracy: 0.9922 - lr: 6.2500e-05\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0454 - accuracy: 0.9848 - val_loss: 0.0227 - val_accuracy: 0.9930 - lr: 6.2500e-05\n",
      "1033/1033 [==============================] - 5s 5ms/step - loss: 0.0217 - accuracy: 0.9931\n",
      "\n",
      "── Fold 4/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 12s 10ms/step - loss: 1.4499 - accuracy: 0.5062 - val_loss: 0.8755 - val_accuracy: 0.7109 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.8620 - accuracy: 0.7098 - val_loss: 0.5694 - val_accuracy: 0.8078 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.6481 - accuracy: 0.7816 - val_loss: 0.4451 - val_accuracy: 0.8498 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.5279 - accuracy: 0.8198 - val_loss: 0.3447 - val_accuracy: 0.8844 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.4476 - accuracy: 0.8461 - val_loss: 0.2945 - val_accuracy: 0.9045 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.3936 - accuracy: 0.8639 - val_loss: 0.2614 - val_accuracy: 0.9098 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.3511 - accuracy: 0.8789 - val_loss: 0.2279 - val_accuracy: 0.9245 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.3173 - accuracy: 0.8907 - val_loss: 0.1931 - val_accuracy: 0.9348 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2954 - accuracy: 0.8969 - val_loss: 0.1823 - val_accuracy: 0.9407 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2728 - accuracy: 0.9044 - val_loss: 0.1554 - val_accuracy: 0.9472 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2509 - accuracy: 0.9116 - val_loss: 0.1526 - val_accuracy: 0.9498 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2357 - accuracy: 0.9180 - val_loss: 0.1391 - val_accuracy: 0.9539 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2235 - accuracy: 0.9216 - val_loss: 0.1243 - val_accuracy: 0.9606 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2151 - accuracy: 0.9251 - val_loss: 0.1238 - val_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2010 - accuracy: 0.9298 - val_loss: 0.1135 - val_accuracy: 0.9632 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1972 - accuracy: 0.9303 - val_loss: 0.1071 - val_accuracy: 0.9657 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1877 - accuracy: 0.9332 - val_loss: 0.1070 - val_accuracy: 0.9644 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1798 - accuracy: 0.9360 - val_loss: 0.1020 - val_accuracy: 0.9663 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1777 - accuracy: 0.9374 - val_loss: 0.0931 - val_accuracy: 0.9719 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1693 - accuracy: 0.9398 - val_loss: 0.0883 - val_accuracy: 0.9730 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1657 - accuracy: 0.9416 - val_loss: 0.0846 - val_accuracy: 0.9719 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1601 - accuracy: 0.9430 - val_loss: 0.0881 - val_accuracy: 0.9714 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1522 - accuracy: 0.9461 - val_loss: 0.0814 - val_accuracy: 0.9744 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1524 - accuracy: 0.9467 - val_loss: 0.0803 - val_accuracy: 0.9726 - lr: 0.0010\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1458 - accuracy: 0.9491 - val_loss: 0.0699 - val_accuracy: 0.9766 - lr: 0.0010\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1459 - accuracy: 0.9490 - val_loss: 0.0738 - val_accuracy: 0.9760 - lr: 0.0010\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1406 - accuracy: 0.9500 - val_loss: 0.0746 - val_accuracy: 0.9761 - lr: 0.0010\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1379 - accuracy: 0.9517 - val_loss: 0.0643 - val_accuracy: 0.9784 - lr: 0.0010\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1385 - accuracy: 0.9514 - val_loss: 0.0702 - val_accuracy: 0.9781 - lr: 0.0010\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1323 - accuracy: 0.9528 - val_loss: 0.0649 - val_accuracy: 0.9794 - lr: 0.0010\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1321 - accuracy: 0.9528 - val_loss: 0.0675 - val_accuracy: 0.9775 - lr: 0.0010\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1004 - accuracy: 0.9653 - val_loss: 0.0455 - val_accuracy: 0.9868 - lr: 5.0000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0922 - accuracy: 0.9681 - val_loss: 0.0407 - val_accuracy: 0.9884 - lr: 5.0000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0898 - accuracy: 0.9687 - val_loss: 0.0443 - val_accuracy: 0.9868 - lr: 5.0000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0884 - accuracy: 0.9693 - val_loss: 0.0451 - val_accuracy: 0.9864 - lr: 5.0000e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0863 - accuracy: 0.9701 - val_loss: 0.0396 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0861 - accuracy: 0.9699 - val_loss: 0.0391 - val_accuracy: 0.9880 - lr: 5.0000e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0819 - accuracy: 0.9713 - val_loss: 0.0397 - val_accuracy: 0.9883 - lr: 5.0000e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0843 - accuracy: 0.9700 - val_loss: 0.0416 - val_accuracy: 0.9868 - lr: 5.0000e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0815 - accuracy: 0.9711 - val_loss: 0.0417 - val_accuracy: 0.9868 - lr: 5.0000e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0692 - accuracy: 0.9758 - val_loss: 0.0361 - val_accuracy: 0.9893 - lr: 2.5000e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0671 - accuracy: 0.9768 - val_loss: 0.0320 - val_accuracy: 0.9913 - lr: 2.5000e-04\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0652 - accuracy: 0.9776 - val_loss: 0.0295 - val_accuracy: 0.9915 - lr: 2.5000e-04\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0629 - accuracy: 0.9785 - val_loss: 0.0312 - val_accuracy: 0.9917 - lr: 2.5000e-04\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0624 - accuracy: 0.9785 - val_loss: 0.0314 - val_accuracy: 0.9915 - lr: 2.5000e-04\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0629 - accuracy: 0.9780 - val_loss: 0.0307 - val_accuracy: 0.9911 - lr: 2.5000e-04\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0566 - accuracy: 0.9808 - val_loss: 0.0269 - val_accuracy: 0.9926 - lr: 1.2500e-04\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0546 - accuracy: 0.9815 - val_loss: 0.0253 - val_accuracy: 0.9934 - lr: 1.2500e-04\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0555 - accuracy: 0.9814 - val_loss: 0.0266 - val_accuracy: 0.9929 - lr: 1.2500e-04\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0520 - accuracy: 0.9821 - val_loss: 0.0244 - val_accuracy: 0.9933 - lr: 1.2500e-04\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0533 - accuracy: 0.9815 - val_loss: 0.0253 - val_accuracy: 0.9936 - lr: 1.2500e-04\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0521 - accuracy: 0.9821 - val_loss: 0.0247 - val_accuracy: 0.9936 - lr: 1.2500e-04\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0520 - accuracy: 0.9825 - val_loss: 0.0246 - val_accuracy: 0.9936 - lr: 1.2500e-04\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0496 - accuracy: 0.9832 - val_loss: 0.0243 - val_accuracy: 0.9934 - lr: 6.2500e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0486 - accuracy: 0.9832 - val_loss: 0.0237 - val_accuracy: 0.9943 - lr: 6.2500e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0492 - accuracy: 0.9835 - val_loss: 0.0235 - val_accuracy: 0.9937 - lr: 6.2500e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0493 - accuracy: 0.9836 - val_loss: 0.0229 - val_accuracy: 0.9946 - lr: 6.2500e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0489 - accuracy: 0.9833 - val_loss: 0.0232 - val_accuracy: 0.9943 - lr: 6.2500e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0489 - accuracy: 0.9842 - val_loss: 0.0233 - val_accuracy: 0.9940 - lr: 6.2500e-05\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0472 - accuracy: 0.9844 - val_loss: 0.0227 - val_accuracy: 0.9942 - lr: 6.2500e-05\n",
      "1033/1033 [==============================] - 5s 5ms/step - loss: 0.0234 - accuracy: 0.9934\n",
      "\n",
      "── Fold 5/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 12s 10ms/step - loss: 1.4489 - accuracy: 0.5087 - val_loss: 0.8500 - val_accuracy: 0.7177 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.8536 - accuracy: 0.7128 - val_loss: 0.5657 - val_accuracy: 0.8130 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.6410 - accuracy: 0.7825 - val_loss: 0.4148 - val_accuracy: 0.8636 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.5248 - accuracy: 0.8211 - val_loss: 0.3473 - val_accuracy: 0.8828 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.4495 - accuracy: 0.8450 - val_loss: 0.2840 - val_accuracy: 0.9028 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.3969 - accuracy: 0.8628 - val_loss: 0.2488 - val_accuracy: 0.9150 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.3537 - accuracy: 0.8795 - val_loss: 0.2318 - val_accuracy: 0.9210 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.3235 - accuracy: 0.8884 - val_loss: 0.1946 - val_accuracy: 0.9349 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.3007 - accuracy: 0.8949 - val_loss: 0.1734 - val_accuracy: 0.9410 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2785 - accuracy: 0.9026 - val_loss: 0.1587 - val_accuracy: 0.9473 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2599 - accuracy: 0.9082 - val_loss: 0.1552 - val_accuracy: 0.9485 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2427 - accuracy: 0.9147 - val_loss: 0.1512 - val_accuracy: 0.9495 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2327 - accuracy: 0.9182 - val_loss: 0.1235 - val_accuracy: 0.9599 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2205 - accuracy: 0.9230 - val_loss: 0.1198 - val_accuracy: 0.9600 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2093 - accuracy: 0.9259 - val_loss: 0.1184 - val_accuracy: 0.9623 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2039 - accuracy: 0.9285 - val_loss: 0.1164 - val_accuracy: 0.9601 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1921 - accuracy: 0.9324 - val_loss: 0.1009 - val_accuracy: 0.9672 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1861 - accuracy: 0.9343 - val_loss: 0.1022 - val_accuracy: 0.9656 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1840 - accuracy: 0.9350 - val_loss: 0.0942 - val_accuracy: 0.9667 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1796 - accuracy: 0.9364 - val_loss: 0.0854 - val_accuracy: 0.9715 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1690 - accuracy: 0.9401 - val_loss: 0.0860 - val_accuracy: 0.9708 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1690 - accuracy: 0.9411 - val_loss: 0.0880 - val_accuracy: 0.9705 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1624 - accuracy: 0.9422 - val_loss: 0.0898 - val_accuracy: 0.9716 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1253 - accuracy: 0.9568 - val_loss: 0.0603 - val_accuracy: 0.9813 - lr: 5.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.1183 - accuracy: 0.9581 - val_loss: 0.0568 - val_accuracy: 0.9809 - lr: 5.0000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1132 - accuracy: 0.9606 - val_loss: 0.0566 - val_accuracy: 0.9809 - lr: 5.0000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1125 - accuracy: 0.9606 - val_loss: 0.0499 - val_accuracy: 0.9847 - lr: 5.0000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1077 - accuracy: 0.9627 - val_loss: 0.0563 - val_accuracy: 0.9830 - lr: 5.0000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1067 - accuracy: 0.9627 - val_loss: 0.0506 - val_accuracy: 0.9832 - lr: 5.0000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1035 - accuracy: 0.9636 - val_loss: 0.0491 - val_accuracy: 0.9837 - lr: 5.0000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1039 - accuracy: 0.9638 - val_loss: 0.0486 - val_accuracy: 0.9840 - lr: 5.0000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1016 - accuracy: 0.9642 - val_loss: 0.0487 - val_accuracy: 0.9837 - lr: 5.0000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0991 - accuracy: 0.9651 - val_loss: 0.0484 - val_accuracy: 0.9856 - lr: 5.0000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0987 - accuracy: 0.9653 - val_loss: 0.0488 - val_accuracy: 0.9847 - lr: 5.0000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0962 - accuracy: 0.9661 - val_loss: 0.0454 - val_accuracy: 0.9853 - lr: 5.0000e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0962 - accuracy: 0.9670 - val_loss: 0.0450 - val_accuracy: 0.9872 - lr: 5.0000e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0954 - accuracy: 0.9671 - val_loss: 0.0432 - val_accuracy: 0.9866 - lr: 5.0000e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0927 - accuracy: 0.9671 - val_loss: 0.0424 - val_accuracy: 0.9868 - lr: 5.0000e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0914 - accuracy: 0.9674 - val_loss: 0.0442 - val_accuracy: 0.9853 - lr: 5.0000e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0914 - accuracy: 0.9679 - val_loss: 0.0390 - val_accuracy: 0.9875 - lr: 5.0000e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0887 - accuracy: 0.9685 - val_loss: 0.0472 - val_accuracy: 0.9841 - lr: 5.0000e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0897 - accuracy: 0.9686 - val_loss: 0.0422 - val_accuracy: 0.9853 - lr: 5.0000e-04\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0887 - accuracy: 0.9684 - val_loss: 0.0373 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0876 - accuracy: 0.9686 - val_loss: 0.0369 - val_accuracy: 0.9884 - lr: 5.0000e-04\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0863 - accuracy: 0.9692 - val_loss: 0.0422 - val_accuracy: 0.9866 - lr: 5.0000e-04\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0857 - accuracy: 0.9695 - val_loss: 0.0376 - val_accuracy: 0.9868 - lr: 5.0000e-04\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0826 - accuracy: 0.9713 - val_loss: 0.0388 - val_accuracy: 0.9877 - lr: 5.0000e-04\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0711 - accuracy: 0.9753 - val_loss: 0.0319 - val_accuracy: 0.9893 - lr: 2.5000e-04\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0659 - accuracy: 0.9776 - val_loss: 0.0298 - val_accuracy: 0.9905 - lr: 2.5000e-04\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0656 - accuracy: 0.9769 - val_loss: 0.0302 - val_accuracy: 0.9902 - lr: 2.5000e-04\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0653 - accuracy: 0.9773 - val_loss: 0.0285 - val_accuracy: 0.9908 - lr: 2.5000e-04\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0628 - accuracy: 0.9779 - val_loss: 0.0303 - val_accuracy: 0.9896 - lr: 2.5000e-04\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0652 - accuracy: 0.9771 - val_loss: 0.0286 - val_accuracy: 0.9901 - lr: 2.5000e-04\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0622 - accuracy: 0.9784 - val_loss: 0.0293 - val_accuracy: 0.9908 - lr: 2.5000e-04\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0570 - accuracy: 0.9809 - val_loss: 0.0270 - val_accuracy: 0.9916 - lr: 1.2500e-04\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0542 - accuracy: 0.9815 - val_loss: 0.0251 - val_accuracy: 0.9924 - lr: 1.2500e-04\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0556 - accuracy: 0.9811 - val_loss: 0.0242 - val_accuracy: 0.9926 - lr: 1.2500e-04\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0537 - accuracy: 0.9819 - val_loss: 0.0259 - val_accuracy: 0.9918 - lr: 1.2500e-04\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0528 - accuracy: 0.9821 - val_loss: 0.0249 - val_accuracy: 0.9925 - lr: 1.2500e-04\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 9s 9ms/step - loss: 0.0525 - accuracy: 0.9821 - val_loss: 0.0254 - val_accuracy: 0.9921 - lr: 1.2500e-04\n",
      "1033/1033 [==============================] - 5s 5ms/step - loss: 0.0247 - accuracy: 0.9916\n",
      "\n",
      "── Fold 6/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 13s 11ms/step - loss: 1.4383 - accuracy: 0.5109 - val_loss: 0.8425 - val_accuracy: 0.7195 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.8413 - accuracy: 0.7162 - val_loss: 0.5480 - val_accuracy: 0.8156 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.6347 - accuracy: 0.7863 - val_loss: 0.4127 - val_accuracy: 0.8617 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.5156 - accuracy: 0.8249 - val_loss: 0.3300 - val_accuracy: 0.8886 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.4398 - accuracy: 0.8501 - val_loss: 0.2772 - val_accuracy: 0.9089 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.3860 - accuracy: 0.8667 - val_loss: 0.2464 - val_accuracy: 0.9179 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.3448 - accuracy: 0.8813 - val_loss: 0.2105 - val_accuracy: 0.9278 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.3141 - accuracy: 0.8915 - val_loss: 0.1855 - val_accuracy: 0.9362 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2887 - accuracy: 0.8987 - val_loss: 0.1731 - val_accuracy: 0.9407 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.2692 - accuracy: 0.9062 - val_loss: 0.1575 - val_accuracy: 0.9462 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2502 - accuracy: 0.9122 - val_loss: 0.1401 - val_accuracy: 0.9502 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2350 - accuracy: 0.9179 - val_loss: 0.1343 - val_accuracy: 0.9559 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.2203 - accuracy: 0.9228 - val_loss: 0.1193 - val_accuracy: 0.9598 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.2122 - accuracy: 0.9252 - val_loss: 0.1144 - val_accuracy: 0.9621 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.2017 - accuracy: 0.9292 - val_loss: 0.1100 - val_accuracy: 0.9633 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1953 - accuracy: 0.9313 - val_loss: 0.1002 - val_accuracy: 0.9665 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1843 - accuracy: 0.9354 - val_loss: 0.0959 - val_accuracy: 0.9671 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1798 - accuracy: 0.9373 - val_loss: 0.0901 - val_accuracy: 0.9689 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1756 - accuracy: 0.9382 - val_loss: 0.0949 - val_accuracy: 0.9660 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1684 - accuracy: 0.9400 - val_loss: 0.1025 - val_accuracy: 0.9635 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1634 - accuracy: 0.9420 - val_loss: 0.0808 - val_accuracy: 0.9732 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1606 - accuracy: 0.9442 - val_loss: 0.0818 - val_accuracy: 0.9723 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1573 - accuracy: 0.9439 - val_loss: 0.0835 - val_accuracy: 0.9722 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1532 - accuracy: 0.9459 - val_loss: 0.0752 - val_accuracy: 0.9757 - lr: 0.0010\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1482 - accuracy: 0.9476 - val_loss: 0.0705 - val_accuracy: 0.9760 - lr: 0.0010\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1443 - accuracy: 0.9492 - val_loss: 0.0757 - val_accuracy: 0.9742 - lr: 0.0010\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1417 - accuracy: 0.9495 - val_loss: 0.0674 - val_accuracy: 0.9775 - lr: 0.0010\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1421 - accuracy: 0.9500 - val_loss: 0.0706 - val_accuracy: 0.9751 - lr: 0.0010\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1348 - accuracy: 0.9524 - val_loss: 0.0642 - val_accuracy: 0.9775 - lr: 0.0010\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1348 - accuracy: 0.9524 - val_loss: 0.0607 - val_accuracy: 0.9803 - lr: 0.0010\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1314 - accuracy: 0.9538 - val_loss: 0.0627 - val_accuracy: 0.9784 - lr: 0.0010\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1275 - accuracy: 0.9550 - val_loss: 0.0605 - val_accuracy: 0.9797 - lr: 0.0010\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1278 - accuracy: 0.9550 - val_loss: 0.0594 - val_accuracy: 0.9809 - lr: 0.0010\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1244 - accuracy: 0.9559 - val_loss: 0.0577 - val_accuracy: 0.9808 - lr: 0.0010\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1218 - accuracy: 0.9569 - val_loss: 0.0705 - val_accuracy: 0.9754 - lr: 0.0010\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1250 - accuracy: 0.9555 - val_loss: 0.0575 - val_accuracy: 0.9822 - lr: 0.0010\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1193 - accuracy: 0.9581 - val_loss: 0.0566 - val_accuracy: 0.9815 - lr: 0.0010\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1166 - accuracy: 0.9588 - val_loss: 0.0571 - val_accuracy: 0.9797 - lr: 0.0010\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1172 - accuracy: 0.9588 - val_loss: 0.0529 - val_accuracy: 0.9812 - lr: 0.0010\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1159 - accuracy: 0.9599 - val_loss: 0.0567 - val_accuracy: 0.9806 - lr: 0.0010\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1135 - accuracy: 0.9598 - val_loss: 0.0495 - val_accuracy: 0.9839 - lr: 0.0010\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1132 - accuracy: 0.9605 - val_loss: 0.0474 - val_accuracy: 0.9853 - lr: 0.0010\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1091 - accuracy: 0.9615 - val_loss: 0.0514 - val_accuracy: 0.9838 - lr: 0.0010\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1123 - accuracy: 0.9601 - val_loss: 0.0517 - val_accuracy: 0.9837 - lr: 0.0010\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1105 - accuracy: 0.9615 - val_loss: 0.0472 - val_accuracy: 0.9845 - lr: 0.0010\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1089 - accuracy: 0.9613 - val_loss: 0.0465 - val_accuracy: 0.9841 - lr: 0.0010\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1069 - accuracy: 0.9625 - val_loss: 0.0432 - val_accuracy: 0.9857 - lr: 0.0010\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1061 - accuracy: 0.9625 - val_loss: 0.0514 - val_accuracy: 0.9828 - lr: 0.0010\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1055 - accuracy: 0.9629 - val_loss: 0.0451 - val_accuracy: 0.9844 - lr: 0.0010\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1053 - accuracy: 0.9631 - val_loss: 0.0446 - val_accuracy: 0.9849 - lr: 0.0010\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0776 - accuracy: 0.9731 - val_loss: 0.0314 - val_accuracy: 0.9901 - lr: 5.0000e-04\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0717 - accuracy: 0.9753 - val_loss: 0.0335 - val_accuracy: 0.9893 - lr: 5.0000e-04\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0695 - accuracy: 0.9758 - val_loss: 0.0340 - val_accuracy: 0.9890 - lr: 5.0000e-04\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0690 - accuracy: 0.9760 - val_loss: 0.0292 - val_accuracy: 0.9912 - lr: 5.0000e-04\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0675 - accuracy: 0.9763 - val_loss: 0.0318 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0675 - accuracy: 0.9763 - val_loss: 0.0287 - val_accuracy: 0.9902 - lr: 5.0000e-04\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0641 - accuracy: 0.9777 - val_loss: 0.0303 - val_accuracy: 0.9896 - lr: 5.0000e-04\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0649 - accuracy: 0.9772 - val_loss: 0.0276 - val_accuracy: 0.9913 - lr: 5.0000e-04\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0641 - accuracy: 0.9770 - val_loss: 0.0293 - val_accuracy: 0.9898 - lr: 5.0000e-04\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0635 - accuracy: 0.9777 - val_loss: 0.0274 - val_accuracy: 0.9912 - lr: 5.0000e-04\n",
      "1033/1033 [==============================] - 5s 5ms/step - loss: 0.0303 - accuracy: 0.9907\n",
      "\n",
      "── Fold 7/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 13s 11ms/step - loss: 1.4577 - accuracy: 0.5054 - val_loss: 0.8542 - val_accuracy: 0.7140 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.8566 - accuracy: 0.7107 - val_loss: 0.5715 - val_accuracy: 0.8096 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.6442 - accuracy: 0.7815 - val_loss: 0.4283 - val_accuracy: 0.8536 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.5302 - accuracy: 0.8193 - val_loss: 0.3326 - val_accuracy: 0.8866 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.4463 - accuracy: 0.8467 - val_loss: 0.2872 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.3954 - accuracy: 0.8631 - val_loss: 0.2539 - val_accuracy: 0.9149 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.3534 - accuracy: 0.8780 - val_loss: 0.2124 - val_accuracy: 0.9303 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.3237 - accuracy: 0.8875 - val_loss: 0.1898 - val_accuracy: 0.9357 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.2962 - accuracy: 0.8969 - val_loss: 0.1727 - val_accuracy: 0.9411 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.2742 - accuracy: 0.9047 - val_loss: 0.1543 - val_accuracy: 0.9483 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.2555 - accuracy: 0.9110 - val_loss: 0.1447 - val_accuracy: 0.9505 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.2429 - accuracy: 0.9152 - val_loss: 0.1230 - val_accuracy: 0.9595 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.2286 - accuracy: 0.9200 - val_loss: 0.1200 - val_accuracy: 0.9603 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.2180 - accuracy: 0.9228 - val_loss: 0.1179 - val_accuracy: 0.9589 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2074 - accuracy: 0.9266 - val_loss: 0.1013 - val_accuracy: 0.9679 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2001 - accuracy: 0.9297 - val_loss: 0.1027 - val_accuracy: 0.9663 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1918 - accuracy: 0.9322 - val_loss: 0.1011 - val_accuracy: 0.9655 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1886 - accuracy: 0.9339 - val_loss: 0.0988 - val_accuracy: 0.9668 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1817 - accuracy: 0.9350 - val_loss: 0.0884 - val_accuracy: 0.9691 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1716 - accuracy: 0.9396 - val_loss: 0.0897 - val_accuracy: 0.9683 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1650 - accuracy: 0.9419 - val_loss: 0.0793 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1616 - accuracy: 0.9437 - val_loss: 0.0779 - val_accuracy: 0.9734 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1625 - accuracy: 0.9424 - val_loss: 0.0777 - val_accuracy: 0.9738 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1523 - accuracy: 0.9457 - val_loss: 0.0699 - val_accuracy: 0.9767 - lr: 0.0010\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1516 - accuracy: 0.9465 - val_loss: 0.0659 - val_accuracy: 0.9780 - lr: 0.0010\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1490 - accuracy: 0.9476 - val_loss: 0.0656 - val_accuracy: 0.9779 - lr: 0.0010\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1466 - accuracy: 0.9483 - val_loss: 0.0696 - val_accuracy: 0.9767 - lr: 0.0010\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1418 - accuracy: 0.9498 - val_loss: 0.0671 - val_accuracy: 0.9769 - lr: 0.0010\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1439 - accuracy: 0.9482 - val_loss: 0.0645 - val_accuracy: 0.9780 - lr: 0.0010\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1379 - accuracy: 0.9517 - val_loss: 0.0587 - val_accuracy: 0.9810 - lr: 0.0010\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1364 - accuracy: 0.9519 - val_loss: 0.0619 - val_accuracy: 0.9784 - lr: 0.0010\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1350 - accuracy: 0.9521 - val_loss: 0.0571 - val_accuracy: 0.9812 - lr: 0.0010\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1305 - accuracy: 0.9539 - val_loss: 0.0546 - val_accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1318 - accuracy: 0.9529 - val_loss: 0.0528 - val_accuracy: 0.9831 - lr: 0.0010\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1271 - accuracy: 0.9555 - val_loss: 0.0552 - val_accuracy: 0.9806 - lr: 0.0010\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1282 - accuracy: 0.9544 - val_loss: 0.0618 - val_accuracy: 0.9784 - lr: 0.0010\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1250 - accuracy: 0.9556 - val_loss: 0.0532 - val_accuracy: 0.9825 - lr: 0.0010\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0939 - accuracy: 0.9671 - val_loss: 0.0359 - val_accuracy: 0.9893 - lr: 5.0000e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0850 - accuracy: 0.9700 - val_loss: 0.0382 - val_accuracy: 0.9865 - lr: 5.0000e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0854 - accuracy: 0.9702 - val_loss: 0.0358 - val_accuracy: 0.9880 - lr: 5.0000e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0839 - accuracy: 0.9709 - val_loss: 0.0322 - val_accuracy: 0.9899 - lr: 5.0000e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 10s 11ms/step - loss: 0.0835 - accuracy: 0.9702 - val_loss: 0.0368 - val_accuracy: 0.9872 - lr: 5.0000e-04\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0808 - accuracy: 0.9719 - val_loss: 0.0323 - val_accuracy: 0.9897 - lr: 5.0000e-04\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 10s 11ms/step - loss: 0.0798 - accuracy: 0.9719 - val_loss: 0.0345 - val_accuracy: 0.9884 - lr: 5.0000e-04\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0679 - accuracy: 0.9767 - val_loss: 0.0254 - val_accuracy: 0.9920 - lr: 2.5000e-04\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0631 - accuracy: 0.9778 - val_loss: 0.0249 - val_accuracy: 0.9918 - lr: 2.5000e-04\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0618 - accuracy: 0.9789 - val_loss: 0.0243 - val_accuracy: 0.9926 - lr: 2.5000e-04\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0627 - accuracy: 0.9781 - val_loss: 0.0254 - val_accuracy: 0.9917 - lr: 2.5000e-04\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0604 - accuracy: 0.9790 - val_loss: 0.0248 - val_accuracy: 0.9921 - lr: 2.5000e-04\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0598 - accuracy: 0.9795 - val_loss: 0.0239 - val_accuracy: 0.9930 - lr: 2.5000e-04\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0588 - accuracy: 0.9799 - val_loss: 0.0229 - val_accuracy: 0.9926 - lr: 2.5000e-04\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0585 - accuracy: 0.9800 - val_loss: 0.0224 - val_accuracy: 0.9930 - lr: 2.5000e-04\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0584 - accuracy: 0.9799 - val_loss: 0.0239 - val_accuracy: 0.9930 - lr: 2.5000e-04\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0579 - accuracy: 0.9797 - val_loss: 0.0231 - val_accuracy: 0.9932 - lr: 2.5000e-04\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0567 - accuracy: 0.9805 - val_loss: 0.0242 - val_accuracy: 0.9923 - lr: 2.5000e-04\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0521 - accuracy: 0.9821 - val_loss: 0.0213 - val_accuracy: 0.9936 - lr: 1.2500e-04\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0511 - accuracy: 0.9825 - val_loss: 0.0192 - val_accuracy: 0.9943 - lr: 1.2500e-04\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0498 - accuracy: 0.9833 - val_loss: 0.0199 - val_accuracy: 0.9939 - lr: 1.2500e-04\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0502 - accuracy: 0.9828 - val_loss: 0.0208 - val_accuracy: 0.9930 - lr: 1.2500e-04\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0477 - accuracy: 0.9841 - val_loss: 0.0206 - val_accuracy: 0.9936 - lr: 1.2500e-04\n",
      "1033/1033 [==============================] - 5s 5ms/step - loss: 0.0255 - accuracy: 0.9921\n",
      "\n",
      "── Fold 8/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 13s 11ms/step - loss: 1.4530 - accuracy: 0.5057 - val_loss: 0.8516 - val_accuracy: 0.7185 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.8512 - accuracy: 0.7154 - val_loss: 0.5536 - val_accuracy: 0.8157 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.6355 - accuracy: 0.7852 - val_loss: 0.4061 - val_accuracy: 0.8661 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.5156 - accuracy: 0.8248 - val_loss: 0.3336 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.4424 - accuracy: 0.8472 - val_loss: 0.2621 - val_accuracy: 0.9164 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.3858 - accuracy: 0.8663 - val_loss: 0.2369 - val_accuracy: 0.9203 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.3424 - accuracy: 0.8812 - val_loss: 0.2062 - val_accuracy: 0.9314 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.3132 - accuracy: 0.8908 - val_loss: 0.1910 - val_accuracy: 0.9374 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2919 - accuracy: 0.8987 - val_loss: 0.1666 - val_accuracy: 0.9439 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2683 - accuracy: 0.9063 - val_loss: 0.1485 - val_accuracy: 0.9517 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2496 - accuracy: 0.9125 - val_loss: 0.1406 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2390 - accuracy: 0.9158 - val_loss: 0.1279 - val_accuracy: 0.9564 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2226 - accuracy: 0.9223 - val_loss: 0.1185 - val_accuracy: 0.9620 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.2136 - accuracy: 0.9252 - val_loss: 0.1114 - val_accuracy: 0.9644 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.2039 - accuracy: 0.9283 - val_loss: 0.1163 - val_accuracy: 0.9622 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1957 - accuracy: 0.9315 - val_loss: 0.1013 - val_accuracy: 0.9649 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1870 - accuracy: 0.9345 - val_loss: 0.0968 - val_accuracy: 0.9672 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1816 - accuracy: 0.9354 - val_loss: 0.0827 - val_accuracy: 0.9738 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1754 - accuracy: 0.9383 - val_loss: 0.0795 - val_accuracy: 0.9751 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1694 - accuracy: 0.9404 - val_loss: 0.0858 - val_accuracy: 0.9719 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1635 - accuracy: 0.9425 - val_loss: 0.0799 - val_accuracy: 0.9744 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1597 - accuracy: 0.9433 - val_loss: 0.0745 - val_accuracy: 0.9758 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1561 - accuracy: 0.9448 - val_loss: 0.0752 - val_accuracy: 0.9765 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1519 - accuracy: 0.9462 - val_loss: 0.0717 - val_accuracy: 0.9772 - lr: 0.0010\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1521 - accuracy: 0.9460 - val_loss: 0.0646 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1437 - accuracy: 0.9491 - val_loss: 0.0709 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1424 - accuracy: 0.9495 - val_loss: 0.0695 - val_accuracy: 0.9766 - lr: 0.0010\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1434 - accuracy: 0.9491 - val_loss: 0.0676 - val_accuracy: 0.9778 - lr: 0.0010\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1064 - accuracy: 0.9626 - val_loss: 0.0462 - val_accuracy: 0.9849 - lr: 5.0000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0982 - accuracy: 0.9655 - val_loss: 0.0452 - val_accuracy: 0.9859 - lr: 5.0000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0978 - accuracy: 0.9655 - val_loss: 0.0418 - val_accuracy: 0.9873 - lr: 5.0000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0938 - accuracy: 0.9676 - val_loss: 0.0408 - val_accuracy: 0.9869 - lr: 5.0000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0929 - accuracy: 0.9670 - val_loss: 0.0450 - val_accuracy: 0.9848 - lr: 5.0000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0920 - accuracy: 0.9684 - val_loss: 0.0394 - val_accuracy: 0.9880 - lr: 5.0000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0910 - accuracy: 0.9684 - val_loss: 0.0389 - val_accuracy: 0.9893 - lr: 5.0000e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0881 - accuracy: 0.9690 - val_loss: 0.0408 - val_accuracy: 0.9871 - lr: 5.0000e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0887 - accuracy: 0.9683 - val_loss: 0.0388 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0855 - accuracy: 0.9702 - val_loss: 0.0370 - val_accuracy: 0.9886 - lr: 5.0000e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0856 - accuracy: 0.9697 - val_loss: 0.0364 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0820 - accuracy: 0.9714 - val_loss: 0.0360 - val_accuracy: 0.9895 - lr: 5.0000e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0845 - accuracy: 0.9702 - val_loss: 0.0371 - val_accuracy: 0.9884 - lr: 5.0000e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0826 - accuracy: 0.9709 - val_loss: 0.0360 - val_accuracy: 0.9888 - lr: 5.0000e-04\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0805 - accuracy: 0.9720 - val_loss: 0.0346 - val_accuracy: 0.9896 - lr: 5.0000e-04\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0794 - accuracy: 0.9723 - val_loss: 0.0394 - val_accuracy: 0.9867 - lr: 5.0000e-04\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0807 - accuracy: 0.9713 - val_loss: 0.0328 - val_accuracy: 0.9896 - lr: 5.0000e-04\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0800 - accuracy: 0.9719 - val_loss: 0.0339 - val_accuracy: 0.9896 - lr: 5.0000e-04\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0766 - accuracy: 0.9732 - val_loss: 0.0362 - val_accuracy: 0.9890 - lr: 5.0000e-04\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0758 - accuracy: 0.9732 - val_loss: 0.0351 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0619 - accuracy: 0.9788 - val_loss: 0.0288 - val_accuracy: 0.9912 - lr: 2.5000e-04\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0590 - accuracy: 0.9796 - val_loss: 0.0278 - val_accuracy: 0.9911 - lr: 2.5000e-04\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0609 - accuracy: 0.9792 - val_loss: 0.0274 - val_accuracy: 0.9915 - lr: 2.5000e-04\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0586 - accuracy: 0.9798 - val_loss: 0.0255 - val_accuracy: 0.9928 - lr: 2.5000e-04\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0569 - accuracy: 0.9802 - val_loss: 0.0289 - val_accuracy: 0.9918 - lr: 2.5000e-04\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0573 - accuracy: 0.9798 - val_loss: 0.0273 - val_accuracy: 0.9918 - lr: 2.5000e-04\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0575 - accuracy: 0.9802 - val_loss: 0.0257 - val_accuracy: 0.9923 - lr: 2.5000e-04\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0522 - accuracy: 0.9821 - val_loss: 0.0243 - val_accuracy: 0.9931 - lr: 1.2500e-04\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0507 - accuracy: 0.9825 - val_loss: 0.0237 - val_accuracy: 0.9942 - lr: 1.2500e-04\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0488 - accuracy: 0.9832 - val_loss: 0.0242 - val_accuracy: 0.9933 - lr: 1.2500e-04\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0478 - accuracy: 0.9838 - val_loss: 0.0237 - val_accuracy: 0.9933 - lr: 1.2500e-04\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0482 - accuracy: 0.9834 - val_loss: 0.0235 - val_accuracy: 0.9936 - lr: 1.2500e-04\n",
      "1033/1033 [==============================] - 5s 5ms/step - loss: 0.0232 - accuracy: 0.9930\n",
      "\n",
      "── Fold 9/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 13s 11ms/step - loss: 1.4446 - accuracy: 0.5079 - val_loss: 0.8298 - val_accuracy: 0.7264 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.8483 - accuracy: 0.7153 - val_loss: 0.5429 - val_accuracy: 0.8169 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.6387 - accuracy: 0.7844 - val_loss: 0.4180 - val_accuracy: 0.8612 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.5205 - accuracy: 0.8223 - val_loss: 0.3305 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.4441 - accuracy: 0.8476 - val_loss: 0.2859 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.3866 - accuracy: 0.8664 - val_loss: 0.2430 - val_accuracy: 0.9168 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.3478 - accuracy: 0.8789 - val_loss: 0.2180 - val_accuracy: 0.9274 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.3174 - accuracy: 0.8892 - val_loss: 0.1949 - val_accuracy: 0.9349 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.2913 - accuracy: 0.8995 - val_loss: 0.1700 - val_accuracy: 0.9417 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.2709 - accuracy: 0.9050 - val_loss: 0.1550 - val_accuracy: 0.9470 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.2511 - accuracy: 0.9124 - val_loss: 0.1429 - val_accuracy: 0.9529 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.2403 - accuracy: 0.9154 - val_loss: 0.1322 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.2278 - accuracy: 0.9201 - val_loss: 0.1277 - val_accuracy: 0.9567 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.2150 - accuracy: 0.9243 - val_loss: 0.1210 - val_accuracy: 0.9591 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.2044 - accuracy: 0.9280 - val_loss: 0.1079 - val_accuracy: 0.9616 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1981 - accuracy: 0.9302 - val_loss: 0.1044 - val_accuracy: 0.9636 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1894 - accuracy: 0.9329 - val_loss: 0.0973 - val_accuracy: 0.9663 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1838 - accuracy: 0.9352 - val_loss: 0.0911 - val_accuracy: 0.9691 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1772 - accuracy: 0.9377 - val_loss: 0.0872 - val_accuracy: 0.9699 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1711 - accuracy: 0.9395 - val_loss: 0.0849 - val_accuracy: 0.9713 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1690 - accuracy: 0.9411 - val_loss: 0.0858 - val_accuracy: 0.9705 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1610 - accuracy: 0.9431 - val_loss: 0.0809 - val_accuracy: 0.9741 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1570 - accuracy: 0.9439 - val_loss: 0.0769 - val_accuracy: 0.9731 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1552 - accuracy: 0.9450 - val_loss: 0.0752 - val_accuracy: 0.9754 - lr: 0.0010\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1504 - accuracy: 0.9467 - val_loss: 0.0719 - val_accuracy: 0.9765 - lr: 0.0010\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1491 - accuracy: 0.9474 - val_loss: 0.0688 - val_accuracy: 0.9774 - lr: 0.0010\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1467 - accuracy: 0.9482 - val_loss: 0.0653 - val_accuracy: 0.9768 - lr: 0.0010\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1399 - accuracy: 0.9503 - val_loss: 0.0676 - val_accuracy: 0.9769 - lr: 0.0010\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1367 - accuracy: 0.9511 - val_loss: 0.0628 - val_accuracy: 0.9787 - lr: 0.0010\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1365 - accuracy: 0.9517 - val_loss: 0.0645 - val_accuracy: 0.9780 - lr: 0.0010\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1345 - accuracy: 0.9520 - val_loss: 0.0596 - val_accuracy: 0.9788 - lr: 0.0010\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1326 - accuracy: 0.9531 - val_loss: 0.0570 - val_accuracy: 0.9810 - lr: 0.0010\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1332 - accuracy: 0.9524 - val_loss: 0.0642 - val_accuracy: 0.9760 - lr: 0.0010\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1296 - accuracy: 0.9543 - val_loss: 0.0578 - val_accuracy: 0.9809 - lr: 0.0010\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1242 - accuracy: 0.9560 - val_loss: 0.0575 - val_accuracy: 0.9805 - lr: 0.0010\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0926 - accuracy: 0.9671 - val_loss: 0.0405 - val_accuracy: 0.9876 - lr: 5.0000e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0878 - accuracy: 0.9690 - val_loss: 0.0390 - val_accuracy: 0.9876 - lr: 5.0000e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0880 - accuracy: 0.9690 - val_loss: 0.0406 - val_accuracy: 0.9883 - lr: 5.0000e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0837 - accuracy: 0.9714 - val_loss: 0.0352 - val_accuracy: 0.9892 - lr: 5.0000e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0844 - accuracy: 0.9703 - val_loss: 0.0393 - val_accuracy: 0.9884 - lr: 5.0000e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0815 - accuracy: 0.9714 - val_loss: 0.0371 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0799 - accuracy: 0.9719 - val_loss: 0.0342 - val_accuracy: 0.9896 - lr: 5.0000e-04\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0813 - accuracy: 0.9712 - val_loss: 0.0366 - val_accuracy: 0.9876 - lr: 5.0000e-04\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0762 - accuracy: 0.9736 - val_loss: 0.0339 - val_accuracy: 0.9899 - lr: 5.0000e-04\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0780 - accuracy: 0.9726 - val_loss: 0.0308 - val_accuracy: 0.9900 - lr: 5.0000e-04\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0779 - accuracy: 0.9728 - val_loss: 0.0288 - val_accuracy: 0.9912 - lr: 5.0000e-04\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0756 - accuracy: 0.9735 - val_loss: 0.0315 - val_accuracy: 0.9899 - lr: 5.0000e-04\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0751 - accuracy: 0.9737 - val_loss: 0.0320 - val_accuracy: 0.9893 - lr: 5.0000e-04\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0741 - accuracy: 0.9739 - val_loss: 0.0309 - val_accuracy: 0.9896 - lr: 5.0000e-04\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0629 - accuracy: 0.9782 - val_loss: 0.0256 - val_accuracy: 0.9924 - lr: 2.5000e-04\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0580 - accuracy: 0.9803 - val_loss: 0.0237 - val_accuracy: 0.9921 - lr: 2.5000e-04\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0576 - accuracy: 0.9803 - val_loss: 0.0234 - val_accuracy: 0.9927 - lr: 2.5000e-04\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0575 - accuracy: 0.9803 - val_loss: 0.0242 - val_accuracy: 0.9925 - lr: 2.5000e-04\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0576 - accuracy: 0.9802 - val_loss: 0.0254 - val_accuracy: 0.9924 - lr: 2.5000e-04\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0565 - accuracy: 0.9803 - val_loss: 0.0253 - val_accuracy: 0.9916 - lr: 2.5000e-04\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0512 - accuracy: 0.9827 - val_loss: 0.0215 - val_accuracy: 0.9933 - lr: 1.2500e-04\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0495 - accuracy: 0.9830 - val_loss: 0.0210 - val_accuracy: 0.9934 - lr: 1.2500e-04\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0495 - accuracy: 0.9836 - val_loss: 0.0206 - val_accuracy: 0.9938 - lr: 1.2500e-04\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0487 - accuracy: 0.9834 - val_loss: 0.0216 - val_accuracy: 0.9929 - lr: 1.2500e-04\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0487 - accuracy: 0.9832 - val_loss: 0.0206 - val_accuracy: 0.9939 - lr: 1.2500e-04\n",
      "1033/1033 [==============================] - 5s 5ms/step - loss: 0.0206 - accuracy: 0.9938\n",
      "\n",
      "── Fold 10/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 13s 11ms/step - loss: 1.4439 - accuracy: 0.5098 - val_loss: 0.8456 - val_accuracy: 0.7194 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.8483 - accuracy: 0.7161 - val_loss: 0.5516 - val_accuracy: 0.8163 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.6386 - accuracy: 0.7844 - val_loss: 0.4107 - val_accuracy: 0.8605 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.5244 - accuracy: 0.8213 - val_loss: 0.3368 - val_accuracy: 0.8854 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.4486 - accuracy: 0.8466 - val_loss: 0.2844 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.3965 - accuracy: 0.8620 - val_loss: 0.2459 - val_accuracy: 0.9166 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.3520 - accuracy: 0.8780 - val_loss: 0.2063 - val_accuracy: 0.9322 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.3203 - accuracy: 0.8891 - val_loss: 0.2008 - val_accuracy: 0.9309 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2963 - accuracy: 0.8965 - val_loss: 0.1627 - val_accuracy: 0.9451 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2750 - accuracy: 0.9040 - val_loss: 0.1637 - val_accuracy: 0.9455 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.2567 - accuracy: 0.9111 - val_loss: 0.1401 - val_accuracy: 0.9542 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.2424 - accuracy: 0.9148 - val_loss: 0.1274 - val_accuracy: 0.9550 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.2282 - accuracy: 0.9201 - val_loss: 0.1206 - val_accuracy: 0.9577 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.2168 - accuracy: 0.9239 - val_loss: 0.1204 - val_accuracy: 0.9591 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.2099 - accuracy: 0.9263 - val_loss: 0.1117 - val_accuracy: 0.9621 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.2003 - accuracy: 0.9303 - val_loss: 0.1104 - val_accuracy: 0.9626 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1920 - accuracy: 0.9324 - val_loss: 0.1049 - val_accuracy: 0.9648 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1867 - accuracy: 0.9345 - val_loss: 0.0979 - val_accuracy: 0.9666 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1774 - accuracy: 0.9378 - val_loss: 0.0930 - val_accuracy: 0.9686 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1716 - accuracy: 0.9388 - val_loss: 0.0900 - val_accuracy: 0.9675 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1682 - accuracy: 0.9415 - val_loss: 0.0861 - val_accuracy: 0.9692 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1641 - accuracy: 0.9420 - val_loss: 0.0824 - val_accuracy: 0.9723 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1614 - accuracy: 0.9429 - val_loss: 0.0766 - val_accuracy: 0.9753 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1542 - accuracy: 0.9455 - val_loss: 0.0715 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1521 - accuracy: 0.9464 - val_loss: 0.0764 - val_accuracy: 0.9736 - lr: 0.0010\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1479 - accuracy: 0.9478 - val_loss: 0.0653 - val_accuracy: 0.9775 - lr: 0.0010\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1455 - accuracy: 0.9483 - val_loss: 0.0712 - val_accuracy: 0.9753 - lr: 0.0010\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1453 - accuracy: 0.9489 - val_loss: 0.0739 - val_accuracy: 0.9741 - lr: 0.0010\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1402 - accuracy: 0.9504 - val_loss: 0.0632 - val_accuracy: 0.9778 - lr: 0.0010\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1396 - accuracy: 0.9506 - val_loss: 0.0644 - val_accuracy: 0.9781 - lr: 0.0010\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.1376 - accuracy: 0.9515 - val_loss: 0.0633 - val_accuracy: 0.9787 - lr: 0.0010\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1342 - accuracy: 0.9526 - val_loss: 0.0577 - val_accuracy: 0.9808 - lr: 0.0010\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1311 - accuracy: 0.9529 - val_loss: 0.0579 - val_accuracy: 0.9792 - lr: 0.0010\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1275 - accuracy: 0.9547 - val_loss: 0.0599 - val_accuracy: 0.9789 - lr: 0.0010\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.1297 - accuracy: 0.9542 - val_loss: 0.0643 - val_accuracy: 0.9788 - lr: 0.0010\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0977 - accuracy: 0.9659 - val_loss: 0.0457 - val_accuracy: 0.9849 - lr: 5.0000e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0891 - accuracy: 0.9688 - val_loss: 0.0397 - val_accuracy: 0.9858 - lr: 5.0000e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0887 - accuracy: 0.9692 - val_loss: 0.0404 - val_accuracy: 0.9857 - lr: 5.0000e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0843 - accuracy: 0.9705 - val_loss: 0.0399 - val_accuracy: 0.9873 - lr: 5.0000e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0860 - accuracy: 0.9698 - val_loss: 0.0392 - val_accuracy: 0.9865 - lr: 5.0000e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0848 - accuracy: 0.9701 - val_loss: 0.0378 - val_accuracy: 0.9868 - lr: 5.0000e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0829 - accuracy: 0.9708 - val_loss: 0.0359 - val_accuracy: 0.9875 - lr: 5.0000e-04\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0817 - accuracy: 0.9716 - val_loss: 0.0364 - val_accuracy: 0.9872 - lr: 5.0000e-04\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0811 - accuracy: 0.9712 - val_loss: 0.0341 - val_accuracy: 0.9877 - lr: 5.0000e-04\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0787 - accuracy: 0.9724 - val_loss: 0.0341 - val_accuracy: 0.9886 - lr: 5.0000e-04\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0787 - accuracy: 0.9726 - val_loss: 0.0358 - val_accuracy: 0.9884 - lr: 5.0000e-04\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0779 - accuracy: 0.9728 - val_loss: 0.0342 - val_accuracy: 0.9889 - lr: 5.0000e-04\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0643 - accuracy: 0.9777 - val_loss: 0.0270 - val_accuracy: 0.9917 - lr: 2.5000e-04\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0618 - accuracy: 0.9790 - val_loss: 0.0267 - val_accuracy: 0.9918 - lr: 2.5000e-04\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0601 - accuracy: 0.9789 - val_loss: 0.0289 - val_accuracy: 0.9902 - lr: 2.5000e-04\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0586 - accuracy: 0.9796 - val_loss: 0.0268 - val_accuracy: 0.9921 - lr: 2.5000e-04\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0595 - accuracy: 0.9795 - val_loss: 0.0265 - val_accuracy: 0.9920 - lr: 2.5000e-04\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0576 - accuracy: 0.9798 - val_loss: 0.0265 - val_accuracy: 0.9913 - lr: 2.5000e-04\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0579 - accuracy: 0.9802 - val_loss: 0.0248 - val_accuracy: 0.9921 - lr: 2.5000e-04\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0569 - accuracy: 0.9803 - val_loss: 0.0244 - val_accuracy: 0.9923 - lr: 2.5000e-04\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0564 - accuracy: 0.9810 - val_loss: 0.0240 - val_accuracy: 0.9926 - lr: 2.5000e-04\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0548 - accuracy: 0.9811 - val_loss: 0.0231 - val_accuracy: 0.9925 - lr: 2.5000e-04\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0565 - accuracy: 0.9809 - val_loss: 0.0238 - val_accuracy: 0.9921 - lr: 2.5000e-04\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 9s 10ms/step - loss: 0.0546 - accuracy: 0.9813 - val_loss: 0.0237 - val_accuracy: 0.9922 - lr: 2.5000e-04\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 10s 10ms/step - loss: 0.0558 - accuracy: 0.9807 - val_loss: 0.0205 - val_accuracy: 0.9933 - lr: 2.5000e-04\n",
      "1033/1033 [==============================] - 5s 5ms/step - loss: 0.0233 - accuracy: 0.9927\n",
      "\n",
      "################ DualStr_Original – 10-fold CV ################\n",
      "\n",
      "── Fold 1/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 43s 41ms/step - loss: 1.9110 - accuracy: 0.3295 - val_loss: 1.5498 - val_accuracy: 0.4492 - lr: 1.0000e-04\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 1.3895 - accuracy: 0.5142 - val_loss: 1.0525 - val_accuracy: 0.6389 - lr: 1.0000e-04\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 36s 39ms/step - loss: 1.0233 - accuracy: 0.6499 - val_loss: 0.7750 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 36s 39ms/step - loss: 0.8056 - accuracy: 0.7249 - val_loss: 0.5967 - val_accuracy: 0.8004 - lr: 1.0000e-04\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.6556 - accuracy: 0.7761 - val_loss: 0.4846 - val_accuracy: 0.8369 - lr: 1.0000e-04\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.5539 - accuracy: 0.8105 - val_loss: 0.4168 - val_accuracy: 0.8608 - lr: 1.0000e-04\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.4787 - accuracy: 0.8348 - val_loss: 0.3387 - val_accuracy: 0.8884 - lr: 1.0000e-04\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 36s 39ms/step - loss: 0.4159 - accuracy: 0.8566 - val_loss: 0.3175 - val_accuracy: 0.8914 - lr: 1.0000e-04\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 36s 39ms/step - loss: 0.3669 - accuracy: 0.8726 - val_loss: 0.2396 - val_accuracy: 0.9211 - lr: 1.0000e-04\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.3212 - accuracy: 0.8879 - val_loss: 0.2268 - val_accuracy: 0.9233 - lr: 1.0000e-04\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.2916 - accuracy: 0.8986 - val_loss: 0.1950 - val_accuracy: 0.9343 - lr: 1.0000e-04\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.2606 - accuracy: 0.9090 - val_loss: 0.1717 - val_accuracy: 0.9427 - lr: 1.0000e-04\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.2319 - accuracy: 0.9187 - val_loss: 0.1442 - val_accuracy: 0.9526 - lr: 1.0000e-04\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.2168 - accuracy: 0.9241 - val_loss: 0.1431 - val_accuracy: 0.9521 - lr: 1.0000e-04\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1965 - accuracy: 0.9318 - val_loss: 0.1283 - val_accuracy: 0.9582 - lr: 1.0000e-04\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.1797 - accuracy: 0.9378 - val_loss: 0.1330 - val_accuracy: 0.9561 - lr: 1.0000e-04\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.1674 - accuracy: 0.9420 - val_loss: 0.1048 - val_accuracy: 0.9642 - lr: 1.0000e-04\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.1534 - accuracy: 0.9462 - val_loss: 0.0848 - val_accuracy: 0.9716 - lr: 1.0000e-04\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.1467 - accuracy: 0.9483 - val_loss: 0.0845 - val_accuracy: 0.9714 - lr: 1.0000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.1336 - accuracy: 0.9533 - val_loss: 0.0816 - val_accuracy: 0.9716 - lr: 1.0000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.1264 - accuracy: 0.9553 - val_loss: 0.0899 - val_accuracy: 0.9679 - lr: 1.0000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1174 - accuracy: 0.9591 - val_loss: 0.0708 - val_accuracy: 0.9773 - lr: 1.0000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.1110 - accuracy: 0.9608 - val_loss: 0.0838 - val_accuracy: 0.9701 - lr: 1.0000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.1068 - accuracy: 0.9624 - val_loss: 0.0701 - val_accuracy: 0.9775 - lr: 1.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1009 - accuracy: 0.9649 - val_loss: 0.0545 - val_accuracy: 0.9815 - lr: 1.0000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0935 - accuracy: 0.9682 - val_loss: 0.0606 - val_accuracy: 0.9797 - lr: 1.0000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0947 - accuracy: 0.9666 - val_loss: 0.0541 - val_accuracy: 0.9821 - lr: 1.0000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0837 - accuracy: 0.9707 - val_loss: 0.0528 - val_accuracy: 0.9821 - lr: 1.0000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0852 - accuracy: 0.9703 - val_loss: 0.0454 - val_accuracy: 0.9837 - lr: 1.0000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0776 - accuracy: 0.9728 - val_loss: 0.0437 - val_accuracy: 0.9854 - lr: 1.0000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0757 - accuracy: 0.9736 - val_loss: 0.0432 - val_accuracy: 0.9858 - lr: 1.0000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0725 - accuracy: 0.9750 - val_loss: 0.0461 - val_accuracy: 0.9851 - lr: 1.0000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0719 - accuracy: 0.9747 - val_loss: 0.0387 - val_accuracy: 0.9884 - lr: 1.0000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0672 - accuracy: 0.9770 - val_loss: 0.0360 - val_accuracy: 0.9889 - lr: 1.0000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0670 - accuracy: 0.9768 - val_loss: 0.0361 - val_accuracy: 0.9871 - lr: 1.0000e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0627 - accuracy: 0.9782 - val_loss: 0.0376 - val_accuracy: 0.9884 - lr: 1.0000e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0612 - accuracy: 0.9789 - val_loss: 0.0397 - val_accuracy: 0.9879 - lr: 1.0000e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0355 - accuracy: 0.9880 - val_loss: 0.0214 - val_accuracy: 0.9927 - lr: 5.0000e-05\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0329 - accuracy: 0.9889 - val_loss: 0.0250 - val_accuracy: 0.9922 - lr: 5.0000e-05\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0353 - accuracy: 0.9878 - val_loss: 0.0249 - val_accuracy: 0.9923 - lr: 5.0000e-05\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0328 - accuracy: 0.9886 - val_loss: 0.0223 - val_accuracy: 0.9927 - lr: 5.0000e-05\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0235 - accuracy: 0.9925 - val_loss: 0.0183 - val_accuracy: 0.9952 - lr: 2.5000e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.0159 - val_accuracy: 0.9950 - lr: 2.5000e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0218 - accuracy: 0.9929 - val_loss: 0.0173 - val_accuracy: 0.9947 - lr: 2.5000e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 0.0163 - val_accuracy: 0.9948 - lr: 2.5000e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0214 - accuracy: 0.9931 - val_loss: 0.0153 - val_accuracy: 0.9951 - lr: 2.5000e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.0158 - val_accuracy: 0.9949 - lr: 2.5000e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0202 - accuracy: 0.9934 - val_loss: 0.0141 - val_accuracy: 0.9956 - lr: 2.5000e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.0149 - val_accuracy: 0.9952 - lr: 2.5000e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0198 - accuracy: 0.9932 - val_loss: 0.0149 - val_accuracy: 0.9958 - lr: 2.5000e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.0137 - val_accuracy: 0.9961 - lr: 2.5000e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 0.0152 - val_accuracy: 0.9955 - lr: 2.5000e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0188 - accuracy: 0.9935 - val_loss: 0.0146 - val_accuracy: 0.9956 - lr: 2.5000e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.0152 - val_accuracy: 0.9951 - lr: 2.5000e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.0119 - val_accuracy: 0.9967 - lr: 1.2500e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.0117 - val_accuracy: 0.9965 - lr: 1.2500e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.0115 - val_accuracy: 0.9966 - lr: 1.2500e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.0123 - val_accuracy: 0.9963 - lr: 1.2500e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0122 - val_accuracy: 0.9965 - lr: 1.2500e-05\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0118 - val_accuracy: 0.9961 - lr: 1.2500e-05\n",
      "1033/1033 [==============================] - 9s 9ms/step - loss: 0.0099 - accuracy: 0.9971\n",
      "\n",
      "── Fold 2/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 45s 41ms/step - loss: 1.9177 - accuracy: 0.3283 - val_loss: 1.5947 - val_accuracy: 0.4370 - lr: 1.0000e-04\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 1.4370 - accuracy: 0.4979 - val_loss: 1.1137 - val_accuracy: 0.6129 - lr: 1.0000e-04\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 1.0612 - accuracy: 0.6351 - val_loss: 0.7744 - val_accuracy: 0.7316 - lr: 1.0000e-04\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.8222 - accuracy: 0.7194 - val_loss: 0.6087 - val_accuracy: 0.7928 - lr: 1.0000e-04\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.6708 - accuracy: 0.7713 - val_loss: 0.4878 - val_accuracy: 0.8353 - lr: 1.0000e-04\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.5604 - accuracy: 0.8094 - val_loss: 0.3962 - val_accuracy: 0.8691 - lr: 1.0000e-04\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.4769 - accuracy: 0.8361 - val_loss: 0.3403 - val_accuracy: 0.8853 - lr: 1.0000e-04\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.4137 - accuracy: 0.8568 - val_loss: 0.2788 - val_accuracy: 0.9036 - lr: 1.0000e-04\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.3649 - accuracy: 0.8734 - val_loss: 0.2598 - val_accuracy: 0.9094 - lr: 1.0000e-04\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.3217 - accuracy: 0.8886 - val_loss: 0.2128 - val_accuracy: 0.9266 - lr: 1.0000e-04\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.2854 - accuracy: 0.9017 - val_loss: 0.1908 - val_accuracy: 0.9359 - lr: 1.0000e-04\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.2595 - accuracy: 0.9108 - val_loss: 0.1637 - val_accuracy: 0.9426 - lr: 1.0000e-04\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.2343 - accuracy: 0.9192 - val_loss: 0.1627 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.2141 - accuracy: 0.9255 - val_loss: 0.1478 - val_accuracy: 0.9484 - lr: 1.0000e-04\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1947 - accuracy: 0.9331 - val_loss: 0.1199 - val_accuracy: 0.9582 - lr: 1.0000e-04\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1778 - accuracy: 0.9381 - val_loss: 0.1066 - val_accuracy: 0.9632 - lr: 1.0000e-04\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1648 - accuracy: 0.9422 - val_loss: 0.0987 - val_accuracy: 0.9678 - lr: 1.0000e-04\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1541 - accuracy: 0.9457 - val_loss: 0.0970 - val_accuracy: 0.9675 - lr: 1.0000e-04\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1437 - accuracy: 0.9492 - val_loss: 0.0897 - val_accuracy: 0.9713 - lr: 1.0000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1326 - accuracy: 0.9544 - val_loss: 0.0839 - val_accuracy: 0.9720 - lr: 1.0000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1275 - accuracy: 0.9560 - val_loss: 0.0833 - val_accuracy: 0.9724 - lr: 1.0000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1164 - accuracy: 0.9595 - val_loss: 0.0834 - val_accuracy: 0.9714 - lr: 1.0000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1101 - accuracy: 0.9615 - val_loss: 0.0701 - val_accuracy: 0.9768 - lr: 1.0000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.1034 - accuracy: 0.9641 - val_loss: 0.0624 - val_accuracy: 0.9792 - lr: 1.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1001 - accuracy: 0.9653 - val_loss: 0.0588 - val_accuracy: 0.9807 - lr: 1.0000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0925 - accuracy: 0.9677 - val_loss: 0.0583 - val_accuracy: 0.9804 - lr: 1.0000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0898 - accuracy: 0.9687 - val_loss: 0.0591 - val_accuracy: 0.9798 - lr: 1.0000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0831 - accuracy: 0.9711 - val_loss: 0.0510 - val_accuracy: 0.9827 - lr: 1.0000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0827 - accuracy: 0.9714 - val_loss: 0.0446 - val_accuracy: 0.9859 - lr: 1.0000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0771 - accuracy: 0.9730 - val_loss: 0.0474 - val_accuracy: 0.9853 - lr: 1.0000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0778 - accuracy: 0.9725 - val_loss: 0.0404 - val_accuracy: 0.9860 - lr: 1.0000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0720 - accuracy: 0.9748 - val_loss: 0.0460 - val_accuracy: 0.9850 - lr: 1.0000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0723 - accuracy: 0.9749 - val_loss: 0.0424 - val_accuracy: 0.9860 - lr: 1.0000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0667 - accuracy: 0.9767 - val_loss: 0.0536 - val_accuracy: 0.9825 - lr: 1.0000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0400 - accuracy: 0.9866 - val_loss: 0.0280 - val_accuracy: 0.9897 - lr: 5.0000e-05\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0365 - accuracy: 0.9876 - val_loss: 0.0262 - val_accuracy: 0.9915 - lr: 5.0000e-05\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0375 - accuracy: 0.9871 - val_loss: 0.0232 - val_accuracy: 0.9924 - lr: 5.0000e-05\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0369 - accuracy: 0.9869 - val_loss: 0.0224 - val_accuracy: 0.9922 - lr: 5.0000e-05\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0379 - accuracy: 0.9872 - val_loss: 0.0203 - val_accuracy: 0.9936 - lr: 5.0000e-05\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0337 - accuracy: 0.9885 - val_loss: 0.0252 - val_accuracy: 0.9922 - lr: 5.0000e-05\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0339 - accuracy: 0.9886 - val_loss: 0.0209 - val_accuracy: 0.9940 - lr: 5.0000e-05\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0325 - accuracy: 0.9886 - val_loss: 0.0216 - val_accuracy: 0.9935 - lr: 5.0000e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0221 - accuracy: 0.9927 - val_loss: 0.0155 - val_accuracy: 0.9952 - lr: 2.5000e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0221 - accuracy: 0.9930 - val_loss: 0.0155 - val_accuracy: 0.9952 - lr: 2.5000e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 0.0152 - val_accuracy: 0.9948 - lr: 2.5000e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0207 - accuracy: 0.9935 - val_loss: 0.0135 - val_accuracy: 0.9960 - lr: 2.5000e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.0143 - val_accuracy: 0.9964 - lr: 2.5000e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0203 - accuracy: 0.9930 - val_loss: 0.0145 - val_accuracy: 0.9953 - lr: 2.5000e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 0.0149 - val_accuracy: 0.9955 - lr: 2.5000e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.0120 - val_accuracy: 0.9967 - lr: 1.2500e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.0115 - val_accuracy: 0.9966 - lr: 1.2500e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.0121 - val_accuracy: 0.9964 - lr: 1.2500e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.0109 - val_accuracy: 0.9966 - lr: 1.2500e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.0108 - val_accuracy: 0.9967 - lr: 1.2500e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0136 - accuracy: 0.9955 - val_loss: 0.0114 - val_accuracy: 0.9969 - lr: 1.2500e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0144 - accuracy: 0.9952 - val_loss: 0.0108 - val_accuracy: 0.9968 - lr: 1.2500e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.0105 - val_accuracy: 0.9971 - lr: 6.2500e-06\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.0105 - val_accuracy: 0.9967 - lr: 6.2500e-06\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 0.0110 - val_accuracy: 0.9968 - lr: 6.2500e-06\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.0098 - val_accuracy: 0.9967 - lr: 6.2500e-06\n",
      "1033/1033 [==============================] - 9s 8ms/step - loss: 0.0119 - accuracy: 0.9967\n",
      "\n",
      "── Fold 3/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 44s 41ms/step - loss: 1.9307 - accuracy: 0.3226 - val_loss: 1.5794 - val_accuracy: 0.4443 - lr: 1.0000e-04\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 1.4280 - accuracy: 0.4987 - val_loss: 1.0615 - val_accuracy: 0.6397 - lr: 1.0000e-04\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 1.0322 - accuracy: 0.6447 - val_loss: 0.7451 - val_accuracy: 0.7519 - lr: 1.0000e-04\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.7940 - accuracy: 0.7274 - val_loss: 0.5864 - val_accuracy: 0.8035 - lr: 1.0000e-04\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.6458 - accuracy: 0.7791 - val_loss: 0.4598 - val_accuracy: 0.8484 - lr: 1.0000e-04\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.5338 - accuracy: 0.8169 - val_loss: 0.3892 - val_accuracy: 0.8688 - lr: 1.0000e-04\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.4633 - accuracy: 0.8401 - val_loss: 0.3247 - val_accuracy: 0.8889 - lr: 1.0000e-04\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.4010 - accuracy: 0.8629 - val_loss: 0.2894 - val_accuracy: 0.9001 - lr: 1.0000e-04\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.3506 - accuracy: 0.8790 - val_loss: 0.2392 - val_accuracy: 0.9175 - lr: 1.0000e-04\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.3137 - accuracy: 0.8915 - val_loss: 0.2074 - val_accuracy: 0.9291 - lr: 1.0000e-04\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.2823 - accuracy: 0.9022 - val_loss: 0.1879 - val_accuracy: 0.9347 - lr: 1.0000e-04\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.2499 - accuracy: 0.9129 - val_loss: 0.1705 - val_accuracy: 0.9417 - lr: 1.0000e-04\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.2259 - accuracy: 0.9213 - val_loss: 0.1590 - val_accuracy: 0.9449 - lr: 1.0000e-04\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.2059 - accuracy: 0.9276 - val_loss: 0.1410 - val_accuracy: 0.9513 - lr: 1.0000e-04\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1885 - accuracy: 0.9341 - val_loss: 0.1214 - val_accuracy: 0.9599 - lr: 1.0000e-04\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1760 - accuracy: 0.9386 - val_loss: 0.1119 - val_accuracy: 0.9635 - lr: 1.0000e-04\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1612 - accuracy: 0.9439 - val_loss: 0.0924 - val_accuracy: 0.9701 - lr: 1.0000e-04\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.1512 - accuracy: 0.9473 - val_loss: 0.0926 - val_accuracy: 0.9683 - lr: 1.0000e-04\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1403 - accuracy: 0.9510 - val_loss: 0.0886 - val_accuracy: 0.9701 - lr: 1.0000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1310 - accuracy: 0.9540 - val_loss: 0.0769 - val_accuracy: 0.9731 - lr: 1.0000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1227 - accuracy: 0.9574 - val_loss: 0.0785 - val_accuracy: 0.9731 - lr: 1.0000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1149 - accuracy: 0.9599 - val_loss: 0.0769 - val_accuracy: 0.9742 - lr: 1.0000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1091 - accuracy: 0.9619 - val_loss: 0.0723 - val_accuracy: 0.9768 - lr: 1.0000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1042 - accuracy: 0.9638 - val_loss: 0.0670 - val_accuracy: 0.9774 - lr: 1.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0975 - accuracy: 0.9659 - val_loss: 0.0689 - val_accuracy: 0.9772 - lr: 1.0000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0927 - accuracy: 0.9674 - val_loss: 0.0569 - val_accuracy: 0.9812 - lr: 1.0000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0903 - accuracy: 0.9687 - val_loss: 0.0668 - val_accuracy: 0.9778 - lr: 1.0000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0867 - accuracy: 0.9694 - val_loss: 0.0672 - val_accuracy: 0.9758 - lr: 1.0000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0832 - accuracy: 0.9707 - val_loss: 0.0558 - val_accuracy: 0.9823 - lr: 1.0000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0779 - accuracy: 0.9726 - val_loss: 0.0546 - val_accuracy: 0.9814 - lr: 1.0000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0725 - accuracy: 0.9746 - val_loss: 0.0622 - val_accuracy: 0.9787 - lr: 1.0000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0721 - accuracy: 0.9749 - val_loss: 0.0413 - val_accuracy: 0.9866 - lr: 1.0000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0699 - accuracy: 0.9753 - val_loss: 0.0495 - val_accuracy: 0.9841 - lr: 1.0000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0650 - accuracy: 0.9774 - val_loss: 0.0484 - val_accuracy: 0.9841 - lr: 1.0000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0659 - accuracy: 0.9774 - val_loss: 0.0474 - val_accuracy: 0.9844 - lr: 1.0000e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0375 - accuracy: 0.9871 - val_loss: 0.0278 - val_accuracy: 0.9908 - lr: 5.0000e-05\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0346 - accuracy: 0.9886 - val_loss: 0.0278 - val_accuracy: 0.9914 - lr: 5.0000e-05\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0360 - accuracy: 0.9878 - val_loss: 0.0273 - val_accuracy: 0.9911 - lr: 5.0000e-05\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0346 - accuracy: 0.9883 - val_loss: 0.0296 - val_accuracy: 0.9905 - lr: 5.0000e-05\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0360 - accuracy: 0.9878 - val_loss: 0.0273 - val_accuracy: 0.9915 - lr: 5.0000e-05\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0320 - accuracy: 0.9891 - val_loss: 0.0293 - val_accuracy: 0.9910 - lr: 5.0000e-05\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0233 - accuracy: 0.9924 - val_loss: 0.0227 - val_accuracy: 0.9933 - lr: 2.5000e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.0212 - val_accuracy: 0.9944 - lr: 2.5000e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0215 - accuracy: 0.9928 - val_loss: 0.0192 - val_accuracy: 0.9946 - lr: 2.5000e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 0.0229 - val_accuracy: 0.9935 - lr: 2.5000e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0206 - accuracy: 0.9930 - val_loss: 0.0226 - val_accuracy: 0.9935 - lr: 2.5000e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.0193 - val_accuracy: 0.9950 - lr: 2.5000e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0158 - accuracy: 0.9950 - val_loss: 0.0173 - val_accuracy: 0.9955 - lr: 1.2500e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 0.0168 - val_accuracy: 0.9955 - lr: 1.2500e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.0169 - val_accuracy: 0.9949 - lr: 1.2500e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.0180 - val_accuracy: 0.9952 - lr: 1.2500e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0170 - val_accuracy: 0.9954 - lr: 1.2500e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.0169 - val_accuracy: 0.9952 - lr: 6.2500e-06\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.0168 - val_accuracy: 0.9958 - lr: 6.2500e-06\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.0172 - val_accuracy: 0.9955 - lr: 6.2500e-06\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0175 - val_accuracy: 0.9948 - lr: 3.1250e-06\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0168 - val_accuracy: 0.9953 - lr: 3.1250e-06\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.0168 - val_accuracy: 0.9952 - lr: 3.1250e-06\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.0164 - val_accuracy: 0.9956 - lr: 1.5625e-06\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0160 - val_accuracy: 0.9956 - lr: 1.5625e-06\n",
      "1033/1033 [==============================] - 9s 9ms/step - loss: 0.0105 - accuracy: 0.9967\n",
      "\n",
      "── Fold 4/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 44s 42ms/step - loss: 1.9301 - accuracy: 0.3249 - val_loss: 1.5561 - val_accuracy: 0.4589 - lr: 1.0000e-04\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 1.4036 - accuracy: 0.5123 - val_loss: 1.0931 - val_accuracy: 0.6280 - lr: 1.0000e-04\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 1.0363 - accuracy: 0.6461 - val_loss: 0.7731 - val_accuracy: 0.7419 - lr: 1.0000e-04\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.8017 - accuracy: 0.7267 - val_loss: 0.6027 - val_accuracy: 0.7980 - lr: 1.0000e-04\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.6541 - accuracy: 0.7773 - val_loss: 0.4855 - val_accuracy: 0.8331 - lr: 1.0000e-04\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.5478 - accuracy: 0.8138 - val_loss: 0.3831 - val_accuracy: 0.8708 - lr: 1.0000e-04\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.4654 - accuracy: 0.8404 - val_loss: 0.3373 - val_accuracy: 0.8853 - lr: 1.0000e-04\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.4029 - accuracy: 0.8615 - val_loss: 0.2744 - val_accuracy: 0.9055 - lr: 1.0000e-04\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.3510 - accuracy: 0.8780 - val_loss: 0.2644 - val_accuracy: 0.9105 - lr: 1.0000e-04\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.3108 - accuracy: 0.8909 - val_loss: 0.2209 - val_accuracy: 0.9241 - lr: 1.0000e-04\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.2807 - accuracy: 0.9022 - val_loss: 0.1933 - val_accuracy: 0.9337 - lr: 1.0000e-04\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.2511 - accuracy: 0.9128 - val_loss: 0.1632 - val_accuracy: 0.9440 - lr: 1.0000e-04\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.2254 - accuracy: 0.9217 - val_loss: 0.1484 - val_accuracy: 0.9502 - lr: 1.0000e-04\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.2076 - accuracy: 0.9281 - val_loss: 0.1228 - val_accuracy: 0.9604 - lr: 1.0000e-04\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1893 - accuracy: 0.9345 - val_loss: 0.1209 - val_accuracy: 0.9589 - lr: 1.0000e-04\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1803 - accuracy: 0.9377 - val_loss: 0.1133 - val_accuracy: 0.9628 - lr: 1.0000e-04\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.1612 - accuracy: 0.9443 - val_loss: 0.0964 - val_accuracy: 0.9679 - lr: 1.0000e-04\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.1513 - accuracy: 0.9467 - val_loss: 0.0880 - val_accuracy: 0.9710 - lr: 1.0000e-04\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1383 - accuracy: 0.9523 - val_loss: 0.0896 - val_accuracy: 0.9696 - lr: 1.0000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1301 - accuracy: 0.9540 - val_loss: 0.0816 - val_accuracy: 0.9738 - lr: 1.0000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.1237 - accuracy: 0.9566 - val_loss: 0.0738 - val_accuracy: 0.9756 - lr: 1.0000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.1148 - accuracy: 0.9596 - val_loss: 0.0702 - val_accuracy: 0.9769 - lr: 1.0000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.1084 - accuracy: 0.9626 - val_loss: 0.0802 - val_accuracy: 0.9750 - lr: 1.0000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.1013 - accuracy: 0.9650 - val_loss: 0.0757 - val_accuracy: 0.9754 - lr: 1.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0987 - accuracy: 0.9654 - val_loss: 0.0575 - val_accuracy: 0.9822 - lr: 1.0000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0932 - accuracy: 0.9676 - val_loss: 0.0634 - val_accuracy: 0.9807 - lr: 1.0000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0879 - accuracy: 0.9694 - val_loss: 0.0504 - val_accuracy: 0.9829 - lr: 1.0000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0840 - accuracy: 0.9708 - val_loss: 0.0587 - val_accuracy: 0.9800 - lr: 1.0000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0792 - accuracy: 0.9726 - val_loss: 0.0459 - val_accuracy: 0.9865 - lr: 1.0000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0788 - accuracy: 0.9727 - val_loss: 0.0521 - val_accuracy: 0.9831 - lr: 1.0000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0738 - accuracy: 0.9746 - val_loss: 0.0479 - val_accuracy: 0.9842 - lr: 1.0000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0703 - accuracy: 0.9756 - val_loss: 0.0499 - val_accuracy: 0.9833 - lr: 1.0000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0429 - accuracy: 0.9856 - val_loss: 0.0309 - val_accuracy: 0.9904 - lr: 5.0000e-05\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0403 - accuracy: 0.9863 - val_loss: 0.0287 - val_accuracy: 0.9915 - lr: 5.0000e-05\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0398 - accuracy: 0.9863 - val_loss: 0.0294 - val_accuracy: 0.9912 - lr: 5.0000e-05\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0404 - accuracy: 0.9861 - val_loss: 0.0306 - val_accuracy: 0.9910 - lr: 5.0000e-05\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0395 - accuracy: 0.9859 - val_loss: 0.0254 - val_accuracy: 0.9927 - lr: 5.0000e-05\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0383 - accuracy: 0.9870 - val_loss: 0.0276 - val_accuracy: 0.9909 - lr: 5.0000e-05\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0368 - accuracy: 0.9877 - val_loss: 0.0250 - val_accuracy: 0.9927 - lr: 5.0000e-05\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0353 - accuracy: 0.9881 - val_loss: 0.0235 - val_accuracy: 0.9930 - lr: 5.0000e-05\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0357 - accuracy: 0.9876 - val_loss: 0.0241 - val_accuracy: 0.9929 - lr: 5.0000e-05\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0340 - accuracy: 0.9886 - val_loss: 0.0262 - val_accuracy: 0.9923 - lr: 5.0000e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0335 - accuracy: 0.9886 - val_loss: 0.0246 - val_accuracy: 0.9925 - lr: 5.0000e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0220 - accuracy: 0.9928 - val_loss: 0.0191 - val_accuracy: 0.9949 - lr: 2.5000e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0204 - accuracy: 0.9934 - val_loss: 0.0191 - val_accuracy: 0.9949 - lr: 2.5000e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0218 - accuracy: 0.9924 - val_loss: 0.0165 - val_accuracy: 0.9956 - lr: 2.5000e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.0167 - val_accuracy: 0.9955 - lr: 2.5000e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0216 - accuracy: 0.9929 - val_loss: 0.0174 - val_accuracy: 0.9950 - lr: 2.5000e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.0181 - val_accuracy: 0.9954 - lr: 2.5000e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.0152 - val_accuracy: 0.9961 - lr: 1.2500e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0152 - accuracy: 0.9950 - val_loss: 0.0146 - val_accuracy: 0.9964 - lr: 1.2500e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.0148 - val_accuracy: 0.9963 - lr: 1.2500e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0154 - accuracy: 0.9950 - val_loss: 0.0156 - val_accuracy: 0.9956 - lr: 1.2500e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.0142 - val_accuracy: 0.9964 - lr: 1.2500e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.0156 - val_accuracy: 0.9960 - lr: 1.2500e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0137 - val_accuracy: 0.9964 - lr: 1.2500e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0143 - accuracy: 0.9955 - val_loss: 0.0144 - val_accuracy: 0.9961 - lr: 1.2500e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.0141 - val_accuracy: 0.9964 - lr: 1.2500e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 0.0146 - val_accuracy: 0.9964 - lr: 1.2500e-05\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.0133 - val_accuracy: 0.9971 - lr: 6.2500e-06\n",
      "1033/1033 [==============================] - 9s 9ms/step - loss: 0.0105 - accuracy: 0.9970\n",
      "\n",
      "── Fold 5/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 45s 42ms/step - loss: 1.9229 - accuracy: 0.3249 - val_loss: 1.5219 - val_accuracy: 0.4632 - lr: 1.0000e-04\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 1.3667 - accuracy: 0.5227 - val_loss: 0.9936 - val_accuracy: 0.6614 - lr: 1.0000e-04\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.9836 - accuracy: 0.6629 - val_loss: 0.7243 - val_accuracy: 0.7509 - lr: 1.0000e-04\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.7611 - accuracy: 0.7398 - val_loss: 0.5439 - val_accuracy: 0.8201 - lr: 1.0000e-04\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.6232 - accuracy: 0.7869 - val_loss: 0.4431 - val_accuracy: 0.8532 - lr: 1.0000e-04\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.5190 - accuracy: 0.8226 - val_loss: 0.3652 - val_accuracy: 0.8793 - lr: 1.0000e-04\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.4463 - accuracy: 0.8465 - val_loss: 0.3254 - val_accuracy: 0.8906 - lr: 1.0000e-04\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.3876 - accuracy: 0.8670 - val_loss: 0.2617 - val_accuracy: 0.9129 - lr: 1.0000e-04\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.3402 - accuracy: 0.8824 - val_loss: 0.2232 - val_accuracy: 0.9238 - lr: 1.0000e-04\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.3015 - accuracy: 0.8948 - val_loss: 0.1941 - val_accuracy: 0.9358 - lr: 1.0000e-04\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.2699 - accuracy: 0.9068 - val_loss: 0.1644 - val_accuracy: 0.9434 - lr: 1.0000e-04\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.2461 - accuracy: 0.9138 - val_loss: 0.1579 - val_accuracy: 0.9489 - lr: 1.0000e-04\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.2224 - accuracy: 0.9223 - val_loss: 0.1334 - val_accuracy: 0.9564 - lr: 1.0000e-04\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.2027 - accuracy: 0.9293 - val_loss: 0.1278 - val_accuracy: 0.9569 - lr: 1.0000e-04\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1852 - accuracy: 0.9352 - val_loss: 0.1112 - val_accuracy: 0.9631 - lr: 1.0000e-04\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1694 - accuracy: 0.9411 - val_loss: 0.1125 - val_accuracy: 0.9599 - lr: 1.0000e-04\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1598 - accuracy: 0.9437 - val_loss: 0.1158 - val_accuracy: 0.9611 - lr: 1.0000e-04\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1440 - accuracy: 0.9500 - val_loss: 0.0887 - val_accuracy: 0.9720 - lr: 1.0000e-04\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1327 - accuracy: 0.9536 - val_loss: 0.0842 - val_accuracy: 0.9717 - lr: 1.0000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1265 - accuracy: 0.9555 - val_loss: 0.0743 - val_accuracy: 0.9762 - lr: 1.0000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1192 - accuracy: 0.9585 - val_loss: 0.0690 - val_accuracy: 0.9750 - lr: 1.0000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1120 - accuracy: 0.9607 - val_loss: 0.0794 - val_accuracy: 0.9748 - lr: 1.0000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1060 - accuracy: 0.9635 - val_loss: 0.0765 - val_accuracy: 0.9736 - lr: 1.0000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1037 - accuracy: 0.9635 - val_loss: 0.0650 - val_accuracy: 0.9787 - lr: 1.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0954 - accuracy: 0.9671 - val_loss: 0.0597 - val_accuracy: 0.9802 - lr: 1.0000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0888 - accuracy: 0.9691 - val_loss: 0.0502 - val_accuracy: 0.9822 - lr: 1.0000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0878 - accuracy: 0.9693 - val_loss: 0.0579 - val_accuracy: 0.9808 - lr: 1.0000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0830 - accuracy: 0.9708 - val_loss: 0.0542 - val_accuracy: 0.9811 - lr: 1.0000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0812 - accuracy: 0.9718 - val_loss: 0.0586 - val_accuracy: 0.9807 - lr: 1.0000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0492 - accuracy: 0.9836 - val_loss: 0.0279 - val_accuracy: 0.9913 - lr: 5.0000e-05\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0460 - accuracy: 0.9845 - val_loss: 0.0295 - val_accuracy: 0.9907 - lr: 5.0000e-05\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0473 - accuracy: 0.9837 - val_loss: 0.0254 - val_accuracy: 0.9914 - lr: 5.0000e-05\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0454 - accuracy: 0.9842 - val_loss: 0.0307 - val_accuracy: 0.9895 - lr: 5.0000e-05\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0458 - accuracy: 0.9845 - val_loss: 0.0298 - val_accuracy: 0.9896 - lr: 5.0000e-05\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0436 - accuracy: 0.9850 - val_loss: 0.0297 - val_accuracy: 0.9899 - lr: 5.0000e-05\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0306 - accuracy: 0.9896 - val_loss: 0.0200 - val_accuracy: 0.9930 - lr: 2.5000e-05\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0290 - accuracy: 0.9901 - val_loss: 0.0186 - val_accuracy: 0.9937 - lr: 2.5000e-05\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0288 - accuracy: 0.9903 - val_loss: 0.0179 - val_accuracy: 0.9943 - lr: 2.5000e-05\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0279 - accuracy: 0.9904 - val_loss: 0.0194 - val_accuracy: 0.9939 - lr: 2.5000e-05\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0278 - accuracy: 0.9905 - val_loss: 0.0187 - val_accuracy: 0.9944 - lr: 2.5000e-05\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0270 - accuracy: 0.9910 - val_loss: 0.0175 - val_accuracy: 0.9942 - lr: 2.5000e-05\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 39s 41ms/step - loss: 0.0266 - accuracy: 0.9913 - val_loss: 0.0160 - val_accuracy: 0.9948 - lr: 2.5000e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0252 - accuracy: 0.9915 - val_loss: 0.0189 - val_accuracy: 0.9930 - lr: 2.5000e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0245 - accuracy: 0.9918 - val_loss: 0.0171 - val_accuracy: 0.9952 - lr: 2.5000e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0245 - accuracy: 0.9920 - val_loss: 0.0163 - val_accuracy: 0.9949 - lr: 2.5000e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 0.0147 - val_accuracy: 0.9951 - lr: 1.2500e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.0151 - val_accuracy: 0.9948 - lr: 1.2500e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 0.0144 - val_accuracy: 0.9958 - lr: 1.2500e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 0.0136 - val_accuracy: 0.9957 - lr: 1.2500e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.0149 - val_accuracy: 0.9952 - lr: 1.2500e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 0.0136 - val_accuracy: 0.9955 - lr: 1.2500e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0176 - accuracy: 0.9941 - val_loss: 0.0135 - val_accuracy: 0.9957 - lr: 1.2500e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0191 - accuracy: 0.9936 - val_loss: 0.0137 - val_accuracy: 0.9958 - lr: 1.2500e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0177 - accuracy: 0.9942 - val_loss: 0.0135 - val_accuracy: 0.9958 - lr: 1.2500e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 0.0132 - val_accuracy: 0.9957 - lr: 1.2500e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.0134 - val_accuracy: 0.9962 - lr: 1.2500e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.0131 - val_accuracy: 0.9956 - lr: 1.2500e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.0134 - val_accuracy: 0.9958 - lr: 1.2500e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.0121 - val_accuracy: 0.9961 - lr: 1.2500e-05\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0134 - val_accuracy: 0.9958 - lr: 1.2500e-05\n",
      "1033/1033 [==============================] - 9s 8ms/step - loss: 0.0135 - accuracy: 0.9957\n",
      "\n",
      "── Fold 6/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 45s 42ms/step - loss: 1.9339 - accuracy: 0.3227 - val_loss: 1.5943 - val_accuracy: 0.4309 - lr: 1.0000e-04\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 1.3916 - accuracy: 0.5138 - val_loss: 1.0496 - val_accuracy: 0.6358 - lr: 1.0000e-04\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 1.0208 - accuracy: 0.6499 - val_loss: 0.7532 - val_accuracy: 0.7449 - lr: 1.0000e-04\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.7934 - accuracy: 0.7289 - val_loss: 0.5711 - val_accuracy: 0.8107 - lr: 1.0000e-04\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.6479 - accuracy: 0.7796 - val_loss: 0.4693 - val_accuracy: 0.8394 - lr: 1.0000e-04\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.5449 - accuracy: 0.8139 - val_loss: 0.3872 - val_accuracy: 0.8681 - lr: 1.0000e-04\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.4652 - accuracy: 0.8404 - val_loss: 0.3316 - val_accuracy: 0.8872 - lr: 1.0000e-04\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.4047 - accuracy: 0.8609 - val_loss: 0.2962 - val_accuracy: 0.8992 - lr: 1.0000e-04\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.3555 - accuracy: 0.8777 - val_loss: 0.2521 - val_accuracy: 0.9152 - lr: 1.0000e-04\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.3143 - accuracy: 0.8910 - val_loss: 0.2000 - val_accuracy: 0.9313 - lr: 1.0000e-04\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.2833 - accuracy: 0.9019 - val_loss: 0.2303 - val_accuracy: 0.9197 - lr: 1.0000e-04\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.2538 - accuracy: 0.9116 - val_loss: 0.1758 - val_accuracy: 0.9400 - lr: 1.0000e-04\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.2270 - accuracy: 0.9213 - val_loss: 0.1513 - val_accuracy: 0.9486 - lr: 1.0000e-04\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.2089 - accuracy: 0.9276 - val_loss: 0.1445 - val_accuracy: 0.9503 - lr: 1.0000e-04\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.1923 - accuracy: 0.9329 - val_loss: 0.1173 - val_accuracy: 0.9594 - lr: 1.0000e-04\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.1733 - accuracy: 0.9399 - val_loss: 0.1102 - val_accuracy: 0.9627 - lr: 1.0000e-04\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.1612 - accuracy: 0.9441 - val_loss: 0.1012 - val_accuracy: 0.9657 - lr: 1.0000e-04\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.1482 - accuracy: 0.9485 - val_loss: 0.1004 - val_accuracy: 0.9629 - lr: 1.0000e-04\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.1386 - accuracy: 0.9516 - val_loss: 0.0845 - val_accuracy: 0.9697 - lr: 1.0000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.1304 - accuracy: 0.9548 - val_loss: 0.0966 - val_accuracy: 0.9672 - lr: 1.0000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.1230 - accuracy: 0.9575 - val_loss: 0.1102 - val_accuracy: 0.9625 - lr: 1.0000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.1119 - accuracy: 0.9606 - val_loss: 0.0807 - val_accuracy: 0.9716 - lr: 1.0000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1099 - accuracy: 0.9612 - val_loss: 0.0736 - val_accuracy: 0.9754 - lr: 1.0000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.1005 - accuracy: 0.9645 - val_loss: 0.0566 - val_accuracy: 0.9807 - lr: 1.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0982 - accuracy: 0.9660 - val_loss: 0.0593 - val_accuracy: 0.9812 - lr: 1.0000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0928 - accuracy: 0.9676 - val_loss: 0.0564 - val_accuracy: 0.9803 - lr: 1.0000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0865 - accuracy: 0.9698 - val_loss: 0.0485 - val_accuracy: 0.9855 - lr: 1.0000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0842 - accuracy: 0.9711 - val_loss: 0.0459 - val_accuracy: 0.9846 - lr: 1.0000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0806 - accuracy: 0.9714 - val_loss: 0.0546 - val_accuracy: 0.9816 - lr: 1.0000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0761 - accuracy: 0.9735 - val_loss: 0.0517 - val_accuracy: 0.9819 - lr: 1.0000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0746 - accuracy: 0.9737 - val_loss: 0.0482 - val_accuracy: 0.9837 - lr: 1.0000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0449 - accuracy: 0.9847 - val_loss: 0.0275 - val_accuracy: 0.9909 - lr: 5.0000e-05\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0436 - accuracy: 0.9850 - val_loss: 0.0305 - val_accuracy: 0.9902 - lr: 5.0000e-05\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0416 - accuracy: 0.9859 - val_loss: 0.0279 - val_accuracy: 0.9912 - lr: 5.0000e-05\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0403 - accuracy: 0.9864 - val_loss: 0.0300 - val_accuracy: 0.9907 - lr: 5.0000e-05\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0302 - accuracy: 0.9899 - val_loss: 0.0214 - val_accuracy: 0.9929 - lr: 2.5000e-05\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0282 - accuracy: 0.9911 - val_loss: 0.0217 - val_accuracy: 0.9931 - lr: 2.5000e-05\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 0.0207 - val_accuracy: 0.9946 - lr: 2.5000e-05\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0266 - accuracy: 0.9910 - val_loss: 0.0224 - val_accuracy: 0.9930 - lr: 2.5000e-05\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0272 - accuracy: 0.9908 - val_loss: 0.0225 - val_accuracy: 0.9927 - lr: 2.5000e-05\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0265 - accuracy: 0.9912 - val_loss: 0.0191 - val_accuracy: 0.9944 - lr: 2.5000e-05\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0253 - accuracy: 0.9916 - val_loss: 0.0188 - val_accuracy: 0.9945 - lr: 2.5000e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0242 - accuracy: 0.9918 - val_loss: 0.0186 - val_accuracy: 0.9947 - lr: 2.5000e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0246 - accuracy: 0.9918 - val_loss: 0.0198 - val_accuracy: 0.9939 - lr: 2.5000e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0232 - accuracy: 0.9925 - val_loss: 0.0205 - val_accuracy: 0.9936 - lr: 2.5000e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0234 - accuracy: 0.9920 - val_loss: 0.0193 - val_accuracy: 0.9943 - lr: 2.5000e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0192 - accuracy: 0.9941 - val_loss: 0.0155 - val_accuracy: 0.9955 - lr: 1.2500e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.0150 - val_accuracy: 0.9958 - lr: 1.2500e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0189 - accuracy: 0.9939 - val_loss: 0.0146 - val_accuracy: 0.9961 - lr: 1.2500e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 0.0155 - val_accuracy: 0.9955 - lr: 1.2500e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.0149 - val_accuracy: 0.9955 - lr: 1.2500e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.0148 - val_accuracy: 0.9960 - lr: 1.2500e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.0149 - val_accuracy: 0.9958 - lr: 6.2500e-06\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.0146 - val_accuracy: 0.9961 - lr: 6.2500e-06\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0143 - val_accuracy: 0.9961 - lr: 6.2500e-06\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.0138 - val_accuracy: 0.9965 - lr: 6.2500e-06\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.0145 - val_accuracy: 0.9958 - lr: 6.2500e-06\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0140 - val_accuracy: 0.9961 - lr: 6.2500e-06\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.0139 - val_accuracy: 0.9964 - lr: 6.2500e-06\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0135 - val_accuracy: 0.9963 - lr: 3.1250e-06\n",
      "1033/1033 [==============================] - 9s 9ms/step - loss: 0.0115 - accuracy: 0.9969\n",
      "\n",
      "── Fold 7/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 45s 42ms/step - loss: 1.9384 - accuracy: 0.3216 - val_loss: 1.5897 - val_accuracy: 0.4362 - lr: 1.0000e-04\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 1.4287 - accuracy: 0.4994 - val_loss: 1.0777 - val_accuracy: 0.6370 - lr: 1.0000e-04\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 1.0499 - accuracy: 0.6401 - val_loss: 0.7720 - val_accuracy: 0.7369 - lr: 1.0000e-04\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.8097 - accuracy: 0.7229 - val_loss: 0.5805 - val_accuracy: 0.8053 - lr: 1.0000e-04\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.6568 - accuracy: 0.7753 - val_loss: 0.4811 - val_accuracy: 0.8365 - lr: 1.0000e-04\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.5547 - accuracy: 0.8091 - val_loss: 0.3879 - val_accuracy: 0.8723 - lr: 1.0000e-04\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.4723 - accuracy: 0.8379 - val_loss: 0.3262 - val_accuracy: 0.8927 - lr: 1.0000e-04\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.4105 - accuracy: 0.8580 - val_loss: 0.2726 - val_accuracy: 0.9093 - lr: 1.0000e-04\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.3598 - accuracy: 0.8755 - val_loss: 0.2551 - val_accuracy: 0.9148 - lr: 1.0000e-04\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.3242 - accuracy: 0.8886 - val_loss: 0.2157 - val_accuracy: 0.9277 - lr: 1.0000e-04\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.2834 - accuracy: 0.9024 - val_loss: 0.1849 - val_accuracy: 0.9388 - lr: 1.0000e-04\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.2612 - accuracy: 0.9105 - val_loss: 0.1717 - val_accuracy: 0.9405 - lr: 1.0000e-04\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.2332 - accuracy: 0.9190 - val_loss: 0.1544 - val_accuracy: 0.9470 - lr: 1.0000e-04\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.2094 - accuracy: 0.9268 - val_loss: 0.1375 - val_accuracy: 0.9547 - lr: 1.0000e-04\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1957 - accuracy: 0.9314 - val_loss: 0.1335 - val_accuracy: 0.9560 - lr: 1.0000e-04\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1788 - accuracy: 0.9380 - val_loss: 0.1010 - val_accuracy: 0.9680 - lr: 1.0000e-04\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1676 - accuracy: 0.9421 - val_loss: 0.1005 - val_accuracy: 0.9660 - lr: 1.0000e-04\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1494 - accuracy: 0.9483 - val_loss: 0.0912 - val_accuracy: 0.9693 - lr: 1.0000e-04\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1410 - accuracy: 0.9505 - val_loss: 0.0776 - val_accuracy: 0.9735 - lr: 1.0000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1324 - accuracy: 0.9540 - val_loss: 0.0739 - val_accuracy: 0.9758 - lr: 1.0000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1219 - accuracy: 0.9578 - val_loss: 0.0685 - val_accuracy: 0.9772 - lr: 1.0000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1175 - accuracy: 0.9587 - val_loss: 0.0677 - val_accuracy: 0.9786 - lr: 1.0000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1094 - accuracy: 0.9613 - val_loss: 0.0659 - val_accuracy: 0.9764 - lr: 1.0000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1060 - accuracy: 0.9635 - val_loss: 0.0578 - val_accuracy: 0.9800 - lr: 1.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0964 - accuracy: 0.9669 - val_loss: 0.0596 - val_accuracy: 0.9804 - lr: 1.0000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0940 - accuracy: 0.9670 - val_loss: 0.0528 - val_accuracy: 0.9822 - lr: 1.0000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0895 - accuracy: 0.9689 - val_loss: 0.0591 - val_accuracy: 0.9795 - lr: 1.0000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0881 - accuracy: 0.9693 - val_loss: 0.0487 - val_accuracy: 0.9846 - lr: 1.0000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0822 - accuracy: 0.9711 - val_loss: 0.0467 - val_accuracy: 0.9851 - lr: 1.0000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0779 - accuracy: 0.9727 - val_loss: 0.0423 - val_accuracy: 0.9866 - lr: 1.0000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0773 - accuracy: 0.9734 - val_loss: 0.0366 - val_accuracy: 0.9897 - lr: 1.0000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0697 - accuracy: 0.9759 - val_loss: 0.0399 - val_accuracy: 0.9859 - lr: 1.0000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0692 - accuracy: 0.9762 - val_loss: 0.0361 - val_accuracy: 0.9884 - lr: 1.0000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0660 - accuracy: 0.9772 - val_loss: 0.0333 - val_accuracy: 0.9895 - lr: 1.0000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0660 - accuracy: 0.9767 - val_loss: 0.0350 - val_accuracy: 0.9887 - lr: 1.0000e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0628 - accuracy: 0.9782 - val_loss: 0.0319 - val_accuracy: 0.9894 - lr: 1.0000e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0590 - accuracy: 0.9795 - val_loss: 0.0336 - val_accuracy: 0.9886 - lr: 1.0000e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 39s 41ms/step - loss: 0.0566 - accuracy: 0.9805 - val_loss: 0.0322 - val_accuracy: 0.9899 - lr: 1.0000e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0585 - accuracy: 0.9799 - val_loss: 0.0457 - val_accuracy: 0.9855 - lr: 1.0000e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0320 - accuracy: 0.9893 - val_loss: 0.0218 - val_accuracy: 0.9933 - lr: 5.0000e-05\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0308 - accuracy: 0.9897 - val_loss: 0.0197 - val_accuracy: 0.9938 - lr: 5.0000e-05\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0295 - accuracy: 0.9899 - val_loss: 0.0159 - val_accuracy: 0.9959 - lr: 5.0000e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0297 - accuracy: 0.9898 - val_loss: 0.0199 - val_accuracy: 0.9938 - lr: 5.0000e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0282 - accuracy: 0.9903 - val_loss: 0.0180 - val_accuracy: 0.9948 - lr: 5.0000e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0298 - accuracy: 0.9896 - val_loss: 0.0194 - val_accuracy: 0.9946 - lr: 5.0000e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0196 - accuracy: 0.9935 - val_loss: 0.0144 - val_accuracy: 0.9958 - lr: 2.5000e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.0138 - val_accuracy: 0.9964 - lr: 2.5000e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.0138 - val_accuracy: 0.9963 - lr: 2.5000e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 0.0145 - val_accuracy: 0.9964 - lr: 2.5000e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0173 - accuracy: 0.9946 - val_loss: 0.0145 - val_accuracy: 0.9961 - lr: 2.5000e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 39s 41ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.0113 - val_accuracy: 0.9971 - lr: 1.2500e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.0114 - val_accuracy: 0.9971 - lr: 1.2500e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.0114 - val_accuracy: 0.9972 - lr: 1.2500e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.0111 - val_accuracy: 0.9973 - lr: 1.2500e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.0111 - val_accuracy: 0.9974 - lr: 1.2500e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.0113 - val_accuracy: 0.9971 - lr: 1.2500e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.0111 - val_accuracy: 0.9970 - lr: 1.2500e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.0109 - val_accuracy: 0.9974 - lr: 6.2500e-06\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.0107 - val_accuracy: 0.9974 - lr: 6.2500e-06\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.0114 - val_accuracy: 0.9971 - lr: 6.2500e-06\n",
      "1033/1033 [==============================] - 9s 9ms/step - loss: 0.0105 - accuracy: 0.9968\n",
      "\n",
      "── Fold 8/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 46s 42ms/step - loss: 1.9134 - accuracy: 0.3305 - val_loss: 1.5496 - val_accuracy: 0.4566 - lr: 1.0000e-04\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 1.3737 - accuracy: 0.5244 - val_loss: 1.0382 - val_accuracy: 0.6430 - lr: 1.0000e-04\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 1.0006 - accuracy: 0.6568 - val_loss: 0.7410 - val_accuracy: 0.7480 - lr: 1.0000e-04\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.7795 - accuracy: 0.7335 - val_loss: 0.5704 - val_accuracy: 0.8069 - lr: 1.0000e-04\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.6340 - accuracy: 0.7833 - val_loss: 0.4732 - val_accuracy: 0.8403 - lr: 1.0000e-04\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.5363 - accuracy: 0.8170 - val_loss: 0.3879 - val_accuracy: 0.8703 - lr: 1.0000e-04\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.4577 - accuracy: 0.8423 - val_loss: 0.3254 - val_accuracy: 0.8896 - lr: 1.0000e-04\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.4014 - accuracy: 0.8610 - val_loss: 0.2756 - val_accuracy: 0.9081 - lr: 1.0000e-04\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.3513 - accuracy: 0.8778 - val_loss: 0.2351 - val_accuracy: 0.9200 - lr: 1.0000e-04\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.3126 - accuracy: 0.8918 - val_loss: 0.2088 - val_accuracy: 0.9306 - lr: 1.0000e-04\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.2817 - accuracy: 0.9020 - val_loss: 0.1965 - val_accuracy: 0.9349 - lr: 1.0000e-04\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 39s 41ms/step - loss: 0.2544 - accuracy: 0.9118 - val_loss: 0.1633 - val_accuracy: 0.9449 - lr: 1.0000e-04\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.2315 - accuracy: 0.9189 - val_loss: 0.1620 - val_accuracy: 0.9464 - lr: 1.0000e-04\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 39s 41ms/step - loss: 0.2102 - accuracy: 0.9266 - val_loss: 0.1331 - val_accuracy: 0.9558 - lr: 1.0000e-04\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 39s 41ms/step - loss: 0.1894 - accuracy: 0.9336 - val_loss: 0.1205 - val_accuracy: 0.9612 - lr: 1.0000e-04\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1753 - accuracy: 0.9393 - val_loss: 0.1101 - val_accuracy: 0.9624 - lr: 1.0000e-04\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1651 - accuracy: 0.9428 - val_loss: 0.0862 - val_accuracy: 0.9734 - lr: 1.0000e-04\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1519 - accuracy: 0.9466 - val_loss: 0.0989 - val_accuracy: 0.9658 - lr: 1.0000e-04\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 39s 41ms/step - loss: 0.1414 - accuracy: 0.9502 - val_loss: 0.0923 - val_accuracy: 0.9680 - lr: 1.0000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 39s 42ms/step - loss: 0.1308 - accuracy: 0.9542 - val_loss: 0.0812 - val_accuracy: 0.9744 - lr: 1.0000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 39s 41ms/step - loss: 0.1236 - accuracy: 0.9563 - val_loss: 0.0747 - val_accuracy: 0.9744 - lr: 1.0000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1146 - accuracy: 0.9598 - val_loss: 0.0756 - val_accuracy: 0.9732 - lr: 1.0000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1103 - accuracy: 0.9610 - val_loss: 0.0703 - val_accuracy: 0.9769 - lr: 1.0000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1027 - accuracy: 0.9639 - val_loss: 0.0621 - val_accuracy: 0.9799 - lr: 1.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0952 - accuracy: 0.9669 - val_loss: 0.0614 - val_accuracy: 0.9799 - lr: 1.0000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0950 - accuracy: 0.9671 - val_loss: 0.0516 - val_accuracy: 0.9825 - lr: 1.0000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0918 - accuracy: 0.9682 - val_loss: 0.0534 - val_accuracy: 0.9830 - lr: 1.0000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0834 - accuracy: 0.9709 - val_loss: 0.0580 - val_accuracy: 0.9800 - lr: 1.0000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0803 - accuracy: 0.9719 - val_loss: 0.0516 - val_accuracy: 0.9829 - lr: 1.0000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0489 - accuracy: 0.9837 - val_loss: 0.0295 - val_accuracy: 0.9904 - lr: 5.0000e-05\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0480 - accuracy: 0.9837 - val_loss: 0.0279 - val_accuracy: 0.9905 - lr: 5.0000e-05\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0467 - accuracy: 0.9841 - val_loss: 0.0282 - val_accuracy: 0.9911 - lr: 5.0000e-05\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0450 - accuracy: 0.9847 - val_loss: 0.0290 - val_accuracy: 0.9908 - lr: 5.0000e-05\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0449 - accuracy: 0.9848 - val_loss: 0.0289 - val_accuracy: 0.9909 - lr: 5.0000e-05\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 39s 41ms/step - loss: 0.0326 - accuracy: 0.9890 - val_loss: 0.0202 - val_accuracy: 0.9934 - lr: 2.5000e-05\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0305 - accuracy: 0.9900 - val_loss: 0.0208 - val_accuracy: 0.9940 - lr: 2.5000e-05\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0296 - accuracy: 0.9900 - val_loss: 0.0190 - val_accuracy: 0.9937 - lr: 2.5000e-05\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0292 - accuracy: 0.9905 - val_loss: 0.0182 - val_accuracy: 0.9954 - lr: 2.5000e-05\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0290 - accuracy: 0.9906 - val_loss: 0.0191 - val_accuracy: 0.9944 - lr: 2.5000e-05\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0287 - accuracy: 0.9902 - val_loss: 0.0178 - val_accuracy: 0.9947 - lr: 2.5000e-05\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0274 - accuracy: 0.9908 - val_loss: 0.0189 - val_accuracy: 0.9951 - lr: 2.5000e-05\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0268 - accuracy: 0.9909 - val_loss: 0.0184 - val_accuracy: 0.9939 - lr: 2.5000e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0270 - accuracy: 0.9908 - val_loss: 0.0177 - val_accuracy: 0.9954 - lr: 2.5000e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0207 - accuracy: 0.9935 - val_loss: 0.0157 - val_accuracy: 0.9964 - lr: 1.2500e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0216 - accuracy: 0.9927 - val_loss: 0.0160 - val_accuracy: 0.9958 - lr: 1.2500e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0206 - accuracy: 0.9935 - val_loss: 0.0156 - val_accuracy: 0.9959 - lr: 1.2500e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 0.0145 - val_accuracy: 0.9964 - lr: 1.2500e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0203 - accuracy: 0.9934 - val_loss: 0.0150 - val_accuracy: 0.9961 - lr: 1.2500e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.0150 - val_accuracy: 0.9958 - lr: 1.2500e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.0144 - val_accuracy: 0.9961 - lr: 1.2500e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.0140 - val_accuracy: 0.9960 - lr: 6.2500e-06\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0165 - accuracy: 0.9946 - val_loss: 0.0133 - val_accuracy: 0.9960 - lr: 6.2500e-06\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0175 - accuracy: 0.9945 - val_loss: 0.0142 - val_accuracy: 0.9961 - lr: 6.2500e-06\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 0.0139 - val_accuracy: 0.9962 - lr: 6.2500e-06\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.0137 - val_accuracy: 0.9964 - lr: 6.2500e-06\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 39s 41ms/step - loss: 0.0156 - accuracy: 0.9952 - val_loss: 0.0131 - val_accuracy: 0.9967 - lr: 3.1250e-06\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.0137 - val_accuracy: 0.9962 - lr: 3.1250e-06\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0129 - val_accuracy: 0.9966 - lr: 3.1250e-06\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.0128 - val_accuracy: 0.9968 - lr: 3.1250e-06\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.0130 - val_accuracy: 0.9962 - lr: 3.1250e-06\n",
      "1033/1033 [==============================] - 9s 9ms/step - loss: 0.0114 - accuracy: 0.9971\n",
      "\n",
      "── Fold 9/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 44s 42ms/step - loss: 1.9140 - accuracy: 0.3308 - val_loss: 1.5177 - val_accuracy: 0.4694 - lr: 1.0000e-04\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 1.3727 - accuracy: 0.5227 - val_loss: 1.0360 - val_accuracy: 0.6424 - lr: 1.0000e-04\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.9886 - accuracy: 0.6586 - val_loss: 0.7383 - val_accuracy: 0.7481 - lr: 1.0000e-04\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.7682 - accuracy: 0.7374 - val_loss: 0.5604 - val_accuracy: 0.8094 - lr: 1.0000e-04\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.6219 - accuracy: 0.7867 - val_loss: 0.4208 - val_accuracy: 0.8594 - lr: 1.0000e-04\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.5201 - accuracy: 0.8214 - val_loss: 0.3542 - val_accuracy: 0.8813 - lr: 1.0000e-04\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.4452 - accuracy: 0.8458 - val_loss: 0.2947 - val_accuracy: 0.9036 - lr: 1.0000e-04\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.3854 - accuracy: 0.8683 - val_loss: 0.2531 - val_accuracy: 0.9163 - lr: 1.0000e-04\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.3403 - accuracy: 0.8829 - val_loss: 0.2175 - val_accuracy: 0.9247 - lr: 1.0000e-04\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.3025 - accuracy: 0.8951 - val_loss: 0.1909 - val_accuracy: 0.9359 - lr: 1.0000e-04\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.2679 - accuracy: 0.9074 - val_loss: 0.1648 - val_accuracy: 0.9442 - lr: 1.0000e-04\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.2418 - accuracy: 0.9163 - val_loss: 0.1534 - val_accuracy: 0.9480 - lr: 1.0000e-04\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.2150 - accuracy: 0.9253 - val_loss: 0.1404 - val_accuracy: 0.9517 - lr: 1.0000e-04\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.2011 - accuracy: 0.9299 - val_loss: 0.1367 - val_accuracy: 0.9529 - lr: 1.0000e-04\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1810 - accuracy: 0.9374 - val_loss: 0.1121 - val_accuracy: 0.9617 - lr: 1.0000e-04\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.1696 - accuracy: 0.9408 - val_loss: 0.1022 - val_accuracy: 0.9657 - lr: 1.0000e-04\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.1543 - accuracy: 0.9461 - val_loss: 0.0921 - val_accuracy: 0.9678 - lr: 1.0000e-04\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1458 - accuracy: 0.9488 - val_loss: 0.0811 - val_accuracy: 0.9724 - lr: 1.0000e-04\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1335 - accuracy: 0.9534 - val_loss: 0.0834 - val_accuracy: 0.9702 - lr: 1.0000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1232 - accuracy: 0.9573 - val_loss: 0.0716 - val_accuracy: 0.9764 - lr: 1.0000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1196 - accuracy: 0.9582 - val_loss: 0.0658 - val_accuracy: 0.9772 - lr: 1.0000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1108 - accuracy: 0.9618 - val_loss: 0.0624 - val_accuracy: 0.9788 - lr: 1.0000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1040 - accuracy: 0.9636 - val_loss: 0.0555 - val_accuracy: 0.9820 - lr: 1.0000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1010 - accuracy: 0.9649 - val_loss: 0.0576 - val_accuracy: 0.9804 - lr: 1.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0933 - accuracy: 0.9671 - val_loss: 0.0524 - val_accuracy: 0.9822 - lr: 1.0000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0924 - accuracy: 0.9679 - val_loss: 0.0715 - val_accuracy: 0.9741 - lr: 1.0000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0864 - accuracy: 0.9698 - val_loss: 0.0463 - val_accuracy: 0.9842 - lr: 1.0000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0808 - accuracy: 0.9720 - val_loss: 0.0495 - val_accuracy: 0.9832 - lr: 1.0000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0786 - accuracy: 0.9727 - val_loss: 0.0395 - val_accuracy: 0.9872 - lr: 1.0000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.0779 - accuracy: 0.9730 - val_loss: 0.0399 - val_accuracy: 0.9865 - lr: 1.0000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0720 - accuracy: 0.9749 - val_loss: 0.0424 - val_accuracy: 0.9860 - lr: 1.0000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0701 - accuracy: 0.9756 - val_loss: 0.0419 - val_accuracy: 0.9861 - lr: 1.0000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0414 - accuracy: 0.9860 - val_loss: 0.0239 - val_accuracy: 0.9918 - lr: 5.0000e-05\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0403 - accuracy: 0.9863 - val_loss: 0.0238 - val_accuracy: 0.9919 - lr: 5.0000e-05\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0398 - accuracy: 0.9865 - val_loss: 0.0269 - val_accuracy: 0.9913 - lr: 5.0000e-05\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0379 - accuracy: 0.9870 - val_loss: 0.0220 - val_accuracy: 0.9930 - lr: 5.0000e-05\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0354 - accuracy: 0.9877 - val_loss: 0.0204 - val_accuracy: 0.9932 - lr: 5.0000e-05\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0359 - accuracy: 0.9883 - val_loss: 0.0220 - val_accuracy: 0.9924 - lr: 5.0000e-05\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0352 - accuracy: 0.9874 - val_loss: 0.0241 - val_accuracy: 0.9917 - lr: 5.0000e-05\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0339 - accuracy: 0.9890 - val_loss: 0.0198 - val_accuracy: 0.9945 - lr: 5.0000e-05\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0337 - accuracy: 0.9888 - val_loss: 0.0201 - val_accuracy: 0.9933 - lr: 5.0000e-05\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0338 - accuracy: 0.9884 - val_loss: 0.0181 - val_accuracy: 0.9947 - lr: 5.0000e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0323 - accuracy: 0.9888 - val_loss: 0.0204 - val_accuracy: 0.9935 - lr: 5.0000e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0311 - accuracy: 0.9896 - val_loss: 0.0204 - val_accuracy: 0.9935 - lr: 5.0000e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0315 - accuracy: 0.9895 - val_loss: 0.0175 - val_accuracy: 0.9944 - lr: 5.0000e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0302 - accuracy: 0.9894 - val_loss: 0.0210 - val_accuracy: 0.9932 - lr: 5.0000e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0309 - accuracy: 0.9894 - val_loss: 0.0222 - val_accuracy: 0.9925 - lr: 5.0000e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0297 - accuracy: 0.9900 - val_loss: 0.0151 - val_accuracy: 0.9955 - lr: 5.0000e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0292 - accuracy: 0.9903 - val_loss: 0.0189 - val_accuracy: 0.9936 - lr: 5.0000e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0283 - accuracy: 0.9903 - val_loss: 0.0213 - val_accuracy: 0.9931 - lr: 5.0000e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0261 - accuracy: 0.9909 - val_loss: 0.0143 - val_accuracy: 0.9964 - lr: 5.0000e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0282 - accuracy: 0.9903 - val_loss: 0.0165 - val_accuracy: 0.9945 - lr: 5.0000e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0254 - accuracy: 0.9913 - val_loss: 0.0147 - val_accuracy: 0.9959 - lr: 5.0000e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0268 - accuracy: 0.9908 - val_loss: 0.0161 - val_accuracy: 0.9946 - lr: 5.0000e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0169 - accuracy: 0.9946 - val_loss: 0.0115 - val_accuracy: 0.9969 - lr: 2.5000e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.0110 - val_accuracy: 0.9972 - lr: 2.5000e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0158 - accuracy: 0.9948 - val_loss: 0.0103 - val_accuracy: 0.9974 - lr: 2.5000e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0161 - accuracy: 0.9948 - val_loss: 0.0118 - val_accuracy: 0.9961 - lr: 2.5000e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0158 - accuracy: 0.9948 - val_loss: 0.0132 - val_accuracy: 0.9960 - lr: 2.5000e-05\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0113 - val_accuracy: 0.9964 - lr: 2.5000e-05\n",
      "1033/1033 [==============================] - 9s 9ms/step - loss: 0.0128 - accuracy: 0.9958\n",
      "\n",
      "── Fold 10/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 46s 43ms/step - loss: 1.9053 - accuracy: 0.3320 - val_loss: 1.5163 - val_accuracy: 0.4592 - lr: 1.0000e-04\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 39s 41ms/step - loss: 1.3560 - accuracy: 0.5265 - val_loss: 1.0340 - val_accuracy: 0.6452 - lr: 1.0000e-04\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.9728 - accuracy: 0.6682 - val_loss: 0.7368 - val_accuracy: 0.7552 - lr: 1.0000e-04\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.7527 - accuracy: 0.7426 - val_loss: 0.5581 - val_accuracy: 0.8113 - lr: 1.0000e-04\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.6165 - accuracy: 0.7903 - val_loss: 0.4367 - val_accuracy: 0.8530 - lr: 1.0000e-04\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.5203 - accuracy: 0.8220 - val_loss: 0.3686 - val_accuracy: 0.8789 - lr: 1.0000e-04\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.4438 - accuracy: 0.8471 - val_loss: 0.3302 - val_accuracy: 0.8899 - lr: 1.0000e-04\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.3871 - accuracy: 0.8653 - val_loss: 0.2706 - val_accuracy: 0.9082 - lr: 1.0000e-04\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.3402 - accuracy: 0.8825 - val_loss: 0.2357 - val_accuracy: 0.9193 - lr: 1.0000e-04\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.3025 - accuracy: 0.8949 - val_loss: 0.2018 - val_accuracy: 0.9317 - lr: 1.0000e-04\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 39s 41ms/step - loss: 0.2724 - accuracy: 0.9060 - val_loss: 0.1670 - val_accuracy: 0.9433 - lr: 1.0000e-04\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.2425 - accuracy: 0.9154 - val_loss: 0.1599 - val_accuracy: 0.9451 - lr: 1.0000e-04\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.2239 - accuracy: 0.9222 - val_loss: 0.1552 - val_accuracy: 0.9475 - lr: 1.0000e-04\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.2016 - accuracy: 0.9298 - val_loss: 0.1282 - val_accuracy: 0.9561 - lr: 1.0000e-04\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1866 - accuracy: 0.9351 - val_loss: 0.1315 - val_accuracy: 0.9545 - lr: 1.0000e-04\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1703 - accuracy: 0.9407 - val_loss: 0.1233 - val_accuracy: 0.9557 - lr: 1.0000e-04\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1560 - accuracy: 0.9452 - val_loss: 0.0976 - val_accuracy: 0.9671 - lr: 1.0000e-04\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1497 - accuracy: 0.9470 - val_loss: 0.0918 - val_accuracy: 0.9691 - lr: 1.0000e-04\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1370 - accuracy: 0.9524 - val_loss: 0.0902 - val_accuracy: 0.9697 - lr: 1.0000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1302 - accuracy: 0.9548 - val_loss: 0.0735 - val_accuracy: 0.9743 - lr: 1.0000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1196 - accuracy: 0.9583 - val_loss: 0.0709 - val_accuracy: 0.9766 - lr: 1.0000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1112 - accuracy: 0.9611 - val_loss: 0.0841 - val_accuracy: 0.9713 - lr: 1.0000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1068 - accuracy: 0.9628 - val_loss: 0.0679 - val_accuracy: 0.9763 - lr: 1.0000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.1041 - accuracy: 0.9637 - val_loss: 0.0695 - val_accuracy: 0.9762 - lr: 1.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0964 - accuracy: 0.9664 - val_loss: 0.0560 - val_accuracy: 0.9818 - lr: 1.0000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0919 - accuracy: 0.9678 - val_loss: 0.0570 - val_accuracy: 0.9818 - lr: 1.0000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0885 - accuracy: 0.9689 - val_loss: 0.0580 - val_accuracy: 0.9788 - lr: 1.0000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0823 - accuracy: 0.9715 - val_loss: 0.0594 - val_accuracy: 0.9790 - lr: 1.0000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0527 - accuracy: 0.9823 - val_loss: 0.0319 - val_accuracy: 0.9890 - lr: 5.0000e-05\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0514 - accuracy: 0.9825 - val_loss: 0.0322 - val_accuracy: 0.9895 - lr: 5.0000e-05\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0480 - accuracy: 0.9835 - val_loss: 0.0332 - val_accuracy: 0.9890 - lr: 5.0000e-05\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0479 - accuracy: 0.9837 - val_loss: 0.0276 - val_accuracy: 0.9909 - lr: 5.0000e-05\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0453 - accuracy: 0.9849 - val_loss: 0.0271 - val_accuracy: 0.9905 - lr: 5.0000e-05\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0450 - accuracy: 0.9846 - val_loss: 0.0319 - val_accuracy: 0.9887 - lr: 5.0000e-05\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0425 - accuracy: 0.9858 - val_loss: 0.0250 - val_accuracy: 0.9913 - lr: 5.0000e-05\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0438 - accuracy: 0.9854 - val_loss: 0.0227 - val_accuracy: 0.9924 - lr: 5.0000e-05\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0419 - accuracy: 0.9858 - val_loss: 0.0252 - val_accuracy: 0.9912 - lr: 5.0000e-05\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0399 - accuracy: 0.9868 - val_loss: 0.0264 - val_accuracy: 0.9910 - lr: 5.0000e-05\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0391 - accuracy: 0.9867 - val_loss: 0.0248 - val_accuracy: 0.9915 - lr: 5.0000e-05\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0273 - accuracy: 0.9908 - val_loss: 0.0172 - val_accuracy: 0.9947 - lr: 2.5000e-05\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0256 - accuracy: 0.9914 - val_loss: 0.0172 - val_accuracy: 0.9935 - lr: 2.5000e-05\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0255 - accuracy: 0.9919 - val_loss: 0.0180 - val_accuracy: 0.9939 - lr: 2.5000e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0245 - accuracy: 0.9919 - val_loss: 0.0157 - val_accuracy: 0.9950 - lr: 2.5000e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0256 - accuracy: 0.9917 - val_loss: 0.0146 - val_accuracy: 0.9955 - lr: 2.5000e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0243 - accuracy: 0.9916 - val_loss: 0.0162 - val_accuracy: 0.9946 - lr: 2.5000e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0241 - accuracy: 0.9916 - val_loss: 0.0160 - val_accuracy: 0.9950 - lr: 2.5000e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0232 - accuracy: 0.9922 - val_loss: 0.0135 - val_accuracy: 0.9958 - lr: 2.5000e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0233 - accuracy: 0.9920 - val_loss: 0.0154 - val_accuracy: 0.9946 - lr: 2.5000e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0225 - accuracy: 0.9925 - val_loss: 0.0186 - val_accuracy: 0.9937 - lr: 2.5000e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0215 - accuracy: 0.9929 - val_loss: 0.0158 - val_accuracy: 0.9942 - lr: 2.5000e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0189 - accuracy: 0.9936 - val_loss: 0.0123 - val_accuracy: 0.9957 - lr: 1.2500e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.0122 - val_accuracy: 0.9958 - lr: 1.2500e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.0114 - val_accuracy: 0.9958 - lr: 1.2500e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0161 - accuracy: 0.9946 - val_loss: 0.0111 - val_accuracy: 0.9961 - lr: 1.2500e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 39s 41ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.0124 - val_accuracy: 0.9957 - lr: 1.2500e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0174 - accuracy: 0.9942 - val_loss: 0.0121 - val_accuracy: 0.9961 - lr: 1.2500e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0122 - val_accuracy: 0.9961 - lr: 1.2500e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.0115 - val_accuracy: 0.9961 - lr: 6.2500e-06\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 39s 41ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.0105 - val_accuracy: 0.9965 - lr: 6.2500e-06\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 38s 41ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.0113 - val_accuracy: 0.9960 - lr: 6.2500e-06\n",
      "1033/1033 [==============================] - 10s 9ms/step - loss: 0.0111 - accuracy: 0.9966\n",
      "\n",
      "################ EMGHandNet_Adaptado – 10-fold CV ################\n",
      "\n",
      "── Fold 1/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 20s 19ms/step - loss: 1.2411 - accuracy: 0.5765 - val_loss: 0.7156 - val_accuracy: 0.7538 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.6569 - accuracy: 0.7779 - val_loss: 0.4614 - val_accuracy: 0.8396 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.4825 - accuracy: 0.8340 - val_loss: 0.3455 - val_accuracy: 0.8809 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.3897 - accuracy: 0.8661 - val_loss: 0.2780 - val_accuracy: 0.9059 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.3318 - accuracy: 0.8847 - val_loss: 0.2294 - val_accuracy: 0.9209 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2905 - accuracy: 0.8980 - val_loss: 0.1992 - val_accuracy: 0.9303 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2596 - accuracy: 0.9084 - val_loss: 0.2235 - val_accuracy: 0.9217 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2361 - accuracy: 0.9175 - val_loss: 0.1985 - val_accuracy: 0.9325 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2167 - accuracy: 0.9236 - val_loss: 0.1401 - val_accuracy: 0.9517 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1995 - accuracy: 0.9298 - val_loss: 0.1282 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1863 - accuracy: 0.9342 - val_loss: 0.1094 - val_accuracy: 0.9624 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1740 - accuracy: 0.9380 - val_loss: 0.1211 - val_accuracy: 0.9566 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1641 - accuracy: 0.9420 - val_loss: 0.1023 - val_accuracy: 0.9641 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1569 - accuracy: 0.9447 - val_loss: 0.0990 - val_accuracy: 0.9652 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1505 - accuracy: 0.9462 - val_loss: 0.0891 - val_accuracy: 0.9690 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1419 - accuracy: 0.9491 - val_loss: 0.1152 - val_accuracy: 0.9589 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1323 - accuracy: 0.9539 - val_loss: 0.0829 - val_accuracy: 0.9710 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1304 - accuracy: 0.9533 - val_loss: 0.0664 - val_accuracy: 0.9781 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1243 - accuracy: 0.9558 - val_loss: 0.1040 - val_accuracy: 0.9640 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1219 - accuracy: 0.9567 - val_loss: 0.0599 - val_accuracy: 0.9798 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1167 - accuracy: 0.9590 - val_loss: 0.0644 - val_accuracy: 0.9774 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1148 - accuracy: 0.9590 - val_loss: 0.0795 - val_accuracy: 0.9722 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1076 - accuracy: 0.9618 - val_loss: 0.0662 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0774 - accuracy: 0.9732 - val_loss: 0.0353 - val_accuracy: 0.9884 - lr: 5.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0715 - accuracy: 0.9754 - val_loss: 0.0315 - val_accuracy: 0.9895 - lr: 5.0000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0688 - accuracy: 0.9758 - val_loss: 0.0313 - val_accuracy: 0.9903 - lr: 5.0000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0680 - accuracy: 0.9765 - val_loss: 0.0266 - val_accuracy: 0.9918 - lr: 5.0000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0633 - accuracy: 0.9778 - val_loss: 0.0292 - val_accuracy: 0.9907 - lr: 5.0000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0641 - accuracy: 0.9780 - val_loss: 0.0300 - val_accuracy: 0.9899 - lr: 5.0000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0633 - accuracy: 0.9779 - val_loss: 0.0330 - val_accuracy: 0.9881 - lr: 5.0000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0507 - accuracy: 0.9828 - val_loss: 0.0199 - val_accuracy: 0.9933 - lr: 2.5000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0468 - accuracy: 0.9837 - val_loss: 0.0172 - val_accuracy: 0.9948 - lr: 2.5000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0449 - accuracy: 0.9849 - val_loss: 0.0183 - val_accuracy: 0.9945 - lr: 2.5000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0456 - accuracy: 0.9845 - val_loss: 0.0187 - val_accuracy: 0.9945 - lr: 2.5000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0438 - accuracy: 0.9854 - val_loss: 0.0172 - val_accuracy: 0.9949 - lr: 2.5000e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0394 - accuracy: 0.9869 - val_loss: 0.0147 - val_accuracy: 0.9960 - lr: 1.2500e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0365 - accuracy: 0.9878 - val_loss: 0.0137 - val_accuracy: 0.9964 - lr: 1.2500e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0373 - accuracy: 0.9877 - val_loss: 0.0138 - val_accuracy: 0.9958 - lr: 1.2500e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0364 - accuracy: 0.9878 - val_loss: 0.0128 - val_accuracy: 0.9962 - lr: 1.2500e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0361 - accuracy: 0.9880 - val_loss: 0.0137 - val_accuracy: 0.9961 - lr: 1.2500e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0353 - accuracy: 0.9886 - val_loss: 0.0123 - val_accuracy: 0.9961 - lr: 1.2500e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0357 - accuracy: 0.9882 - val_loss: 0.0122 - val_accuracy: 0.9965 - lr: 1.2500e-04\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0342 - accuracy: 0.9887 - val_loss: 0.0132 - val_accuracy: 0.9959 - lr: 1.2500e-04\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0337 - accuracy: 0.9887 - val_loss: 0.0113 - val_accuracy: 0.9960 - lr: 1.2500e-04\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0346 - accuracy: 0.9884 - val_loss: 0.0123 - val_accuracy: 0.9964 - lr: 1.2500e-04\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0331 - accuracy: 0.9892 - val_loss: 0.0118 - val_accuracy: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0337 - accuracy: 0.9889 - val_loss: 0.0122 - val_accuracy: 0.9965 - lr: 1.2500e-04\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0316 - accuracy: 0.9899 - val_loss: 0.0109 - val_accuracy: 0.9967 - lr: 6.2500e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0309 - accuracy: 0.9896 - val_loss: 0.0110 - val_accuracy: 0.9966 - lr: 6.2500e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0295 - accuracy: 0.9907 - val_loss: 0.0107 - val_accuracy: 0.9967 - lr: 6.2500e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0296 - accuracy: 0.9902 - val_loss: 0.0103 - val_accuracy: 0.9972 - lr: 6.2500e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0290 - accuracy: 0.9904 - val_loss: 0.0099 - val_accuracy: 0.9969 - lr: 6.2500e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0290 - accuracy: 0.9905 - val_loss: 0.0097 - val_accuracy: 0.9972 - lr: 6.2500e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0291 - accuracy: 0.9904 - val_loss: 0.0096 - val_accuracy: 0.9970 - lr: 6.2500e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0291 - accuracy: 0.9905 - val_loss: 0.0100 - val_accuracy: 0.9971 - lr: 6.2500e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0281 - accuracy: 0.9908 - val_loss: 0.0099 - val_accuracy: 0.9971 - lr: 6.2500e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0279 - accuracy: 0.9909 - val_loss: 0.0092 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0273 - accuracy: 0.9910 - val_loss: 0.0096 - val_accuracy: 0.9968 - lr: 3.1250e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0270 - accuracy: 0.9910 - val_loss: 0.0093 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0277 - accuracy: 0.9912 - val_loss: 0.0091 - val_accuracy: 0.9971 - lr: 3.1250e-05\n",
      "1033/1033 [==============================] - 5s 5ms/step - loss: 0.0101 - accuracy: 0.9969\n",
      "\n",
      "── Fold 2/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 20s 19ms/step - loss: 1.2519 - accuracy: 0.5730 - val_loss: 0.7501 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.6543 - accuracy: 0.7787 - val_loss: 0.4632 - val_accuracy: 0.8406 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.4798 - accuracy: 0.8368 - val_loss: 0.3334 - val_accuracy: 0.8822 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.3872 - accuracy: 0.8659 - val_loss: 0.3454 - val_accuracy: 0.8764 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.3279 - accuracy: 0.8858 - val_loss: 0.2362 - val_accuracy: 0.9152 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.2868 - accuracy: 0.8997 - val_loss: 0.2151 - val_accuracy: 0.9243 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2541 - accuracy: 0.9112 - val_loss: 0.1686 - val_accuracy: 0.9403 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 16s 17ms/step - loss: 0.2341 - accuracy: 0.9181 - val_loss: 0.1711 - val_accuracy: 0.9361 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 16s 17ms/step - loss: 0.2147 - accuracy: 0.9244 - val_loss: 0.1504 - val_accuracy: 0.9471 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1967 - accuracy: 0.9311 - val_loss: 0.1205 - val_accuracy: 0.9564 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1868 - accuracy: 0.9339 - val_loss: 0.1223 - val_accuracy: 0.9570 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.1733 - accuracy: 0.9386 - val_loss: 0.1141 - val_accuracy: 0.9606 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1613 - accuracy: 0.9433 - val_loss: 0.0859 - val_accuracy: 0.9713 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1560 - accuracy: 0.9447 - val_loss: 0.0979 - val_accuracy: 0.9665 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1491 - accuracy: 0.9473 - val_loss: 0.0895 - val_accuracy: 0.9682 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1420 - accuracy: 0.9496 - val_loss: 0.0849 - val_accuracy: 0.9698 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.1349 - accuracy: 0.9526 - val_loss: 0.0716 - val_accuracy: 0.9741 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1295 - accuracy: 0.9542 - val_loss: 0.0730 - val_accuracy: 0.9744 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 16s 17ms/step - loss: 0.1238 - accuracy: 0.9561 - val_loss: 0.0694 - val_accuracy: 0.9759 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 16s 17ms/step - loss: 0.1192 - accuracy: 0.9584 - val_loss: 0.0832 - val_accuracy: 0.9703 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1166 - accuracy: 0.9579 - val_loss: 0.0726 - val_accuracy: 0.9737 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1123 - accuracy: 0.9604 - val_loss: 0.0509 - val_accuracy: 0.9826 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1078 - accuracy: 0.9616 - val_loss: 0.0759 - val_accuracy: 0.9722 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1056 - accuracy: 0.9627 - val_loss: 0.0656 - val_accuracy: 0.9756 - lr: 0.0010\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1011 - accuracy: 0.9639 - val_loss: 0.0475 - val_accuracy: 0.9837 - lr: 0.0010\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.0985 - accuracy: 0.9649 - val_loss: 0.0600 - val_accuracy: 0.9787 - lr: 0.0010\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0965 - accuracy: 0.9658 - val_loss: 0.0542 - val_accuracy: 0.9793 - lr: 0.0010\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.0960 - accuracy: 0.9660 - val_loss: 0.0638 - val_accuracy: 0.9778 - lr: 0.0010\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0674 - accuracy: 0.9765 - val_loss: 0.0309 - val_accuracy: 0.9903 - lr: 5.0000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0609 - accuracy: 0.9789 - val_loss: 0.0236 - val_accuracy: 0.9924 - lr: 5.0000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0595 - accuracy: 0.9794 - val_loss: 0.0242 - val_accuracy: 0.9918 - lr: 5.0000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0574 - accuracy: 0.9802 - val_loss: 0.0245 - val_accuracy: 0.9917 - lr: 5.0000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0569 - accuracy: 0.9805 - val_loss: 0.0314 - val_accuracy: 0.9889 - lr: 5.0000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0460 - accuracy: 0.9847 - val_loss: 0.0185 - val_accuracy: 0.9941 - lr: 2.5000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0442 - accuracy: 0.9849 - val_loss: 0.0183 - val_accuracy: 0.9934 - lr: 2.5000e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0408 - accuracy: 0.9861 - val_loss: 0.0173 - val_accuracy: 0.9938 - lr: 2.5000e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.0409 - accuracy: 0.9863 - val_loss: 0.0167 - val_accuracy: 0.9941 - lr: 2.5000e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.0397 - accuracy: 0.9865 - val_loss: 0.0167 - val_accuracy: 0.9941 - lr: 2.5000e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0395 - accuracy: 0.9865 - val_loss: 0.0158 - val_accuracy: 0.9953 - lr: 2.5000e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0389 - accuracy: 0.9866 - val_loss: 0.0143 - val_accuracy: 0.9947 - lr: 2.5000e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0391 - accuracy: 0.9866 - val_loss: 0.0180 - val_accuracy: 0.9939 - lr: 2.5000e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.0384 - accuracy: 0.9868 - val_loss: 0.0155 - val_accuracy: 0.9945 - lr: 2.5000e-04\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0375 - accuracy: 0.9870 - val_loss: 0.0157 - val_accuracy: 0.9947 - lr: 2.5000e-04\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.0341 - accuracy: 0.9884 - val_loss: 0.0136 - val_accuracy: 0.9957 - lr: 1.2500e-04\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0322 - accuracy: 0.9891 - val_loss: 0.0131 - val_accuracy: 0.9955 - lr: 1.2500e-04\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0310 - accuracy: 0.9895 - val_loss: 0.0123 - val_accuracy: 0.9958 - lr: 1.2500e-04\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0304 - accuracy: 0.9898 - val_loss: 0.0122 - val_accuracy: 0.9964 - lr: 1.2500e-04\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0306 - accuracy: 0.9899 - val_loss: 0.0130 - val_accuracy: 0.9961 - lr: 1.2500e-04\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0307 - accuracy: 0.9894 - val_loss: 0.0117 - val_accuracy: 0.9962 - lr: 1.2500e-04\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0299 - accuracy: 0.9900 - val_loss: 0.0115 - val_accuracy: 0.9962 - lr: 1.2500e-04\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0310 - accuracy: 0.9897 - val_loss: 0.0110 - val_accuracy: 0.9963 - lr: 1.2500e-04\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0295 - accuracy: 0.9900 - val_loss: 0.0114 - val_accuracy: 0.9960 - lr: 1.2500e-04\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0292 - accuracy: 0.9902 - val_loss: 0.0110 - val_accuracy: 0.9962 - lr: 1.2500e-04\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.0297 - accuracy: 0.9899 - val_loss: 0.0114 - val_accuracy: 0.9964 - lr: 1.2500e-04\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0273 - accuracy: 0.9912 - val_loss: 0.0104 - val_accuracy: 0.9968 - lr: 6.2500e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.0268 - accuracy: 0.9909 - val_loss: 0.0106 - val_accuracy: 0.9965 - lr: 6.2500e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0259 - accuracy: 0.9915 - val_loss: 0.0102 - val_accuracy: 0.9961 - lr: 6.2500e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.0099 - val_accuracy: 0.9971 - lr: 6.2500e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 16s 17ms/step - loss: 0.0263 - accuracy: 0.9911 - val_loss: 0.0101 - val_accuracy: 0.9967 - lr: 6.2500e-05\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.0258 - accuracy: 0.9914 - val_loss: 0.0106 - val_accuracy: 0.9965 - lr: 6.2500e-05\n",
      "1033/1033 [==============================] - 5s 5ms/step - loss: 0.0116 - accuracy: 0.9965\n",
      "\n",
      "── Fold 3/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 20s 19ms/step - loss: 1.2335 - accuracy: 0.5806 - val_loss: 0.7252 - val_accuracy: 0.7511 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.6367 - accuracy: 0.7846 - val_loss: 0.4466 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.4625 - accuracy: 0.8413 - val_loss: 0.4168 - val_accuracy: 0.8531 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.3729 - accuracy: 0.8710 - val_loss: 0.2765 - val_accuracy: 0.9007 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.3139 - accuracy: 0.8906 - val_loss: 0.2077 - val_accuracy: 0.9266 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2765 - accuracy: 0.9033 - val_loss: 0.2038 - val_accuracy: 0.9293 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2469 - accuracy: 0.9133 - val_loss: 0.1434 - val_accuracy: 0.9495 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2261 - accuracy: 0.9199 - val_loss: 0.1510 - val_accuracy: 0.9452 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2063 - accuracy: 0.9275 - val_loss: 0.1517 - val_accuracy: 0.9461 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1894 - accuracy: 0.9338 - val_loss: 0.1172 - val_accuracy: 0.9589 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1781 - accuracy: 0.9369 - val_loss: 0.1096 - val_accuracy: 0.9632 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1665 - accuracy: 0.9413 - val_loss: 0.1077 - val_accuracy: 0.9609 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1574 - accuracy: 0.9451 - val_loss: 0.1256 - val_accuracy: 0.9567 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1491 - accuracy: 0.9472 - val_loss: 0.0919 - val_accuracy: 0.9692 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1443 - accuracy: 0.9492 - val_loss: 0.0954 - val_accuracy: 0.9689 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1340 - accuracy: 0.9527 - val_loss: 0.0853 - val_accuracy: 0.9715 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1285 - accuracy: 0.9545 - val_loss: 0.1051 - val_accuracy: 0.9638 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1263 - accuracy: 0.9560 - val_loss: 0.0810 - val_accuracy: 0.9720 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1204 - accuracy: 0.9573 - val_loss: 0.0811 - val_accuracy: 0.9722 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1132 - accuracy: 0.9605 - val_loss: 0.0744 - val_accuracy: 0.9737 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1119 - accuracy: 0.9606 - val_loss: 0.0651 - val_accuracy: 0.9771 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1069 - accuracy: 0.9624 - val_loss: 0.0583 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1062 - accuracy: 0.9625 - val_loss: 0.0759 - val_accuracy: 0.9735 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1006 - accuracy: 0.9643 - val_loss: 0.0545 - val_accuracy: 0.9823 - lr: 0.0010\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1006 - accuracy: 0.9637 - val_loss: 0.0626 - val_accuracy: 0.9775 - lr: 0.0010\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0927 - accuracy: 0.9679 - val_loss: 0.0586 - val_accuracy: 0.9797 - lr: 0.0010\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0934 - accuracy: 0.9666 - val_loss: 0.0477 - val_accuracy: 0.9840 - lr: 0.0010\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0912 - accuracy: 0.9681 - val_loss: 0.0502 - val_accuracy: 0.9814 - lr: 0.0010\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0895 - accuracy: 0.9690 - val_loss: 0.0494 - val_accuracy: 0.9825 - lr: 0.0010\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0872 - accuracy: 0.9694 - val_loss: 0.0512 - val_accuracy: 0.9825 - lr: 0.0010\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0597 - accuracy: 0.9794 - val_loss: 0.0295 - val_accuracy: 0.9902 - lr: 5.0000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0553 - accuracy: 0.9806 - val_loss: 0.0274 - val_accuracy: 0.9912 - lr: 5.0000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0535 - accuracy: 0.9812 - val_loss: 0.0280 - val_accuracy: 0.9911 - lr: 5.0000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0524 - accuracy: 0.9818 - val_loss: 0.0237 - val_accuracy: 0.9927 - lr: 5.0000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0518 - accuracy: 0.9822 - val_loss: 0.0258 - val_accuracy: 0.9918 - lr: 5.0000e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0501 - accuracy: 0.9825 - val_loss: 0.0282 - val_accuracy: 0.9905 - lr: 5.0000e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0498 - accuracy: 0.9824 - val_loss: 0.0238 - val_accuracy: 0.9916 - lr: 5.0000e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0405 - accuracy: 0.9861 - val_loss: 0.0180 - val_accuracy: 0.9940 - lr: 2.5000e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0351 - accuracy: 0.9885 - val_loss: 0.0193 - val_accuracy: 0.9942 - lr: 2.5000e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0356 - accuracy: 0.9879 - val_loss: 0.0192 - val_accuracy: 0.9942 - lr: 2.5000e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0351 - accuracy: 0.9883 - val_loss: 0.0171 - val_accuracy: 0.9952 - lr: 2.5000e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0329 - accuracy: 0.9889 - val_loss: 0.0171 - val_accuracy: 0.9943 - lr: 2.5000e-04\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0335 - accuracy: 0.9888 - val_loss: 0.0163 - val_accuracy: 0.9948 - lr: 2.5000e-04\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0339 - accuracy: 0.9884 - val_loss: 0.0181 - val_accuracy: 0.9946 - lr: 2.5000e-04\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0329 - accuracy: 0.9889 - val_loss: 0.0174 - val_accuracy: 0.9946 - lr: 2.5000e-04\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0321 - accuracy: 0.9889 - val_loss: 0.0156 - val_accuracy: 0.9947 - lr: 2.5000e-04\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0313 - accuracy: 0.9892 - val_loss: 0.0154 - val_accuracy: 0.9953 - lr: 2.5000e-04\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0309 - accuracy: 0.9892 - val_loss: 0.0256 - val_accuracy: 0.9926 - lr: 2.5000e-04\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 16s 17ms/step - loss: 0.0315 - accuracy: 0.9895 - val_loss: 0.0162 - val_accuracy: 0.9952 - lr: 2.5000e-04\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0312 - accuracy: 0.9891 - val_loss: 0.0177 - val_accuracy: 0.9948 - lr: 2.5000e-04\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0271 - accuracy: 0.9912 - val_loss: 0.0143 - val_accuracy: 0.9955 - lr: 1.2500e-04\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0241 - accuracy: 0.9922 - val_loss: 0.0131 - val_accuracy: 0.9961 - lr: 1.2500e-04\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.0250 - accuracy: 0.9917 - val_loss: 0.0147 - val_accuracy: 0.9955 - lr: 1.2500e-04\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0248 - accuracy: 0.9918 - val_loss: 0.0123 - val_accuracy: 0.9965 - lr: 1.2500e-04\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 16s 17ms/step - loss: 0.0240 - accuracy: 0.9918 - val_loss: 0.0141 - val_accuracy: 0.9957 - lr: 1.2500e-04\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.0247 - accuracy: 0.9917 - val_loss: 0.0140 - val_accuracy: 0.9958 - lr: 1.2500e-04\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 16s 17ms/step - loss: 0.0241 - accuracy: 0.9918 - val_loss: 0.0127 - val_accuracy: 0.9961 - lr: 1.2500e-04\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 16s 17ms/step - loss: 0.0225 - accuracy: 0.9926 - val_loss: 0.0124 - val_accuracy: 0.9960 - lr: 6.2500e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 16s 17ms/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 0.0120 - val_accuracy: 0.9964 - lr: 6.2500e-05\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 0.0117 - val_accuracy: 0.9964 - lr: 6.2500e-05\n",
      "1033/1033 [==============================] - 5s 5ms/step - loss: 0.0086 - accuracy: 0.9974\n",
      "\n",
      "── Fold 4/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 20s 19ms/step - loss: 1.2137 - accuracy: 0.5875 - val_loss: 0.6881 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.6303 - accuracy: 0.7869 - val_loss: 0.4364 - val_accuracy: 0.8475 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.4640 - accuracy: 0.8398 - val_loss: 0.3259 - val_accuracy: 0.8863 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 16s 17ms/step - loss: 0.3741 - accuracy: 0.8704 - val_loss: 0.3170 - val_accuracy: 0.8862 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 16s 17ms/step - loss: 0.3191 - accuracy: 0.8889 - val_loss: 0.2590 - val_accuracy: 0.9078 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 16s 17ms/step - loss: 0.2785 - accuracy: 0.9025 - val_loss: 0.3103 - val_accuracy: 0.8890 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2497 - accuracy: 0.9124 - val_loss: 0.1723 - val_accuracy: 0.9394 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2247 - accuracy: 0.9204 - val_loss: 0.1441 - val_accuracy: 0.9489 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2092 - accuracy: 0.9265 - val_loss: 0.1484 - val_accuracy: 0.9461 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1946 - accuracy: 0.9311 - val_loss: 0.1144 - val_accuracy: 0.9586 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1809 - accuracy: 0.9363 - val_loss: 0.1107 - val_accuracy: 0.9604 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1692 - accuracy: 0.9397 - val_loss: 0.0961 - val_accuracy: 0.9672 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1611 - accuracy: 0.9426 - val_loss: 0.0993 - val_accuracy: 0.9656 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 16s 17ms/step - loss: 0.1521 - accuracy: 0.9461 - val_loss: 0.0806 - val_accuracy: 0.9714 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1418 - accuracy: 0.9501 - val_loss: 0.0951 - val_accuracy: 0.9656 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1355 - accuracy: 0.9525 - val_loss: 0.0783 - val_accuracy: 0.9713 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.1301 - accuracy: 0.9551 - val_loss: 0.1041 - val_accuracy: 0.9641 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1274 - accuracy: 0.9553 - val_loss: 0.0746 - val_accuracy: 0.9723 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1233 - accuracy: 0.9561 - val_loss: 0.0765 - val_accuracy: 0.9734 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1161 - accuracy: 0.9591 - val_loss: 0.0701 - val_accuracy: 0.9740 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1107 - accuracy: 0.9609 - val_loss: 0.0584 - val_accuracy: 0.9784 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1090 - accuracy: 0.9614 - val_loss: 0.0559 - val_accuracy: 0.9803 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.1073 - accuracy: 0.9618 - val_loss: 0.0568 - val_accuracy: 0.9790 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.0988 - accuracy: 0.9649 - val_loss: 0.0726 - val_accuracy: 0.9755 - lr: 0.0010\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1004 - accuracy: 0.9640 - val_loss: 0.0425 - val_accuracy: 0.9846 - lr: 0.0010\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 16s 17ms/step - loss: 0.0946 - accuracy: 0.9665 - val_loss: 0.0524 - val_accuracy: 0.9815 - lr: 0.0010\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0962 - accuracy: 0.9657 - val_loss: 0.0604 - val_accuracy: 0.9787 - lr: 0.0010\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0911 - accuracy: 0.9674 - val_loss: 0.0528 - val_accuracy: 0.9810 - lr: 0.0010\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0637 - accuracy: 0.9776 - val_loss: 0.0251 - val_accuracy: 0.9918 - lr: 5.0000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0569 - accuracy: 0.9803 - val_loss: 0.0305 - val_accuracy: 0.9900 - lr: 5.0000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0561 - accuracy: 0.9804 - val_loss: 0.0236 - val_accuracy: 0.9924 - lr: 5.0000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0542 - accuracy: 0.9816 - val_loss: 0.0238 - val_accuracy: 0.9931 - lr: 5.0000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0558 - accuracy: 0.9805 - val_loss: 0.0252 - val_accuracy: 0.9921 - lr: 5.0000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 16s 17ms/step - loss: 0.0538 - accuracy: 0.9813 - val_loss: 0.0234 - val_accuracy: 0.9922 - lr: 5.0000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0524 - accuracy: 0.9816 - val_loss: 0.0230 - val_accuracy: 0.9932 - lr: 5.0000e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0491 - accuracy: 0.9828 - val_loss: 0.0259 - val_accuracy: 0.9920 - lr: 5.0000e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0496 - accuracy: 0.9826 - val_loss: 0.0211 - val_accuracy: 0.9935 - lr: 5.0000e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0493 - accuracy: 0.9831 - val_loss: 0.0244 - val_accuracy: 0.9924 - lr: 5.0000e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 16s 17ms/step - loss: 0.0472 - accuracy: 0.9836 - val_loss: 0.0232 - val_accuracy: 0.9927 - lr: 5.0000e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0467 - accuracy: 0.9842 - val_loss: 0.0237 - val_accuracy: 0.9928 - lr: 5.0000e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0363 - accuracy: 0.9877 - val_loss: 0.0176 - val_accuracy: 0.9945 - lr: 2.5000e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.0356 - accuracy: 0.9876 - val_loss: 0.0159 - val_accuracy: 0.9944 - lr: 2.5000e-04\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0345 - accuracy: 0.9880 - val_loss: 0.0168 - val_accuracy: 0.9946 - lr: 2.5000e-04\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0330 - accuracy: 0.9889 - val_loss: 0.0147 - val_accuracy: 0.9955 - lr: 2.5000e-04\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0333 - accuracy: 0.9883 - val_loss: 0.0161 - val_accuracy: 0.9950 - lr: 2.5000e-04\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 16s 17ms/step - loss: 0.0326 - accuracy: 0.9887 - val_loss: 0.0157 - val_accuracy: 0.9946 - lr: 2.5000e-04\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 16s 17ms/step - loss: 0.0317 - accuracy: 0.9891 - val_loss: 0.0152 - val_accuracy: 0.9953 - lr: 2.5000e-04\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0287 - accuracy: 0.9904 - val_loss: 0.0114 - val_accuracy: 0.9964 - lr: 1.2500e-04\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0265 - accuracy: 0.9911 - val_loss: 0.0121 - val_accuracy: 0.9961 - lr: 1.2500e-04\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.0262 - accuracy: 0.9911 - val_loss: 0.0118 - val_accuracy: 0.9964 - lr: 1.2500e-04\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0259 - accuracy: 0.9914 - val_loss: 0.0109 - val_accuracy: 0.9968 - lr: 1.2500e-04\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0265 - accuracy: 0.9911 - val_loss: 0.0106 - val_accuracy: 0.9966 - lr: 1.2500e-04\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.0243 - accuracy: 0.9919 - val_loss: 0.0114 - val_accuracy: 0.9963 - lr: 1.2500e-04\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0250 - accuracy: 0.9916 - val_loss: 0.0100 - val_accuracy: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0250 - accuracy: 0.9918 - val_loss: 0.0113 - val_accuracy: 0.9964 - lr: 1.2500e-04\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0244 - accuracy: 0.9919 - val_loss: 0.0107 - val_accuracy: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 0.0110 - val_accuracy: 0.9968 - lr: 1.2500e-04\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0227 - accuracy: 0.9923 - val_loss: 0.0101 - val_accuracy: 0.9970 - lr: 6.2500e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.0217 - accuracy: 0.9929 - val_loss: 0.0092 - val_accuracy: 0.9972 - lr: 6.2500e-05\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0217 - accuracy: 0.9929 - val_loss: 0.0091 - val_accuracy: 0.9972 - lr: 6.2500e-05\n",
      "1033/1033 [==============================] - 5s 5ms/step - loss: 0.0107 - accuracy: 0.9966\n",
      "\n",
      "── Fold 5/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 20s 19ms/step - loss: 1.2361 - accuracy: 0.5796 - val_loss: 0.7184 - val_accuracy: 0.7562 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.6437 - accuracy: 0.7817 - val_loss: 0.4466 - val_accuracy: 0.8491 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.4705 - accuracy: 0.8384 - val_loss: 0.4018 - val_accuracy: 0.8594 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.3815 - accuracy: 0.8674 - val_loss: 0.2559 - val_accuracy: 0.9125 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.3228 - accuracy: 0.8884 - val_loss: 0.2129 - val_accuracy: 0.9257 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2830 - accuracy: 0.9006 - val_loss: 0.2110 - val_accuracy: 0.9246 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 16s 17ms/step - loss: 0.2525 - accuracy: 0.9111 - val_loss: 0.2239 - val_accuracy: 0.9203 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2281 - accuracy: 0.9204 - val_loss: 0.1751 - val_accuracy: 0.9407 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.2113 - accuracy: 0.9249 - val_loss: 0.1344 - val_accuracy: 0.9536 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 16s 17ms/step - loss: 0.1933 - accuracy: 0.9317 - val_loss: 0.1410 - val_accuracy: 0.9490 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1811 - accuracy: 0.9365 - val_loss: 0.1229 - val_accuracy: 0.9564 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1706 - accuracy: 0.9399 - val_loss: 0.1196 - val_accuracy: 0.9582 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1630 - accuracy: 0.9425 - val_loss: 0.1092 - val_accuracy: 0.9627 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1538 - accuracy: 0.9455 - val_loss: 0.0837 - val_accuracy: 0.9686 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1447 - accuracy: 0.9489 - val_loss: 0.0830 - val_accuracy: 0.9709 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1387 - accuracy: 0.9512 - val_loss: 0.0745 - val_accuracy: 0.9713 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.1338 - accuracy: 0.9522 - val_loss: 0.0765 - val_accuracy: 0.9738 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.1272 - accuracy: 0.9549 - val_loss: 0.0891 - val_accuracy: 0.9673 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1240 - accuracy: 0.9561 - val_loss: 0.0731 - val_accuracy: 0.9731 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1186 - accuracy: 0.9585 - val_loss: 0.0631 - val_accuracy: 0.9782 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1127 - accuracy: 0.9604 - val_loss: 0.0710 - val_accuracy: 0.9744 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1111 - accuracy: 0.9610 - val_loss: 0.0710 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1093 - accuracy: 0.9618 - val_loss: 0.0493 - val_accuracy: 0.9836 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1030 - accuracy: 0.9632 - val_loss: 0.0663 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0983 - accuracy: 0.9651 - val_loss: 0.0672 - val_accuracy: 0.9759 - lr: 0.0010\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.0985 - accuracy: 0.9655 - val_loss: 0.0709 - val_accuracy: 0.9755 - lr: 0.0010\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.0697 - accuracy: 0.9753 - val_loss: 0.0294 - val_accuracy: 0.9902 - lr: 5.0000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0638 - accuracy: 0.9778 - val_loss: 0.0310 - val_accuracy: 0.9890 - lr: 5.0000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0620 - accuracy: 0.9783 - val_loss: 0.0284 - val_accuracy: 0.9909 - lr: 5.0000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0600 - accuracy: 0.9790 - val_loss: 0.0218 - val_accuracy: 0.9922 - lr: 5.0000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0577 - accuracy: 0.9792 - val_loss: 0.0277 - val_accuracy: 0.9897 - lr: 5.0000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.0564 - accuracy: 0.9804 - val_loss: 0.0299 - val_accuracy: 0.9899 - lr: 5.0000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0572 - accuracy: 0.9802 - val_loss: 0.0245 - val_accuracy: 0.9917 - lr: 5.0000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0447 - accuracy: 0.9845 - val_loss: 0.0183 - val_accuracy: 0.9937 - lr: 2.5000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0430 - accuracy: 0.9852 - val_loss: 0.0160 - val_accuracy: 0.9951 - lr: 2.5000e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0409 - accuracy: 0.9860 - val_loss: 0.0160 - val_accuracy: 0.9953 - lr: 2.5000e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0406 - accuracy: 0.9860 - val_loss: 0.0187 - val_accuracy: 0.9939 - lr: 2.5000e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0395 - accuracy: 0.9863 - val_loss: 0.0148 - val_accuracy: 0.9952 - lr: 2.5000e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0408 - accuracy: 0.9861 - val_loss: 0.0159 - val_accuracy: 0.9946 - lr: 2.5000e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0384 - accuracy: 0.9870 - val_loss: 0.0154 - val_accuracy: 0.9953 - lr: 2.5000e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0383 - accuracy: 0.9872 - val_loss: 0.0150 - val_accuracy: 0.9949 - lr: 2.5000e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0333 - accuracy: 0.9886 - val_loss: 0.0125 - val_accuracy: 0.9961 - lr: 1.2500e-04\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0308 - accuracy: 0.9898 - val_loss: 0.0114 - val_accuracy: 0.9966 - lr: 1.2500e-04\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 16s 17ms/step - loss: 0.0309 - accuracy: 0.9898 - val_loss: 0.0121 - val_accuracy: 0.9964 - lr: 1.2500e-04\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0306 - accuracy: 0.9897 - val_loss: 0.0108 - val_accuracy: 0.9970 - lr: 1.2500e-04\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0298 - accuracy: 0.9903 - val_loss: 0.0113 - val_accuracy: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 16s 17ms/step - loss: 0.0306 - accuracy: 0.9897 - val_loss: 0.0114 - val_accuracy: 0.9968 - lr: 1.2500e-04\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0298 - accuracy: 0.9900 - val_loss: 0.0110 - val_accuracy: 0.9966 - lr: 1.2500e-04\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0276 - accuracy: 0.9910 - val_loss: 0.0100 - val_accuracy: 0.9971 - lr: 6.2500e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0278 - accuracy: 0.9908 - val_loss: 0.0109 - val_accuracy: 0.9966 - lr: 6.2500e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0268 - accuracy: 0.9914 - val_loss: 0.0099 - val_accuracy: 0.9972 - lr: 6.2500e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0267 - accuracy: 0.9917 - val_loss: 0.0099 - val_accuracy: 0.9969 - lr: 6.2500e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0270 - accuracy: 0.9910 - val_loss: 0.0110 - val_accuracy: 0.9966 - lr: 6.2500e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0258 - accuracy: 0.9916 - val_loss: 0.0100 - val_accuracy: 0.9974 - lr: 6.2500e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0250 - accuracy: 0.9920 - val_loss: 0.0095 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 16s 17ms/step - loss: 0.0256 - accuracy: 0.9918 - val_loss: 0.0097 - val_accuracy: 0.9970 - lr: 3.1250e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0253 - accuracy: 0.9917 - val_loss: 0.0093 - val_accuracy: 0.9973 - lr: 3.1250e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 16s 18ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.0094 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0247 - accuracy: 0.9920 - val_loss: 0.0096 - val_accuracy: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 0.0092 - val_accuracy: 0.9970 - lr: 3.1250e-05\n",
      "1033/1033 [==============================] - 5s 5ms/step - loss: 0.0103 - accuracy: 0.9967\n",
      "\n",
      "── Fold 6/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 21s 19ms/step - loss: 1.2390 - accuracy: 0.5766 - val_loss: 0.8476 - val_accuracy: 0.7136 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.6382 - accuracy: 0.7840 - val_loss: 0.4584 - val_accuracy: 0.8411 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.4642 - accuracy: 0.8409 - val_loss: 0.3957 - val_accuracy: 0.8617 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.3753 - accuracy: 0.8699 - val_loss: 0.2795 - val_accuracy: 0.9039 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.3176 - accuracy: 0.8898 - val_loss: 0.2467 - val_accuracy: 0.9153 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2808 - accuracy: 0.9024 - val_loss: 0.2611 - val_accuracy: 0.9080 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2515 - accuracy: 0.9115 - val_loss: 0.1633 - val_accuracy: 0.9430 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2250 - accuracy: 0.9216 - val_loss: 0.1736 - val_accuracy: 0.9371 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2077 - accuracy: 0.9267 - val_loss: 0.1564 - val_accuracy: 0.9468 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1954 - accuracy: 0.9309 - val_loss: 0.1334 - val_accuracy: 0.9517 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1803 - accuracy: 0.9361 - val_loss: 0.1760 - val_accuracy: 0.9371 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1718 - accuracy: 0.9387 - val_loss: 0.1518 - val_accuracy: 0.9475 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1625 - accuracy: 0.9416 - val_loss: 0.1094 - val_accuracy: 0.9609 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1531 - accuracy: 0.9453 - val_loss: 0.1166 - val_accuracy: 0.9595 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1444 - accuracy: 0.9482 - val_loss: 0.1019 - val_accuracy: 0.9656 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1369 - accuracy: 0.9513 - val_loss: 0.1067 - val_accuracy: 0.9611 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1336 - accuracy: 0.9525 - val_loss: 0.0832 - val_accuracy: 0.9713 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1297 - accuracy: 0.9543 - val_loss: 0.0920 - val_accuracy: 0.9689 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1258 - accuracy: 0.9562 - val_loss: 0.0774 - val_accuracy: 0.9713 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1211 - accuracy: 0.9572 - val_loss: 0.0702 - val_accuracy: 0.9745 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1169 - accuracy: 0.9587 - val_loss: 0.0719 - val_accuracy: 0.9753 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1099 - accuracy: 0.9609 - val_loss: 0.0604 - val_accuracy: 0.9774 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1104 - accuracy: 0.9604 - val_loss: 0.0826 - val_accuracy: 0.9695 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1045 - accuracy: 0.9629 - val_loss: 0.0589 - val_accuracy: 0.9806 - lr: 0.0010\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1029 - accuracy: 0.9640 - val_loss: 0.0496 - val_accuracy: 0.9832 - lr: 0.0010\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1010 - accuracy: 0.9639 - val_loss: 0.0777 - val_accuracy: 0.9720 - lr: 0.0010\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0969 - accuracy: 0.9660 - val_loss: 0.0575 - val_accuracy: 0.9812 - lr: 0.0010\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0941 - accuracy: 0.9668 - val_loss: 0.0516 - val_accuracy: 0.9833 - lr: 0.0010\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0674 - accuracy: 0.9761 - val_loss: 0.0329 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0627 - accuracy: 0.9785 - val_loss: 0.0293 - val_accuracy: 0.9893 - lr: 5.0000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0611 - accuracy: 0.9791 - val_loss: 0.0311 - val_accuracy: 0.9882 - lr: 5.0000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0587 - accuracy: 0.9792 - val_loss: 0.0343 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0593 - accuracy: 0.9794 - val_loss: 0.0287 - val_accuracy: 0.9902 - lr: 5.0000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0567 - accuracy: 0.9802 - val_loss: 0.0294 - val_accuracy: 0.9904 - lr: 5.0000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0567 - accuracy: 0.9800 - val_loss: 0.0266 - val_accuracy: 0.9907 - lr: 5.0000e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0540 - accuracy: 0.9810 - val_loss: 0.0312 - val_accuracy: 0.9905 - lr: 5.0000e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0532 - accuracy: 0.9815 - val_loss: 0.0285 - val_accuracy: 0.9904 - lr: 5.0000e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0523 - accuracy: 0.9821 - val_loss: 0.0212 - val_accuracy: 0.9931 - lr: 5.0000e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0528 - accuracy: 0.9814 - val_loss: 0.0242 - val_accuracy: 0.9915 - lr: 5.0000e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0509 - accuracy: 0.9824 - val_loss: 0.0248 - val_accuracy: 0.9918 - lr: 5.0000e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0494 - accuracy: 0.9832 - val_loss: 0.0247 - val_accuracy: 0.9913 - lr: 5.0000e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0385 - accuracy: 0.9870 - val_loss: 0.0153 - val_accuracy: 0.9951 - lr: 2.5000e-04\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0379 - accuracy: 0.9869 - val_loss: 0.0162 - val_accuracy: 0.9947 - lr: 2.5000e-04\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0368 - accuracy: 0.9876 - val_loss: 0.0167 - val_accuracy: 0.9943 - lr: 2.5000e-04\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0364 - accuracy: 0.9872 - val_loss: 0.0148 - val_accuracy: 0.9951 - lr: 2.5000e-04\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0363 - accuracy: 0.9877 - val_loss: 0.0160 - val_accuracy: 0.9946 - lr: 2.5000e-04\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0362 - accuracy: 0.9874 - val_loss: 0.0142 - val_accuracy: 0.9955 - lr: 2.5000e-04\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0352 - accuracy: 0.9879 - val_loss: 0.0149 - val_accuracy: 0.9944 - lr: 2.5000e-04\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0346 - accuracy: 0.9880 - val_loss: 0.0147 - val_accuracy: 0.9951 - lr: 2.5000e-04\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0343 - accuracy: 0.9881 - val_loss: 0.0137 - val_accuracy: 0.9951 - lr: 2.5000e-04\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0326 - accuracy: 0.9890 - val_loss: 0.0136 - val_accuracy: 0.9951 - lr: 2.5000e-04\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0345 - accuracy: 0.9884 - val_loss: 0.0144 - val_accuracy: 0.9958 - lr: 2.5000e-04\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0330 - accuracy: 0.9884 - val_loss: 0.0135 - val_accuracy: 0.9958 - lr: 2.5000e-04\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0321 - accuracy: 0.9892 - val_loss: 0.0147 - val_accuracy: 0.9946 - lr: 2.5000e-04\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0288 - accuracy: 0.9903 - val_loss: 0.0123 - val_accuracy: 0.9959 - lr: 1.2500e-04\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0275 - accuracy: 0.9907 - val_loss: 0.0108 - val_accuracy: 0.9965 - lr: 1.2500e-04\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0271 - accuracy: 0.9910 - val_loss: 0.0121 - val_accuracy: 0.9958 - lr: 1.2500e-04\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0280 - accuracy: 0.9907 - val_loss: 0.0118 - val_accuracy: 0.9962 - lr: 1.2500e-04\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0271 - accuracy: 0.9908 - val_loss: 0.0114 - val_accuracy: 0.9964 - lr: 1.2500e-04\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0259 - accuracy: 0.9917 - val_loss: 0.0107 - val_accuracy: 0.9964 - lr: 6.2500e-05\n",
      "1033/1033 [==============================] - 6s 5ms/step - loss: 0.0109 - accuracy: 0.9963\n",
      "\n",
      "── Fold 7/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 21s 20ms/step - loss: 1.2384 - accuracy: 0.5778 - val_loss: 0.7703 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.6414 - accuracy: 0.7823 - val_loss: 0.4305 - val_accuracy: 0.8543 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.4674 - accuracy: 0.8403 - val_loss: 0.3117 - val_accuracy: 0.8884 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.3772 - accuracy: 0.8700 - val_loss: 0.2336 - val_accuracy: 0.9214 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.3245 - accuracy: 0.8859 - val_loss: 0.2316 - val_accuracy: 0.9235 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2814 - accuracy: 0.9004 - val_loss: 0.2165 - val_accuracy: 0.9245 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2514 - accuracy: 0.9116 - val_loss: 0.2219 - val_accuracy: 0.9219 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2281 - accuracy: 0.9200 - val_loss: 0.1550 - val_accuracy: 0.9458 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2106 - accuracy: 0.9261 - val_loss: 0.1419 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1956 - accuracy: 0.9313 - val_loss: 0.1246 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1813 - accuracy: 0.9361 - val_loss: 0.1186 - val_accuracy: 0.9564 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1722 - accuracy: 0.9390 - val_loss: 0.0964 - val_accuracy: 0.9644 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1629 - accuracy: 0.9425 - val_loss: 0.0994 - val_accuracy: 0.9657 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1548 - accuracy: 0.9443 - val_loss: 0.0919 - val_accuracy: 0.9692 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1460 - accuracy: 0.9481 - val_loss: 0.0848 - val_accuracy: 0.9698 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1399 - accuracy: 0.9506 - val_loss: 0.0869 - val_accuracy: 0.9681 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1342 - accuracy: 0.9527 - val_loss: 0.0780 - val_accuracy: 0.9736 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1302 - accuracy: 0.9544 - val_loss: 0.0638 - val_accuracy: 0.9775 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1234 - accuracy: 0.9562 - val_loss: 0.0741 - val_accuracy: 0.9743 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1192 - accuracy: 0.9575 - val_loss: 0.0498 - val_accuracy: 0.9843 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1134 - accuracy: 0.9599 - val_loss: 0.0727 - val_accuracy: 0.9735 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1085 - accuracy: 0.9621 - val_loss: 0.0879 - val_accuracy: 0.9707 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1082 - accuracy: 0.9620 - val_loss: 0.0576 - val_accuracy: 0.9805 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0780 - accuracy: 0.9727 - val_loss: 0.0341 - val_accuracy: 0.9890 - lr: 5.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0698 - accuracy: 0.9756 - val_loss: 0.0323 - val_accuracy: 0.9901 - lr: 5.0000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0680 - accuracy: 0.9768 - val_loss: 0.0250 - val_accuracy: 0.9923 - lr: 5.0000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0653 - accuracy: 0.9779 - val_loss: 0.0259 - val_accuracy: 0.9918 - lr: 5.0000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0645 - accuracy: 0.9779 - val_loss: 0.0267 - val_accuracy: 0.9916 - lr: 5.0000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0643 - accuracy: 0.9774 - val_loss: 0.0300 - val_accuracy: 0.9896 - lr: 5.0000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0510 - accuracy: 0.9825 - val_loss: 0.0196 - val_accuracy: 0.9943 - lr: 2.5000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0488 - accuracy: 0.9830 - val_loss: 0.0180 - val_accuracy: 0.9949 - lr: 2.5000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0465 - accuracy: 0.9839 - val_loss: 0.0161 - val_accuracy: 0.9957 - lr: 2.5000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0456 - accuracy: 0.9847 - val_loss: 0.0167 - val_accuracy: 0.9955 - lr: 2.5000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0450 - accuracy: 0.9847 - val_loss: 0.0194 - val_accuracy: 0.9944 - lr: 2.5000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0447 - accuracy: 0.9850 - val_loss: 0.0144 - val_accuracy: 0.9960 - lr: 2.5000e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0442 - accuracy: 0.9853 - val_loss: 0.0167 - val_accuracy: 0.9953 - lr: 2.5000e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0450 - accuracy: 0.9844 - val_loss: 0.0141 - val_accuracy: 0.9960 - lr: 2.5000e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0425 - accuracy: 0.9855 - val_loss: 0.0157 - val_accuracy: 0.9952 - lr: 2.5000e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0403 - accuracy: 0.9860 - val_loss: 0.0138 - val_accuracy: 0.9961 - lr: 2.5000e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0404 - accuracy: 0.9858 - val_loss: 0.0128 - val_accuracy: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0407 - accuracy: 0.9861 - val_loss: 0.0138 - val_accuracy: 0.9963 - lr: 2.5000e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0403 - accuracy: 0.9860 - val_loss: 0.0143 - val_accuracy: 0.9958 - lr: 2.5000e-04\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0395 - accuracy: 0.9865 - val_loss: 0.0143 - val_accuracy: 0.9957 - lr: 2.5000e-04\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0351 - accuracy: 0.9882 - val_loss: 0.0118 - val_accuracy: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0336 - accuracy: 0.9887 - val_loss: 0.0105 - val_accuracy: 0.9975 - lr: 1.2500e-04\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0337 - accuracy: 0.9887 - val_loss: 0.0108 - val_accuracy: 0.9970 - lr: 1.2500e-04\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0333 - accuracy: 0.9889 - val_loss: 0.0107 - val_accuracy: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0321 - accuracy: 0.9893 - val_loss: 0.0107 - val_accuracy: 0.9977 - lr: 1.2500e-04\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0300 - accuracy: 0.9903 - val_loss: 0.0104 - val_accuracy: 0.9973 - lr: 6.2500e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0296 - accuracy: 0.9902 - val_loss: 0.0096 - val_accuracy: 0.9974 - lr: 6.2500e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0287 - accuracy: 0.9906 - val_loss: 0.0099 - val_accuracy: 0.9974 - lr: 6.2500e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0289 - accuracy: 0.9905 - val_loss: 0.0098 - val_accuracy: 0.9975 - lr: 6.2500e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0282 - accuracy: 0.9906 - val_loss: 0.0098 - val_accuracy: 0.9974 - lr: 6.2500e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0273 - accuracy: 0.9911 - val_loss: 0.0097 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0278 - accuracy: 0.9908 - val_loss: 0.0096 - val_accuracy: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0270 - accuracy: 0.9911 - val_loss: 0.0094 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0269 - accuracy: 0.9913 - val_loss: 0.0095 - val_accuracy: 0.9975 - lr: 3.1250e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0264 - accuracy: 0.9914 - val_loss: 0.0096 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0264 - accuracy: 0.9915 - val_loss: 0.0094 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0263 - accuracy: 0.9918 - val_loss: 0.0095 - val_accuracy: 0.9974 - lr: 1.5625e-05\n",
      "1033/1033 [==============================] - 5s 5ms/step - loss: 0.0103 - accuracy: 0.9970\n",
      "\n",
      "── Fold 8/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 20s 19ms/step - loss: 1.2325 - accuracy: 0.5797 - val_loss: 0.7725 - val_accuracy: 0.7380 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.6407 - accuracy: 0.7834 - val_loss: 0.4828 - val_accuracy: 0.8331 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.4695 - accuracy: 0.8388 - val_loss: 0.3416 - val_accuracy: 0.8811 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.3839 - accuracy: 0.8671 - val_loss: 0.3020 - val_accuracy: 0.8943 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.3212 - accuracy: 0.8876 - val_loss: 0.2393 - val_accuracy: 0.9186 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2841 - accuracy: 0.9002 - val_loss: 0.2453 - val_accuracy: 0.9157 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2518 - accuracy: 0.9114 - val_loss: 0.1735 - val_accuracy: 0.9412 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2289 - accuracy: 0.9183 - val_loss: 0.1569 - val_accuracy: 0.9430 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2140 - accuracy: 0.9243 - val_loss: 0.1599 - val_accuracy: 0.9452 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1945 - accuracy: 0.9318 - val_loss: 0.1371 - val_accuracy: 0.9523 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1822 - accuracy: 0.9354 - val_loss: 0.1410 - val_accuracy: 0.9508 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1718 - accuracy: 0.9390 - val_loss: 0.1010 - val_accuracy: 0.9663 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1611 - accuracy: 0.9432 - val_loss: 0.0893 - val_accuracy: 0.9685 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1531 - accuracy: 0.9454 - val_loss: 0.1006 - val_accuracy: 0.9651 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1457 - accuracy: 0.9485 - val_loss: 0.0994 - val_accuracy: 0.9652 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1401 - accuracy: 0.9504 - val_loss: 0.1084 - val_accuracy: 0.9614 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0985 - accuracy: 0.9658 - val_loss: 0.0470 - val_accuracy: 0.9845 - lr: 5.0000e-04\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0934 - accuracy: 0.9669 - val_loss: 0.0515 - val_accuracy: 0.9815 - lr: 5.0000e-04\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0897 - accuracy: 0.9687 - val_loss: 0.0542 - val_accuracy: 0.9814 - lr: 5.0000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0848 - accuracy: 0.9704 - val_loss: 0.0425 - val_accuracy: 0.9859 - lr: 5.0000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0835 - accuracy: 0.9706 - val_loss: 0.0404 - val_accuracy: 0.9865 - lr: 5.0000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0817 - accuracy: 0.9714 - val_loss: 0.0568 - val_accuracy: 0.9810 - lr: 5.0000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0802 - accuracy: 0.9721 - val_loss: 0.0369 - val_accuracy: 0.9884 - lr: 5.0000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0777 - accuracy: 0.9728 - val_loss: 0.0356 - val_accuracy: 0.9890 - lr: 5.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0740 - accuracy: 0.9741 - val_loss: 0.0472 - val_accuracy: 0.9842 - lr: 5.0000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0732 - accuracy: 0.9743 - val_loss: 0.0332 - val_accuracy: 0.9871 - lr: 5.0000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0716 - accuracy: 0.9749 - val_loss: 0.0344 - val_accuracy: 0.9883 - lr: 5.0000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0695 - accuracy: 0.9756 - val_loss: 0.0315 - val_accuracy: 0.9897 - lr: 5.0000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0684 - accuracy: 0.9760 - val_loss: 0.0576 - val_accuracy: 0.9799 - lr: 5.0000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0672 - accuracy: 0.9769 - val_loss: 0.0341 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0658 - accuracy: 0.9768 - val_loss: 0.0494 - val_accuracy: 0.9824 - lr: 5.0000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0518 - accuracy: 0.9821 - val_loss: 0.0202 - val_accuracy: 0.9936 - lr: 2.5000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0485 - accuracy: 0.9836 - val_loss: 0.0200 - val_accuracy: 0.9939 - lr: 2.5000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0472 - accuracy: 0.9838 - val_loss: 0.0210 - val_accuracy: 0.9936 - lr: 2.5000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0480 - accuracy: 0.9838 - val_loss: 0.0214 - val_accuracy: 0.9933 - lr: 2.5000e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0459 - accuracy: 0.9848 - val_loss: 0.0200 - val_accuracy: 0.9937 - lr: 2.5000e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0400 - accuracy: 0.9865 - val_loss: 0.0161 - val_accuracy: 0.9952 - lr: 1.2500e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0386 - accuracy: 0.9871 - val_loss: 0.0153 - val_accuracy: 0.9958 - lr: 1.2500e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0374 - accuracy: 0.9881 - val_loss: 0.0167 - val_accuracy: 0.9949 - lr: 1.2500e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0371 - accuracy: 0.9875 - val_loss: 0.0169 - val_accuracy: 0.9946 - lr: 1.2500e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0372 - accuracy: 0.9876 - val_loss: 0.0158 - val_accuracy: 0.9952 - lr: 1.2500e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0334 - accuracy: 0.9890 - val_loss: 0.0143 - val_accuracy: 0.9957 - lr: 6.2500e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 0.0147 - val_accuracy: 0.9954 - lr: 6.2500e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0337 - accuracy: 0.9887 - val_loss: 0.0150 - val_accuracy: 0.9956 - lr: 6.2500e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0330 - accuracy: 0.9890 - val_loss: 0.0150 - val_accuracy: 0.9956 - lr: 6.2500e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0314 - accuracy: 0.9897 - val_loss: 0.0144 - val_accuracy: 0.9954 - lr: 3.1250e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0308 - accuracy: 0.9900 - val_loss: 0.0139 - val_accuracy: 0.9959 - lr: 3.1250e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0304 - accuracy: 0.9900 - val_loss: 0.0140 - val_accuracy: 0.9961 - lr: 3.1250e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0309 - accuracy: 0.9897 - val_loss: 0.0138 - val_accuracy: 0.9959 - lr: 3.1250e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0302 - accuracy: 0.9903 - val_loss: 0.0137 - val_accuracy: 0.9958 - lr: 3.1250e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0309 - accuracy: 0.9897 - val_loss: 0.0134 - val_accuracy: 0.9961 - lr: 3.1250e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0302 - accuracy: 0.9905 - val_loss: 0.0137 - val_accuracy: 0.9961 - lr: 3.1250e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0310 - accuracy: 0.9897 - val_loss: 0.0137 - val_accuracy: 0.9960 - lr: 3.1250e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0303 - accuracy: 0.9904 - val_loss: 0.0135 - val_accuracy: 0.9959 - lr: 3.1250e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0281 - accuracy: 0.9909 - val_loss: 0.0134 - val_accuracy: 0.9958 - lr: 1.5625e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0285 - accuracy: 0.9906 - val_loss: 0.0132 - val_accuracy: 0.9961 - lr: 1.5625e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0295 - accuracy: 0.9903 - val_loss: 0.0130 - val_accuracy: 0.9961 - lr: 1.5625e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0288 - accuracy: 0.9906 - val_loss: 0.0131 - val_accuracy: 0.9961 - lr: 1.5625e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0284 - accuracy: 0.9907 - val_loss: 0.0132 - val_accuracy: 0.9961 - lr: 1.5625e-05\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0286 - accuracy: 0.9910 - val_loss: 0.0129 - val_accuracy: 0.9961 - lr: 1.5625e-05\n",
      "1033/1033 [==============================] - 5s 5ms/step - loss: 0.0128 - accuracy: 0.9959\n",
      "\n",
      "── Fold 9/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 20s 19ms/step - loss: 1.2394 - accuracy: 0.5784 - val_loss: 0.7885 - val_accuracy: 0.7287 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.6465 - accuracy: 0.7815 - val_loss: 0.4402 - val_accuracy: 0.8483 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.4744 - accuracy: 0.8367 - val_loss: 0.3966 - val_accuracy: 0.8613 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.3828 - accuracy: 0.8685 - val_loss: 0.2661 - val_accuracy: 0.9065 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.3263 - accuracy: 0.8875 - val_loss: 0.2252 - val_accuracy: 0.9204 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2882 - accuracy: 0.8986 - val_loss: 0.2193 - val_accuracy: 0.9229 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2551 - accuracy: 0.9100 - val_loss: 0.1803 - val_accuracy: 0.9359 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2344 - accuracy: 0.9184 - val_loss: 0.1981 - val_accuracy: 0.9301 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2142 - accuracy: 0.9249 - val_loss: 0.1290 - val_accuracy: 0.9544 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1975 - accuracy: 0.9305 - val_loss: 0.1083 - val_accuracy: 0.9623 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1836 - accuracy: 0.9354 - val_loss: 0.1168 - val_accuracy: 0.9596 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1729 - accuracy: 0.9382 - val_loss: 0.1336 - val_accuracy: 0.9530 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1638 - accuracy: 0.9421 - val_loss: 0.1017 - val_accuracy: 0.9654 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1557 - accuracy: 0.9453 - val_loss: 0.1137 - val_accuracy: 0.9592 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1516 - accuracy: 0.9469 - val_loss: 0.0926 - val_accuracy: 0.9666 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1438 - accuracy: 0.9493 - val_loss: 0.0997 - val_accuracy: 0.9638 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1341 - accuracy: 0.9524 - val_loss: 0.0758 - val_accuracy: 0.9731 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1300 - accuracy: 0.9540 - val_loss: 0.0716 - val_accuracy: 0.9741 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1247 - accuracy: 0.9553 - val_loss: 0.0611 - val_accuracy: 0.9778 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1205 - accuracy: 0.9568 - val_loss: 0.0653 - val_accuracy: 0.9781 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1159 - accuracy: 0.9588 - val_loss: 0.0601 - val_accuracy: 0.9789 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1113 - accuracy: 0.9607 - val_loss: 0.0761 - val_accuracy: 0.9747 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1091 - accuracy: 0.9613 - val_loss: 0.0690 - val_accuracy: 0.9758 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1051 - accuracy: 0.9630 - val_loss: 0.0625 - val_accuracy: 0.9770 - lr: 0.0010\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0750 - accuracy: 0.9742 - val_loss: 0.0334 - val_accuracy: 0.9886 - lr: 5.0000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0693 - accuracy: 0.9758 - val_loss: 0.0269 - val_accuracy: 0.9922 - lr: 5.0000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0682 - accuracy: 0.9756 - val_loss: 0.0294 - val_accuracy: 0.9906 - lr: 5.0000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0649 - accuracy: 0.9771 - val_loss: 0.0318 - val_accuracy: 0.9892 - lr: 5.0000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0637 - accuracy: 0.9775 - val_loss: 0.0284 - val_accuracy: 0.9911 - lr: 5.0000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0514 - accuracy: 0.9826 - val_loss: 0.0196 - val_accuracy: 0.9936 - lr: 2.5000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0479 - accuracy: 0.9839 - val_loss: 0.0193 - val_accuracy: 0.9940 - lr: 2.5000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0467 - accuracy: 0.9846 - val_loss: 0.0232 - val_accuracy: 0.9921 - lr: 2.5000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0459 - accuracy: 0.9841 - val_loss: 0.0198 - val_accuracy: 0.9943 - lr: 2.5000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0458 - accuracy: 0.9837 - val_loss: 0.0176 - val_accuracy: 0.9943 - lr: 2.5000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0441 - accuracy: 0.9847 - val_loss: 0.0192 - val_accuracy: 0.9932 - lr: 2.5000e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0436 - accuracy: 0.9854 - val_loss: 0.0157 - val_accuracy: 0.9950 - lr: 2.5000e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0422 - accuracy: 0.9855 - val_loss: 0.0175 - val_accuracy: 0.9942 - lr: 2.5000e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0422 - accuracy: 0.9859 - val_loss: 0.0178 - val_accuracy: 0.9948 - lr: 2.5000e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0425 - accuracy: 0.9851 - val_loss: 0.0164 - val_accuracy: 0.9952 - lr: 2.5000e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0366 - accuracy: 0.9876 - val_loss: 0.0131 - val_accuracy: 0.9966 - lr: 1.2500e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0358 - accuracy: 0.9878 - val_loss: 0.0132 - val_accuracy: 0.9966 - lr: 1.2500e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0346 - accuracy: 0.9884 - val_loss: 0.0130 - val_accuracy: 0.9961 - lr: 1.2500e-04\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0334 - accuracy: 0.9891 - val_loss: 0.0121 - val_accuracy: 0.9970 - lr: 1.2500e-04\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0336 - accuracy: 0.9885 - val_loss: 0.0123 - val_accuracy: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0333 - accuracy: 0.9891 - val_loss: 0.0138 - val_accuracy: 0.9958 - lr: 1.2500e-04\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0331 - accuracy: 0.9886 - val_loss: 0.0119 - val_accuracy: 0.9966 - lr: 1.2500e-04\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0332 - accuracy: 0.9891 - val_loss: 0.0118 - val_accuracy: 0.9970 - lr: 1.2500e-04\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0324 - accuracy: 0.9890 - val_loss: 0.0121 - val_accuracy: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0315 - accuracy: 0.9898 - val_loss: 0.0107 - val_accuracy: 0.9973 - lr: 1.2500e-04\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0309 - accuracy: 0.9899 - val_loss: 0.0104 - val_accuracy: 0.9974 - lr: 1.2500e-04\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0309 - accuracy: 0.9898 - val_loss: 0.0111 - val_accuracy: 0.9966 - lr: 1.2500e-04\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0314 - accuracy: 0.9892 - val_loss: 0.0122 - val_accuracy: 0.9964 - lr: 1.2500e-04\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0301 - accuracy: 0.9899 - val_loss: 0.0120 - val_accuracy: 0.9960 - lr: 1.2500e-04\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0288 - accuracy: 0.9905 - val_loss: 0.0102 - val_accuracy: 0.9977 - lr: 6.2500e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0282 - accuracy: 0.9908 - val_loss: 0.0103 - val_accuracy: 0.9972 - lr: 6.2500e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0279 - accuracy: 0.9908 - val_loss: 0.0103 - val_accuracy: 0.9972 - lr: 6.2500e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0284 - accuracy: 0.9907 - val_loss: 0.0101 - val_accuracy: 0.9974 - lr: 6.2500e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0259 - accuracy: 0.9917 - val_loss: 0.0098 - val_accuracy: 0.9977 - lr: 3.1250e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0266 - accuracy: 0.9911 - val_loss: 0.0099 - val_accuracy: 0.9975 - lr: 3.1250e-05\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0254 - accuracy: 0.9919 - val_loss: 0.0096 - val_accuracy: 0.9970 - lr: 3.1250e-05\n",
      "1033/1033 [==============================] - 5s 5ms/step - loss: 0.0104 - accuracy: 0.9971\n",
      "\n",
      "── Fold 10/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 20s 19ms/step - loss: 1.2331 - accuracy: 0.5797 - val_loss: 0.7635 - val_accuracy: 0.7367 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.6461 - accuracy: 0.7818 - val_loss: 0.4650 - val_accuracy: 0.8382 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.4751 - accuracy: 0.8380 - val_loss: 0.3812 - val_accuracy: 0.8687 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.3852 - accuracy: 0.8676 - val_loss: 0.2974 - val_accuracy: 0.8964 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.3261 - accuracy: 0.8870 - val_loss: 0.2337 - val_accuracy: 0.9194 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2889 - accuracy: 0.8986 - val_loss: 0.2363 - val_accuracy: 0.9141 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2573 - accuracy: 0.9099 - val_loss: 0.1895 - val_accuracy: 0.9342 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2310 - accuracy: 0.9188 - val_loss: 0.1881 - val_accuracy: 0.9349 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2150 - accuracy: 0.9244 - val_loss: 0.1296 - val_accuracy: 0.9553 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.2011 - accuracy: 0.9292 - val_loss: 0.1227 - val_accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1886 - accuracy: 0.9328 - val_loss: 0.1175 - val_accuracy: 0.9591 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1737 - accuracy: 0.9387 - val_loss: 0.1191 - val_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1618 - accuracy: 0.9421 - val_loss: 0.0901 - val_accuracy: 0.9664 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1532 - accuracy: 0.9455 - val_loss: 0.0962 - val_accuracy: 0.9672 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1520 - accuracy: 0.9464 - val_loss: 0.1090 - val_accuracy: 0.9620 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1411 - accuracy: 0.9498 - val_loss: 0.0768 - val_accuracy: 0.9734 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1374 - accuracy: 0.9522 - val_loss: 0.0780 - val_accuracy: 0.9728 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1321 - accuracy: 0.9525 - val_loss: 0.0833 - val_accuracy: 0.9704 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.1248 - accuracy: 0.9556 - val_loss: 0.0857 - val_accuracy: 0.9698 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0892 - accuracy: 0.9688 - val_loss: 0.0539 - val_accuracy: 0.9810 - lr: 5.0000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0814 - accuracy: 0.9713 - val_loss: 0.0428 - val_accuracy: 0.9850 - lr: 5.0000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0808 - accuracy: 0.9721 - val_loss: 0.0400 - val_accuracy: 0.9868 - lr: 5.0000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0800 - accuracy: 0.9717 - val_loss: 0.0403 - val_accuracy: 0.9862 - lr: 5.0000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0757 - accuracy: 0.9738 - val_loss: 0.0453 - val_accuracy: 0.9845 - lr: 5.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0734 - accuracy: 0.9740 - val_loss: 0.0419 - val_accuracy: 0.9859 - lr: 5.0000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0595 - accuracy: 0.9796 - val_loss: 0.0282 - val_accuracy: 0.9908 - lr: 2.5000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0559 - accuracy: 0.9809 - val_loss: 0.0263 - val_accuracy: 0.9909 - lr: 2.5000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0551 - accuracy: 0.9804 - val_loss: 0.0252 - val_accuracy: 0.9918 - lr: 2.5000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0524 - accuracy: 0.9822 - val_loss: 0.0249 - val_accuracy: 0.9914 - lr: 2.5000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0531 - accuracy: 0.9815 - val_loss: 0.0250 - val_accuracy: 0.9917 - lr: 2.5000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0521 - accuracy: 0.9824 - val_loss: 0.0247 - val_accuracy: 0.9919 - lr: 2.5000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0526 - accuracy: 0.9821 - val_loss: 0.0290 - val_accuracy: 0.9893 - lr: 2.5000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0506 - accuracy: 0.9827 - val_loss: 0.0243 - val_accuracy: 0.9918 - lr: 2.5000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0496 - accuracy: 0.9828 - val_loss: 0.0242 - val_accuracy: 0.9924 - lr: 2.5000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0482 - accuracy: 0.9836 - val_loss: 0.0240 - val_accuracy: 0.9921 - lr: 2.5000e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0488 - accuracy: 0.9832 - val_loss: 0.0206 - val_accuracy: 0.9922 - lr: 2.5000e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0479 - accuracy: 0.9840 - val_loss: 0.0211 - val_accuracy: 0.9927 - lr: 2.5000e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0469 - accuracy: 0.9841 - val_loss: 0.0212 - val_accuracy: 0.9932 - lr: 2.5000e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0449 - accuracy: 0.9847 - val_loss: 0.0196 - val_accuracy: 0.9940 - lr: 2.5000e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0460 - accuracy: 0.9843 - val_loss: 0.0216 - val_accuracy: 0.9930 - lr: 2.5000e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0444 - accuracy: 0.9846 - val_loss: 0.0208 - val_accuracy: 0.9932 - lr: 2.5000e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0431 - accuracy: 0.9851 - val_loss: 0.0242 - val_accuracy: 0.9915 - lr: 2.5000e-04\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0377 - accuracy: 0.9873 - val_loss: 0.0149 - val_accuracy: 0.9946 - lr: 1.2500e-04\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0366 - accuracy: 0.9879 - val_loss: 0.0172 - val_accuracy: 0.9939 - lr: 1.2500e-04\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0359 - accuracy: 0.9880 - val_loss: 0.0163 - val_accuracy: 0.9945 - lr: 1.2500e-04\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0360 - accuracy: 0.9878 - val_loss: 0.0153 - val_accuracy: 0.9952 - lr: 1.2500e-04\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0330 - accuracy: 0.9889 - val_loss: 0.0142 - val_accuracy: 0.9957 - lr: 6.2500e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0325 - accuracy: 0.9890 - val_loss: 0.0152 - val_accuracy: 0.9953 - lr: 6.2500e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0322 - accuracy: 0.9894 - val_loss: 0.0144 - val_accuracy: 0.9958 - lr: 6.2500e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0318 - accuracy: 0.9895 - val_loss: 0.0151 - val_accuracy: 0.9952 - lr: 6.2500e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0310 - accuracy: 0.9901 - val_loss: 0.0146 - val_accuracy: 0.9952 - lr: 3.1250e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0306 - accuracy: 0.9899 - val_loss: 0.0144 - val_accuracy: 0.9955 - lr: 3.1250e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0306 - accuracy: 0.9901 - val_loss: 0.0140 - val_accuracy: 0.9955 - lr: 3.1250e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0303 - accuracy: 0.9900 - val_loss: 0.0133 - val_accuracy: 0.9959 - lr: 3.1250e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0299 - accuracy: 0.9900 - val_loss: 0.0135 - val_accuracy: 0.9955 - lr: 3.1250e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0294 - accuracy: 0.9906 - val_loss: 0.0136 - val_accuracy: 0.9961 - lr: 3.1250e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0301 - accuracy: 0.9902 - val_loss: 0.0137 - val_accuracy: 0.9959 - lr: 3.1250e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0295 - accuracy: 0.9902 - val_loss: 0.0134 - val_accuracy: 0.9964 - lr: 1.5625e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0286 - accuracy: 0.9906 - val_loss: 0.0133 - val_accuracy: 0.9960 - lr: 1.5625e-05\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 17s 18ms/step - loss: 0.0291 - accuracy: 0.9906 - val_loss: 0.0131 - val_accuracy: 0.9964 - lr: 1.5625e-05\n",
      "1033/1033 [==============================] - 5s 5ms/step - loss: 0.0119 - accuracy: 0.9965\n",
      "\n",
      "################ EMGHandNet_Original – 10-fold CV ################\n",
      "\n",
      "── Fold 1/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 31s 28ms/step - loss: 1.1131 - accuracy: 0.6180 - val_loss: 0.6463 - val_accuracy: 0.7751 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.6297 - accuracy: 0.7820 - val_loss: 0.6301 - val_accuracy: 0.7885 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.4819 - accuracy: 0.8309 - val_loss: 0.4001 - val_accuracy: 0.8624 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.3965 - accuracy: 0.8590 - val_loss: 0.4036 - val_accuracy: 0.8691 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.3477 - accuracy: 0.8770 - val_loss: 0.2686 - val_accuracy: 0.9039 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.3102 - accuracy: 0.8893 - val_loss: 0.2541 - val_accuracy: 0.9120 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.2788 - accuracy: 0.9006 - val_loss: 0.2456 - val_accuracy: 0.9104 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.2611 - accuracy: 0.9069 - val_loss: 0.5089 - val_accuracy: 0.8525 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.2448 - accuracy: 0.9134 - val_loss: 0.2066 - val_accuracy: 0.9272 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.2256 - accuracy: 0.9191 - val_loss: 0.1761 - val_accuracy: 0.9365 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.2176 - accuracy: 0.9222 - val_loss: 0.1159 - val_accuracy: 0.9566 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.2026 - accuracy: 0.9284 - val_loss: 0.1392 - val_accuracy: 0.9499 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.1915 - accuracy: 0.9312 - val_loss: 0.1325 - val_accuracy: 0.9516 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.1839 - accuracy: 0.9341 - val_loss: 0.1710 - val_accuracy: 0.9392 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.1185 - accuracy: 0.9569 - val_loss: 0.0651 - val_accuracy: 0.9767 - lr: 5.0000e-04\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.1046 - accuracy: 0.9620 - val_loss: 0.0710 - val_accuracy: 0.9757 - lr: 5.0000e-04\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.1025 - accuracy: 0.9628 - val_loss: 0.0440 - val_accuracy: 0.9845 - lr: 5.0000e-04\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.1010 - accuracy: 0.9634 - val_loss: 0.0616 - val_accuracy: 0.9775 - lr: 5.0000e-04\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0960 - accuracy: 0.9656 - val_loss: 0.0576 - val_accuracy: 0.9787 - lr: 5.0000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0939 - accuracy: 0.9669 - val_loss: 0.0788 - val_accuracy: 0.9710 - lr: 5.0000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 22s 24ms/step - loss: 0.0678 - accuracy: 0.9754 - val_loss: 0.0305 - val_accuracy: 0.9889 - lr: 2.5000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0601 - accuracy: 0.9779 - val_loss: 0.0295 - val_accuracy: 0.9894 - lr: 2.5000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0600 - accuracy: 0.9783 - val_loss: 0.0320 - val_accuracy: 0.9893 - lr: 2.5000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0592 - accuracy: 0.9788 - val_loss: 0.0301 - val_accuracy: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0572 - accuracy: 0.9791 - val_loss: 0.0228 - val_accuracy: 0.9920 - lr: 2.5000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0555 - accuracy: 0.9804 - val_loss: 0.0233 - val_accuracy: 0.9918 - lr: 2.5000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0569 - accuracy: 0.9797 - val_loss: 0.0240 - val_accuracy: 0.9916 - lr: 2.5000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0517 - accuracy: 0.9812 - val_loss: 0.0229 - val_accuracy: 0.9921 - lr: 2.5000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0412 - accuracy: 0.9853 - val_loss: 0.0150 - val_accuracy: 0.9947 - lr: 1.2500e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0391 - accuracy: 0.9862 - val_loss: 0.0139 - val_accuracy: 0.9952 - lr: 1.2500e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0382 - accuracy: 0.9863 - val_loss: 0.0144 - val_accuracy: 0.9949 - lr: 1.2500e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0374 - accuracy: 0.9866 - val_loss: 0.0136 - val_accuracy: 0.9957 - lr: 1.2500e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0377 - accuracy: 0.9860 - val_loss: 0.0153 - val_accuracy: 0.9952 - lr: 1.2500e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0374 - accuracy: 0.9866 - val_loss: 0.0146 - val_accuracy: 0.9951 - lr: 1.2500e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0337 - accuracy: 0.9878 - val_loss: 0.0131 - val_accuracy: 0.9955 - lr: 1.2500e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0347 - accuracy: 0.9878 - val_loss: 0.0122 - val_accuracy: 0.9958 - lr: 1.2500e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0350 - accuracy: 0.9873 - val_loss: 0.0106 - val_accuracy: 0.9962 - lr: 1.2500e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0334 - accuracy: 0.9882 - val_loss: 0.0164 - val_accuracy: 0.9943 - lr: 1.2500e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0343 - accuracy: 0.9875 - val_loss: 0.0125 - val_accuracy: 0.9952 - lr: 1.2500e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0334 - accuracy: 0.9882 - val_loss: 0.0125 - val_accuracy: 0.9959 - lr: 1.2500e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0297 - accuracy: 0.9891 - val_loss: 0.0098 - val_accuracy: 0.9969 - lr: 6.2500e-05\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0280 - accuracy: 0.9900 - val_loss: 0.0094 - val_accuracy: 0.9969 - lr: 6.2500e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0270 - accuracy: 0.9905 - val_loss: 0.0100 - val_accuracy: 0.9967 - lr: 6.2500e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0273 - accuracy: 0.9900 - val_loss: 0.0101 - val_accuracy: 0.9969 - lr: 6.2500e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0284 - accuracy: 0.9899 - val_loss: 0.0099 - val_accuracy: 0.9968 - lr: 6.2500e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0254 - accuracy: 0.9907 - val_loss: 0.0092 - val_accuracy: 0.9967 - lr: 3.1250e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0237 - accuracy: 0.9914 - val_loss: 0.0085 - val_accuracy: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0244 - accuracy: 0.9914 - val_loss: 0.0084 - val_accuracy: 0.9971 - lr: 3.1250e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0234 - accuracy: 0.9918 - val_loss: 0.0083 - val_accuracy: 0.9971 - lr: 3.1250e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0231 - accuracy: 0.9917 - val_loss: 0.0078 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0233 - accuracy: 0.9915 - val_loss: 0.0078 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 22s 24ms/step - loss: 0.0221 - accuracy: 0.9921 - val_loss: 0.0078 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0236 - accuracy: 0.9913 - val_loss: 0.0079 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0228 - accuracy: 0.9919 - val_loss: 0.0074 - val_accuracy: 0.9977 - lr: 1.5625e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0217 - accuracy: 0.9921 - val_loss: 0.0074 - val_accuracy: 0.9977 - lr: 1.5625e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0217 - accuracy: 0.9922 - val_loss: 0.0074 - val_accuracy: 0.9978 - lr: 1.5625e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0219 - accuracy: 0.9920 - val_loss: 0.0075 - val_accuracy: 0.9974 - lr: 1.5625e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0210 - accuracy: 0.9924 - val_loss: 0.0074 - val_accuracy: 0.9977 - lr: 7.8125e-06\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0207 - accuracy: 0.9927 - val_loss: 0.0072 - val_accuracy: 0.9976 - lr: 7.8125e-06\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0208 - accuracy: 0.9924 - val_loss: 0.0073 - val_accuracy: 0.9976 - lr: 7.8125e-06\n",
      "1033/1033 [==============================] - 9s 9ms/step - loss: 0.0095 - accuracy: 0.9971\n",
      "\n",
      "── Fold 2/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 30s 27ms/step - loss: 1.0976 - accuracy: 0.6224 - val_loss: 0.6875 - val_accuracy: 0.7609 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.6169 - accuracy: 0.7860 - val_loss: 0.6337 - val_accuracy: 0.7924 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.4718 - accuracy: 0.8358 - val_loss: 0.4738 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.3960 - accuracy: 0.8607 - val_loss: 0.3681 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.3409 - accuracy: 0.8794 - val_loss: 0.3643 - val_accuracy: 0.8772 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.3015 - accuracy: 0.8921 - val_loss: 0.3606 - val_accuracy: 0.8803 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.2722 - accuracy: 0.9032 - val_loss: 0.2379 - val_accuracy: 0.9130 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.2580 - accuracy: 0.9086 - val_loss: 0.3082 - val_accuracy: 0.8992 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.2366 - accuracy: 0.9157 - val_loss: 0.2061 - val_accuracy: 0.9250 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.2224 - accuracy: 0.9209 - val_loss: 0.1738 - val_accuracy: 0.9361 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.2081 - accuracy: 0.9249 - val_loss: 0.2446 - val_accuracy: 0.9210 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.2048 - accuracy: 0.9279 - val_loss: 0.1515 - val_accuracy: 0.9474 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.1901 - accuracy: 0.9322 - val_loss: 0.1187 - val_accuracy: 0.9578 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.1796 - accuracy: 0.9365 - val_loss: 0.1116 - val_accuracy: 0.9588 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.1737 - accuracy: 0.9378 - val_loss: 0.1141 - val_accuracy: 0.9589 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.1691 - accuracy: 0.9401 - val_loss: 0.1570 - val_accuracy: 0.9461 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.1618 - accuracy: 0.9427 - val_loss: 0.1606 - val_accuracy: 0.9448 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.1002 - accuracy: 0.9641 - val_loss: 0.0434 - val_accuracy: 0.9836 - lr: 5.0000e-04\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0905 - accuracy: 0.9671 - val_loss: 0.0626 - val_accuracy: 0.9769 - lr: 5.0000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0904 - accuracy: 0.9670 - val_loss: 0.0592 - val_accuracy: 0.9774 - lr: 5.0000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0851 - accuracy: 0.9690 - val_loss: 0.0580 - val_accuracy: 0.9797 - lr: 5.0000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0630 - accuracy: 0.9773 - val_loss: 0.0301 - val_accuracy: 0.9891 - lr: 2.5000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0563 - accuracy: 0.9797 - val_loss: 0.0239 - val_accuracy: 0.9916 - lr: 2.5000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0547 - accuracy: 0.9801 - val_loss: 0.0237 - val_accuracy: 0.9924 - lr: 2.5000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0527 - accuracy: 0.9809 - val_loss: 0.0286 - val_accuracy: 0.9890 - lr: 2.5000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0534 - accuracy: 0.9809 - val_loss: 0.0228 - val_accuracy: 0.9924 - lr: 2.5000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0527 - accuracy: 0.9808 - val_loss: 0.0233 - val_accuracy: 0.9919 - lr: 2.5000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0498 - accuracy: 0.9818 - val_loss: 0.0219 - val_accuracy: 0.9926 - lr: 2.5000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0494 - accuracy: 0.9820 - val_loss: 0.0197 - val_accuracy: 0.9933 - lr: 2.5000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 22s 24ms/step - loss: 0.0461 - accuracy: 0.9828 - val_loss: 0.0200 - val_accuracy: 0.9932 - lr: 2.5000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0465 - accuracy: 0.9835 - val_loss: 0.0236 - val_accuracy: 0.9919 - lr: 2.5000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0476 - accuracy: 0.9829 - val_loss: 0.0221 - val_accuracy: 0.9927 - lr: 2.5000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0351 - accuracy: 0.9874 - val_loss: 0.0127 - val_accuracy: 0.9959 - lr: 1.2500e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0333 - accuracy: 0.9874 - val_loss: 0.0141 - val_accuracy: 0.9957 - lr: 1.2500e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0344 - accuracy: 0.9877 - val_loss: 0.0128 - val_accuracy: 0.9954 - lr: 1.2500e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0328 - accuracy: 0.9880 - val_loss: 0.0131 - val_accuracy: 0.9958 - lr: 1.2500e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0278 - accuracy: 0.9899 - val_loss: 0.0109 - val_accuracy: 0.9965 - lr: 6.2500e-05\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0277 - accuracy: 0.9899 - val_loss: 0.0106 - val_accuracy: 0.9963 - lr: 6.2500e-05\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0272 - accuracy: 0.9897 - val_loss: 0.0114 - val_accuracy: 0.9962 - lr: 6.2500e-05\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0250 - accuracy: 0.9906 - val_loss: 0.0109 - val_accuracy: 0.9962 - lr: 6.2500e-05\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0259 - accuracy: 0.9907 - val_loss: 0.0091 - val_accuracy: 0.9974 - lr: 6.2500e-05\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0267 - accuracy: 0.9903 - val_loss: 0.0093 - val_accuracy: 0.9969 - lr: 6.2500e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0251 - accuracy: 0.9907 - val_loss: 0.0092 - val_accuracy: 0.9972 - lr: 6.2500e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0254 - accuracy: 0.9910 - val_loss: 0.0101 - val_accuracy: 0.9970 - lr: 6.2500e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0235 - accuracy: 0.9917 - val_loss: 0.0088 - val_accuracy: 0.9977 - lr: 3.1250e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0233 - accuracy: 0.9913 - val_loss: 0.0086 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0222 - accuracy: 0.9920 - val_loss: 0.0087 - val_accuracy: 0.9975 - lr: 3.1250e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0217 - accuracy: 0.9921 - val_loss: 0.0088 - val_accuracy: 0.9975 - lr: 3.1250e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0213 - accuracy: 0.9921 - val_loss: 0.0087 - val_accuracy: 0.9975 - lr: 3.1250e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0205 - accuracy: 0.9925 - val_loss: 0.0085 - val_accuracy: 0.9977 - lr: 1.5625e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0210 - accuracy: 0.9923 - val_loss: 0.0084 - val_accuracy: 0.9975 - lr: 1.5625e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0202 - accuracy: 0.9925 - val_loss: 0.0085 - val_accuracy: 0.9977 - lr: 1.5625e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0206 - accuracy: 0.9926 - val_loss: 0.0083 - val_accuracy: 0.9976 - lr: 1.5625e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0204 - accuracy: 0.9926 - val_loss: 0.0076 - val_accuracy: 0.9977 - lr: 1.5625e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0199 - accuracy: 0.9928 - val_loss: 0.0079 - val_accuracy: 0.9977 - lr: 1.5625e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0196 - accuracy: 0.9927 - val_loss: 0.0079 - val_accuracy: 0.9979 - lr: 1.5625e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0190 - accuracy: 0.9932 - val_loss: 0.0078 - val_accuracy: 0.9977 - lr: 1.5625e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0192 - accuracy: 0.9929 - val_loss: 0.0074 - val_accuracy: 0.9978 - lr: 7.8125e-06\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0183 - accuracy: 0.9934 - val_loss: 0.0077 - val_accuracy: 0.9976 - lr: 7.8125e-06\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0190 - accuracy: 0.9931 - val_loss: 0.0077 - val_accuracy: 0.9977 - lr: 7.8125e-06\n",
      "1033/1033 [==============================] - 9s 9ms/step - loss: 0.0076 - accuracy: 0.9977\n",
      "\n",
      "── Fold 3/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 29s 26ms/step - loss: 1.0850 - accuracy: 0.6268 - val_loss: 0.7045 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.6155 - accuracy: 0.7857 - val_loss: 0.7016 - val_accuracy: 0.7701 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.4651 - accuracy: 0.8359 - val_loss: 0.4790 - val_accuracy: 0.8367 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.3894 - accuracy: 0.8627 - val_loss: 0.3807 - val_accuracy: 0.8649 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.3373 - accuracy: 0.8797 - val_loss: 0.2751 - val_accuracy: 0.9011 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.2996 - accuracy: 0.8940 - val_loss: 0.2619 - val_accuracy: 0.9049 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.2733 - accuracy: 0.9014 - val_loss: 0.2540 - val_accuracy: 0.9117 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.2534 - accuracy: 0.9101 - val_loss: 0.3067 - val_accuracy: 0.8978 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.2377 - accuracy: 0.9158 - val_loss: 0.2692 - val_accuracy: 0.9095 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.2232 - accuracy: 0.9200 - val_loss: 0.2052 - val_accuracy: 0.9274 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.2068 - accuracy: 0.9260 - val_loss: 0.1625 - val_accuracy: 0.9430 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.1993 - accuracy: 0.9293 - val_loss: 0.1798 - val_accuracy: 0.9362 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.1872 - accuracy: 0.9344 - val_loss: 0.2460 - val_accuracy: 0.9219 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.1778 - accuracy: 0.9372 - val_loss: 0.1740 - val_accuracy: 0.9418 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.1088 - accuracy: 0.9603 - val_loss: 0.0792 - val_accuracy: 0.9723 - lr: 5.0000e-04\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0996 - accuracy: 0.9643 - val_loss: 0.0627 - val_accuracy: 0.9772 - lr: 5.0000e-04\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0940 - accuracy: 0.9659 - val_loss: 0.0724 - val_accuracy: 0.9744 - lr: 5.0000e-04\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0926 - accuracy: 0.9665 - val_loss: 0.0702 - val_accuracy: 0.9756 - lr: 5.0000e-04\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0922 - accuracy: 0.9669 - val_loss: 0.0566 - val_accuracy: 0.9807 - lr: 5.0000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0895 - accuracy: 0.9681 - val_loss: 0.0720 - val_accuracy: 0.9759 - lr: 5.0000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0879 - accuracy: 0.9684 - val_loss: 0.0843 - val_accuracy: 0.9713 - lr: 5.0000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0815 - accuracy: 0.9706 - val_loss: 0.0593 - val_accuracy: 0.9785 - lr: 5.0000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.0575 - accuracy: 0.9797 - val_loss: 0.0308 - val_accuracy: 0.9888 - lr: 2.5000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.0547 - accuracy: 0.9797 - val_loss: 0.0301 - val_accuracy: 0.9901 - lr: 2.5000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 28s 29ms/step - loss: 0.0529 - accuracy: 0.9811 - val_loss: 0.0264 - val_accuracy: 0.9906 - lr: 2.5000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0511 - accuracy: 0.9818 - val_loss: 0.0261 - val_accuracy: 0.9925 - lr: 2.5000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0497 - accuracy: 0.9820 - val_loss: 0.0313 - val_accuracy: 0.9893 - lr: 2.5000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.0482 - accuracy: 0.9825 - val_loss: 0.0313 - val_accuracy: 0.9905 - lr: 2.5000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.0486 - accuracy: 0.9823 - val_loss: 0.0220 - val_accuracy: 0.9932 - lr: 2.5000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0470 - accuracy: 0.9830 - val_loss: 0.0288 - val_accuracy: 0.9913 - lr: 2.5000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0443 - accuracy: 0.9844 - val_loss: 0.0310 - val_accuracy: 0.9899 - lr: 2.5000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0447 - accuracy: 0.9841 - val_loss: 0.0311 - val_accuracy: 0.9910 - lr: 2.5000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0346 - accuracy: 0.9876 - val_loss: 0.0216 - val_accuracy: 0.9934 - lr: 1.2500e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0328 - accuracy: 0.9881 - val_loss: 0.0172 - val_accuracy: 0.9951 - lr: 1.2500e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 26s 28ms/step - loss: 0.0313 - accuracy: 0.9889 - val_loss: 0.0180 - val_accuracy: 0.9948 - lr: 1.2500e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.0302 - accuracy: 0.9887 - val_loss: 0.0165 - val_accuracy: 0.9955 - lr: 1.2500e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.0308 - accuracy: 0.9890 - val_loss: 0.0159 - val_accuracy: 0.9956 - lr: 1.2500e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0304 - accuracy: 0.9892 - val_loss: 0.0183 - val_accuracy: 0.9949 - lr: 1.2500e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 26s 28ms/step - loss: 0.0293 - accuracy: 0.9894 - val_loss: 0.0174 - val_accuracy: 0.9944 - lr: 1.2500e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0281 - accuracy: 0.9901 - val_loss: 0.0162 - val_accuracy: 0.9950 - lr: 1.2500e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0255 - accuracy: 0.9907 - val_loss: 0.0151 - val_accuracy: 0.9956 - lr: 6.2500e-05\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 26s 28ms/step - loss: 0.0241 - accuracy: 0.9914 - val_loss: 0.0139 - val_accuracy: 0.9958 - lr: 6.2500e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0233 - accuracy: 0.9915 - val_loss: 0.0144 - val_accuracy: 0.9961 - lr: 6.2500e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0235 - accuracy: 0.9917 - val_loss: 0.0143 - val_accuracy: 0.9961 - lr: 6.2500e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0233 - accuracy: 0.9918 - val_loss: 0.0131 - val_accuracy: 0.9960 - lr: 6.2500e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0222 - accuracy: 0.9920 - val_loss: 0.0147 - val_accuracy: 0.9956 - lr: 6.2500e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0208 - accuracy: 0.9923 - val_loss: 0.0145 - val_accuracy: 0.9957 - lr: 6.2500e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0224 - accuracy: 0.9921 - val_loss: 0.0134 - val_accuracy: 0.9963 - lr: 6.2500e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0203 - accuracy: 0.9929 - val_loss: 0.0129 - val_accuracy: 0.9964 - lr: 3.1250e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0195 - accuracy: 0.9928 - val_loss: 0.0120 - val_accuracy: 0.9964 - lr: 3.1250e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0192 - accuracy: 0.9927 - val_loss: 0.0124 - val_accuracy: 0.9964 - lr: 3.1250e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0194 - accuracy: 0.9929 - val_loss: 0.0126 - val_accuracy: 0.9965 - lr: 3.1250e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.0198 - accuracy: 0.9926 - val_loss: 0.0121 - val_accuracy: 0.9969 - lr: 3.1250e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0180 - accuracy: 0.9936 - val_loss: 0.0116 - val_accuracy: 0.9971 - lr: 1.5625e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 0.0115 - val_accuracy: 0.9971 - lr: 1.5625e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0170 - accuracy: 0.9939 - val_loss: 0.0120 - val_accuracy: 0.9972 - lr: 1.5625e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0174 - accuracy: 0.9939 - val_loss: 0.0115 - val_accuracy: 0.9967 - lr: 1.5625e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0173 - accuracy: 0.9940 - val_loss: 0.0112 - val_accuracy: 0.9971 - lr: 1.5625e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0173 - accuracy: 0.9936 - val_loss: 0.0116 - val_accuracy: 0.9968 - lr: 1.5625e-05\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0175 - accuracy: 0.9938 - val_loss: 0.0116 - val_accuracy: 0.9967 - lr: 1.5625e-05\n",
      "1033/1033 [==============================] - 12s 11ms/step - loss: 0.0088 - accuracy: 0.9975\n",
      "\n",
      "── Fold 4/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 37s 34ms/step - loss: 1.1189 - accuracy: 0.6157 - val_loss: 0.6704 - val_accuracy: 0.7704 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.6273 - accuracy: 0.7832 - val_loss: 0.4778 - val_accuracy: 0.8291 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.4806 - accuracy: 0.8322 - val_loss: 0.3488 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 26s 28ms/step - loss: 0.3974 - accuracy: 0.8599 - val_loss: 0.3266 - val_accuracy: 0.8825 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 26s 27ms/step - loss: 0.3441 - accuracy: 0.8781 - val_loss: 0.2709 - val_accuracy: 0.9053 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.3068 - accuracy: 0.8913 - val_loss: 0.2654 - val_accuracy: 0.9052 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.2781 - accuracy: 0.9004 - val_loss: 0.1936 - val_accuracy: 0.9259 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.2550 - accuracy: 0.9085 - val_loss: 0.2024 - val_accuracy: 0.9261 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.2415 - accuracy: 0.9136 - val_loss: 0.2088 - val_accuracy: 0.9272 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.2212 - accuracy: 0.9210 - val_loss: 0.2213 - val_accuracy: 0.9194 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.1402 - accuracy: 0.9491 - val_loss: 0.0848 - val_accuracy: 0.9682 - lr: 5.0000e-04\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.1285 - accuracy: 0.9539 - val_loss: 0.0711 - val_accuracy: 0.9747 - lr: 5.0000e-04\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 26s 28ms/step - loss: 0.1224 - accuracy: 0.9560 - val_loss: 0.1055 - val_accuracy: 0.9651 - lr: 5.0000e-04\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.1167 - accuracy: 0.9578 - val_loss: 0.0619 - val_accuracy: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.1125 - accuracy: 0.9587 - val_loss: 0.0868 - val_accuracy: 0.9696 - lr: 5.0000e-04\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.1087 - accuracy: 0.9612 - val_loss: 0.0645 - val_accuracy: 0.9769 - lr: 5.0000e-04\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 27s 28ms/step - loss: 0.1037 - accuracy: 0.9625 - val_loss: 0.0623 - val_accuracy: 0.9784 - lr: 5.0000e-04\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0732 - accuracy: 0.9732 - val_loss: 0.0391 - val_accuracy: 0.9861 - lr: 2.5000e-04\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0662 - accuracy: 0.9766 - val_loss: 0.0345 - val_accuracy: 0.9867 - lr: 2.5000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0644 - accuracy: 0.9770 - val_loss: 0.0309 - val_accuracy: 0.9890 - lr: 2.5000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0632 - accuracy: 0.9768 - val_loss: 0.0258 - val_accuracy: 0.9920 - lr: 2.5000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0626 - accuracy: 0.9772 - val_loss: 0.0257 - val_accuracy: 0.9918 - lr: 2.5000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0588 - accuracy: 0.9787 - val_loss: 0.0306 - val_accuracy: 0.9898 - lr: 2.5000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0601 - accuracy: 0.9782 - val_loss: 0.0276 - val_accuracy: 0.9902 - lr: 2.5000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0445 - accuracy: 0.9837 - val_loss: 0.0186 - val_accuracy: 0.9933 - lr: 1.2500e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0460 - accuracy: 0.9834 - val_loss: 0.0185 - val_accuracy: 0.9936 - lr: 1.2500e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0442 - accuracy: 0.9837 - val_loss: 0.0175 - val_accuracy: 0.9946 - lr: 1.2500e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0407 - accuracy: 0.9850 - val_loss: 0.0176 - val_accuracy: 0.9939 - lr: 1.2500e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0414 - accuracy: 0.9851 - val_loss: 0.0174 - val_accuracy: 0.9948 - lr: 1.2500e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0398 - accuracy: 0.9856 - val_loss: 0.0185 - val_accuracy: 0.9943 - lr: 1.2500e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0401 - accuracy: 0.9854 - val_loss: 0.0177 - val_accuracy: 0.9943 - lr: 1.2500e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0379 - accuracy: 0.9863 - val_loss: 0.0183 - val_accuracy: 0.9938 - lr: 1.2500e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0343 - accuracy: 0.9876 - val_loss: 0.0160 - val_accuracy: 0.9954 - lr: 6.2500e-05\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0311 - accuracy: 0.9883 - val_loss: 0.0133 - val_accuracy: 0.9965 - lr: 6.2500e-05\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0317 - accuracy: 0.9884 - val_loss: 0.0161 - val_accuracy: 0.9957 - lr: 6.2500e-05\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0315 - accuracy: 0.9883 - val_loss: 0.0141 - val_accuracy: 0.9959 - lr: 6.2500e-05\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0309 - accuracy: 0.9887 - val_loss: 0.0145 - val_accuracy: 0.9961 - lr: 6.2500e-05\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 28s 29ms/step - loss: 0.0282 - accuracy: 0.9895 - val_loss: 0.0130 - val_accuracy: 0.9961 - lr: 3.1250e-05\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0276 - accuracy: 0.9899 - val_loss: 0.0128 - val_accuracy: 0.9965 - lr: 3.1250e-05\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 28s 29ms/step - loss: 0.0284 - accuracy: 0.9897 - val_loss: 0.0131 - val_accuracy: 0.9962 - lr: 3.1250e-05\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.0261 - accuracy: 0.9905 - val_loss: 0.0129 - val_accuracy: 0.9963 - lr: 3.1250e-05\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0266 - accuracy: 0.9906 - val_loss: 0.0125 - val_accuracy: 0.9964 - lr: 3.1250e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0259 - accuracy: 0.9906 - val_loss: 0.0120 - val_accuracy: 0.9968 - lr: 3.1250e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0259 - accuracy: 0.9909 - val_loss: 0.0126 - val_accuracy: 0.9961 - lr: 3.1250e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0267 - accuracy: 0.9902 - val_loss: 0.0121 - val_accuracy: 0.9966 - lr: 3.1250e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0253 - accuracy: 0.9909 - val_loss: 0.0116 - val_accuracy: 0.9970 - lr: 3.1250e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.0266 - accuracy: 0.9906 - val_loss: 0.0128 - val_accuracy: 0.9963 - lr: 3.1250e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 27s 28ms/step - loss: 0.0258 - accuracy: 0.9907 - val_loss: 0.0122 - val_accuracy: 0.9964 - lr: 3.1250e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.0254 - accuracy: 0.9908 - val_loss: 0.0113 - val_accuracy: 0.9967 - lr: 3.1250e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0254 - accuracy: 0.9907 - val_loss: 0.0128 - val_accuracy: 0.9962 - lr: 3.1250e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 45s 48ms/step - loss: 0.0250 - accuracy: 0.9910 - val_loss: 0.0121 - val_accuracy: 0.9968 - lr: 3.1250e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 64s 69ms/step - loss: 0.0267 - accuracy: 0.9903 - val_loss: 0.0122 - val_accuracy: 0.9971 - lr: 3.1250e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 41s 44ms/step - loss: 0.0243 - accuracy: 0.9912 - val_loss: 0.0118 - val_accuracy: 0.9968 - lr: 1.5625e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 26s 28ms/step - loss: 0.0241 - accuracy: 0.9913 - val_loss: 0.0119 - val_accuracy: 0.9969 - lr: 1.5625e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0245 - accuracy: 0.9913 - val_loss: 0.0112 - val_accuracy: 0.9971 - lr: 1.5625e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0220 - accuracy: 0.9922 - val_loss: 0.0114 - val_accuracy: 0.9974 - lr: 7.8125e-06\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 35s 37ms/step - loss: 0.0226 - accuracy: 0.9920 - val_loss: 0.0110 - val_accuracy: 0.9971 - lr: 7.8125e-06\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 26s 28ms/step - loss: 0.0232 - accuracy: 0.9919 - val_loss: 0.0111 - val_accuracy: 0.9974 - lr: 7.8125e-06\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.0227 - accuracy: 0.9920 - val_loss: 0.0111 - val_accuracy: 0.9974 - lr: 7.8125e-06\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 26s 28ms/step - loss: 0.0221 - accuracy: 0.9918 - val_loss: 0.0108 - val_accuracy: 0.9974 - lr: 7.8125e-06\n",
      "1033/1033 [==============================] - 10s 10ms/step - loss: 0.0091 - accuracy: 0.9972\n",
      "\n",
      "── Fold 5/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 33s 29ms/step - loss: 1.1079 - accuracy: 0.6201 - val_loss: 0.8630 - val_accuracy: 0.7233 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.6229 - accuracy: 0.7833 - val_loss: 0.5659 - val_accuracy: 0.8109 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.4828 - accuracy: 0.8313 - val_loss: 0.5205 - val_accuracy: 0.8233 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 26s 27ms/step - loss: 0.4004 - accuracy: 0.8589 - val_loss: 0.3722 - val_accuracy: 0.8735 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.3465 - accuracy: 0.8765 - val_loss: 0.3604 - val_accuracy: 0.8780 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 26s 28ms/step - loss: 0.3058 - accuracy: 0.8914 - val_loss: 0.3702 - val_accuracy: 0.8739 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 26s 27ms/step - loss: 0.2815 - accuracy: 0.9014 - val_loss: 0.2237 - val_accuracy: 0.9207 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.2615 - accuracy: 0.9064 - val_loss: 0.1947 - val_accuracy: 0.9313 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.2420 - accuracy: 0.9140 - val_loss: 0.3726 - val_accuracy: 0.8862 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.2221 - accuracy: 0.9215 - val_loss: 0.2556 - val_accuracy: 0.9126 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.2177 - accuracy: 0.9233 - val_loss: 0.2314 - val_accuracy: 0.9196 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.1379 - accuracy: 0.9503 - val_loss: 0.0875 - val_accuracy: 0.9688 - lr: 5.0000e-04\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.1236 - accuracy: 0.9552 - val_loss: 0.0967 - val_accuracy: 0.9643 - lr: 5.0000e-04\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.1206 - accuracy: 0.9564 - val_loss: 0.0633 - val_accuracy: 0.9771 - lr: 5.0000e-04\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.1142 - accuracy: 0.9590 - val_loss: 0.0669 - val_accuracy: 0.9753 - lr: 5.0000e-04\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.1098 - accuracy: 0.9600 - val_loss: 0.0600 - val_accuracy: 0.9787 - lr: 5.0000e-04\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 26s 28ms/step - loss: 0.1066 - accuracy: 0.9619 - val_loss: 0.0472 - val_accuracy: 0.9853 - lr: 5.0000e-04\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.1030 - accuracy: 0.9630 - val_loss: 0.0540 - val_accuracy: 0.9801 - lr: 5.0000e-04\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 26s 28ms/step - loss: 0.1031 - accuracy: 0.9633 - val_loss: 0.1225 - val_accuracy: 0.9582 - lr: 5.0000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.1002 - accuracy: 0.9638 - val_loss: 0.0564 - val_accuracy: 0.9792 - lr: 5.0000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0692 - accuracy: 0.9749 - val_loss: 0.0291 - val_accuracy: 0.9905 - lr: 2.5000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0630 - accuracy: 0.9772 - val_loss: 0.0261 - val_accuracy: 0.9917 - lr: 2.5000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0609 - accuracy: 0.9779 - val_loss: 0.0321 - val_accuracy: 0.9898 - lr: 2.5000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0596 - accuracy: 0.9783 - val_loss: 0.0287 - val_accuracy: 0.9895 - lr: 2.5000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0568 - accuracy: 0.9794 - val_loss: 0.0232 - val_accuracy: 0.9923 - lr: 2.5000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0576 - accuracy: 0.9792 - val_loss: 0.0317 - val_accuracy: 0.9880 - lr: 2.5000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0559 - accuracy: 0.9796 - val_loss: 0.0254 - val_accuracy: 0.9912 - lr: 2.5000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0551 - accuracy: 0.9799 - val_loss: 0.0272 - val_accuracy: 0.9899 - lr: 2.5000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0424 - accuracy: 0.9848 - val_loss: 0.0187 - val_accuracy: 0.9937 - lr: 1.2500e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0395 - accuracy: 0.9859 - val_loss: 0.0192 - val_accuracy: 0.9939 - lr: 1.2500e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0400 - accuracy: 0.9854 - val_loss: 0.0152 - val_accuracy: 0.9950 - lr: 1.2500e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0401 - accuracy: 0.9855 - val_loss: 0.0127 - val_accuracy: 0.9961 - lr: 1.2500e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0370 - accuracy: 0.9872 - val_loss: 0.0139 - val_accuracy: 0.9952 - lr: 1.2500e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.0361 - accuracy: 0.9868 - val_loss: 0.0136 - val_accuracy: 0.9955 - lr: 1.2500e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 26s 28ms/step - loss: 0.0365 - accuracy: 0.9867 - val_loss: 0.0140 - val_accuracy: 0.9949 - lr: 1.2500e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0315 - accuracy: 0.9889 - val_loss: 0.0120 - val_accuracy: 0.9963 - lr: 6.2500e-05\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.0301 - accuracy: 0.9891 - val_loss: 0.0123 - val_accuracy: 0.9958 - lr: 6.2500e-05\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.0291 - accuracy: 0.9894 - val_loss: 0.0109 - val_accuracy: 0.9959 - lr: 6.2500e-05\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0295 - accuracy: 0.9894 - val_loss: 0.0110 - val_accuracy: 0.9967 - lr: 6.2500e-05\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 26s 28ms/step - loss: 0.0286 - accuracy: 0.9897 - val_loss: 0.0135 - val_accuracy: 0.9964 - lr: 6.2500e-05\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0295 - accuracy: 0.9893 - val_loss: 0.0105 - val_accuracy: 0.9967 - lr: 6.2500e-05\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0297 - accuracy: 0.9895 - val_loss: 0.0105 - val_accuracy: 0.9965 - lr: 6.2500e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0278 - accuracy: 0.9897 - val_loss: 0.0106 - val_accuracy: 0.9967 - lr: 6.2500e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0289 - accuracy: 0.9893 - val_loss: 0.0108 - val_accuracy: 0.9964 - lr: 6.2500e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0255 - accuracy: 0.9909 - val_loss: 0.0100 - val_accuracy: 0.9968 - lr: 3.1250e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0249 - accuracy: 0.9913 - val_loss: 0.0094 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0253 - accuracy: 0.9908 - val_loss: 0.0094 - val_accuracy: 0.9971 - lr: 3.1250e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0243 - accuracy: 0.9911 - val_loss: 0.0092 - val_accuracy: 0.9973 - lr: 3.1250e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0251 - accuracy: 0.9910 - val_loss: 0.0096 - val_accuracy: 0.9971 - lr: 3.1250e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0235 - accuracy: 0.9914 - val_loss: 0.0097 - val_accuracy: 0.9970 - lr: 3.1250e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0223 - accuracy: 0.9920 - val_loss: 0.0086 - val_accuracy: 0.9976 - lr: 3.1250e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0232 - accuracy: 0.9918 - val_loss: 0.0089 - val_accuracy: 0.9971 - lr: 3.1250e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0242 - accuracy: 0.9912 - val_loss: 0.0085 - val_accuracy: 0.9977 - lr: 3.1250e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0244 - accuracy: 0.9916 - val_loss: 0.0080 - val_accuracy: 0.9975 - lr: 3.1250e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0236 - accuracy: 0.9916 - val_loss: 0.0084 - val_accuracy: 0.9971 - lr: 3.1250e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0227 - accuracy: 0.9917 - val_loss: 0.0086 - val_accuracy: 0.9975 - lr: 3.1250e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 22s 24ms/step - loss: 0.0236 - accuracy: 0.9916 - val_loss: 0.0083 - val_accuracy: 0.9973 - lr: 3.1250e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0235 - accuracy: 0.9916 - val_loss: 0.0083 - val_accuracy: 0.9977 - lr: 1.5625e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0214 - accuracy: 0.9924 - val_loss: 0.0081 - val_accuracy: 0.9974 - lr: 1.5625e-05\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0219 - accuracy: 0.9921 - val_loss: 0.0080 - val_accuracy: 0.9977 - lr: 1.5625e-05\n",
      "1033/1033 [==============================] - 9s 8ms/step - loss: 0.0081 - accuracy: 0.9975\n",
      "\n",
      "── Fold 6/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 28s 25ms/step - loss: 1.1108 - accuracy: 0.6172 - val_loss: 0.7932 - val_accuracy: 0.7346 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.6269 - accuracy: 0.7812 - val_loss: 0.4940 - val_accuracy: 0.8292 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.4818 - accuracy: 0.8311 - val_loss: 0.3946 - val_accuracy: 0.8629 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.3945 - accuracy: 0.8609 - val_loss: 0.4155 - val_accuracy: 0.8555 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 28s 29ms/step - loss: 0.3449 - accuracy: 0.8775 - val_loss: 0.2792 - val_accuracy: 0.8971 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.3063 - accuracy: 0.8918 - val_loss: 0.3929 - val_accuracy: 0.8811 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.2808 - accuracy: 0.9001 - val_loss: 0.3049 - val_accuracy: 0.8952 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.2569 - accuracy: 0.9079 - val_loss: 0.4171 - val_accuracy: 0.8749 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.1620 - accuracy: 0.9419 - val_loss: 0.0999 - val_accuracy: 0.9641 - lr: 5.0000e-04\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.1476 - accuracy: 0.9466 - val_loss: 0.1028 - val_accuracy: 0.9620 - lr: 5.0000e-04\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.1381 - accuracy: 0.9495 - val_loss: 0.0906 - val_accuracy: 0.9660 - lr: 5.0000e-04\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.1350 - accuracy: 0.9514 - val_loss: 0.0909 - val_accuracy: 0.9660 - lr: 5.0000e-04\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.1294 - accuracy: 0.9533 - val_loss: 0.0727 - val_accuracy: 0.9761 - lr: 5.0000e-04\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.1211 - accuracy: 0.9558 - val_loss: 0.0591 - val_accuracy: 0.9784 - lr: 5.0000e-04\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.1170 - accuracy: 0.9581 - val_loss: 0.0705 - val_accuracy: 0.9756 - lr: 5.0000e-04\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.1138 - accuracy: 0.9588 - val_loss: 0.0813 - val_accuracy: 0.9718 - lr: 5.0000e-04\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.1111 - accuracy: 0.9600 - val_loss: 0.0802 - val_accuracy: 0.9700 - lr: 5.0000e-04\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0768 - accuracy: 0.9726 - val_loss: 0.0349 - val_accuracy: 0.9879 - lr: 2.5000e-04\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0702 - accuracy: 0.9740 - val_loss: 0.0318 - val_accuracy: 0.9887 - lr: 2.5000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0680 - accuracy: 0.9756 - val_loss: 0.0329 - val_accuracy: 0.9885 - lr: 2.5000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0692 - accuracy: 0.9749 - val_loss: 0.0352 - val_accuracy: 0.9877 - lr: 2.5000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0642 - accuracy: 0.9769 - val_loss: 0.0274 - val_accuracy: 0.9899 - lr: 2.5000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.0655 - accuracy: 0.9759 - val_loss: 0.0312 - val_accuracy: 0.9889 - lr: 2.5000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0628 - accuracy: 0.9774 - val_loss: 0.0296 - val_accuracy: 0.9893 - lr: 2.5000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0604 - accuracy: 0.9783 - val_loss: 0.0301 - val_accuracy: 0.9899 - lr: 2.5000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0469 - accuracy: 0.9830 - val_loss: 0.0206 - val_accuracy: 0.9927 - lr: 1.2500e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0440 - accuracy: 0.9837 - val_loss: 0.0172 - val_accuracy: 0.9951 - lr: 1.2500e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 26s 28ms/step - loss: 0.0440 - accuracy: 0.9840 - val_loss: 0.0215 - val_accuracy: 0.9934 - lr: 1.2500e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 27s 28ms/step - loss: 0.0405 - accuracy: 0.9856 - val_loss: 0.0190 - val_accuracy: 0.9934 - lr: 1.2500e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0415 - accuracy: 0.9847 - val_loss: 0.0179 - val_accuracy: 0.9939 - lr: 1.2500e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0360 - accuracy: 0.9868 - val_loss: 0.0151 - val_accuracy: 0.9949 - lr: 6.2500e-05\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 30s 33ms/step - loss: 0.0339 - accuracy: 0.9875 - val_loss: 0.0124 - val_accuracy: 0.9959 - lr: 6.2500e-05\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 27s 28ms/step - loss: 0.0329 - accuracy: 0.9878 - val_loss: 0.0155 - val_accuracy: 0.9949 - lr: 6.2500e-05\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.0352 - accuracy: 0.9871 - val_loss: 0.0137 - val_accuracy: 0.9962 - lr: 6.2500e-05\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0328 - accuracy: 0.9882 - val_loss: 0.0140 - val_accuracy: 0.9957 - lr: 6.2500e-05\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0308 - accuracy: 0.9890 - val_loss: 0.0125 - val_accuracy: 0.9966 - lr: 3.1250e-05\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0320 - accuracy: 0.9884 - val_loss: 0.0119 - val_accuracy: 0.9968 - lr: 3.1250e-05\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0290 - accuracy: 0.9891 - val_loss: 0.0124 - val_accuracy: 0.9964 - lr: 3.1250e-05\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0284 - accuracy: 0.9896 - val_loss: 0.0124 - val_accuracy: 0.9965 - lr: 3.1250e-05\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 32s 35ms/step - loss: 0.0298 - accuracy: 0.9895 - val_loss: 0.0123 - val_accuracy: 0.9968 - lr: 3.1250e-05\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0254 - accuracy: 0.9907 - val_loss: 0.0122 - val_accuracy: 0.9963 - lr: 1.5625e-05\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.0267 - accuracy: 0.9901 - val_loss: 0.0119 - val_accuracy: 0.9967 - lr: 1.5625e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.0268 - accuracy: 0.9899 - val_loss: 0.0112 - val_accuracy: 0.9968 - lr: 1.5625e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.0262 - accuracy: 0.9903 - val_loss: 0.0114 - val_accuracy: 0.9968 - lr: 1.5625e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.0278 - accuracy: 0.9897 - val_loss: 0.0113 - val_accuracy: 0.9971 - lr: 1.5625e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 39s 42ms/step - loss: 0.0260 - accuracy: 0.9904 - val_loss: 0.0116 - val_accuracy: 0.9969 - lr: 1.5625e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0256 - accuracy: 0.9908 - val_loss: 0.0114 - val_accuracy: 0.9968 - lr: 7.8125e-06\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0257 - accuracy: 0.9908 - val_loss: 0.0113 - val_accuracy: 0.9970 - lr: 7.8125e-06\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0263 - accuracy: 0.9905 - val_loss: 0.0112 - val_accuracy: 0.9968 - lr: 7.8125e-06\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0252 - accuracy: 0.9908 - val_loss: 0.0112 - val_accuracy: 0.9971 - lr: 3.9063e-06\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.0271 - accuracy: 0.9902 - val_loss: 0.0112 - val_accuracy: 0.9969 - lr: 3.9063e-06\n",
      "1033/1033 [==============================] - 12s 11ms/step - loss: 0.0111 - accuracy: 0.9967\n",
      "\n",
      "── Fold 7/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 39s 36ms/step - loss: 1.1195 - accuracy: 0.6159 - val_loss: 0.7422 - val_accuracy: 0.7430 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.6343 - accuracy: 0.7801 - val_loss: 0.4593 - val_accuracy: 0.8366 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.4861 - accuracy: 0.8298 - val_loss: 0.4102 - val_accuracy: 0.8533 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.4020 - accuracy: 0.8586 - val_loss: 0.2864 - val_accuracy: 0.8970 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.3432 - accuracy: 0.8789 - val_loss: 0.2760 - val_accuracy: 0.9036 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.3100 - accuracy: 0.8892 - val_loss: 0.5078 - val_accuracy: 0.8412 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.2785 - accuracy: 0.9015 - val_loss: 0.2068 - val_accuracy: 0.9252 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.2572 - accuracy: 0.9086 - val_loss: 0.2217 - val_accuracy: 0.9206 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.2380 - accuracy: 0.9153 - val_loss: 0.1624 - val_accuracy: 0.9403 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.2225 - accuracy: 0.9203 - val_loss: 0.1591 - val_accuracy: 0.9393 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.2093 - accuracy: 0.9256 - val_loss: 0.1502 - val_accuracy: 0.9449 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.2012 - accuracy: 0.9279 - val_loss: 0.1080 - val_accuracy: 0.9595 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1905 - accuracy: 0.9313 - val_loss: 0.1162 - val_accuracy: 0.9570 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.1783 - accuracy: 0.9363 - val_loss: 0.1221 - val_accuracy: 0.9551 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.1776 - accuracy: 0.9370 - val_loss: 0.2011 - val_accuracy: 0.9335 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.1076 - accuracy: 0.9612 - val_loss: 0.0647 - val_accuracy: 0.9759 - lr: 5.0000e-04\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0967 - accuracy: 0.9641 - val_loss: 0.0567 - val_accuracy: 0.9810 - lr: 5.0000e-04\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 32s 35ms/step - loss: 0.0980 - accuracy: 0.9646 - val_loss: 0.0546 - val_accuracy: 0.9793 - lr: 5.0000e-04\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0933 - accuracy: 0.9659 - val_loss: 0.0651 - val_accuracy: 0.9765 - lr: 5.0000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0890 - accuracy: 0.9678 - val_loss: 0.0415 - val_accuracy: 0.9860 - lr: 5.0000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0858 - accuracy: 0.9694 - val_loss: 0.0619 - val_accuracy: 0.9789 - lr: 5.0000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 30s 33ms/step - loss: 0.0851 - accuracy: 0.9697 - val_loss: 0.0359 - val_accuracy: 0.9868 - lr: 5.0000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0813 - accuracy: 0.9705 - val_loss: 0.0419 - val_accuracy: 0.9849 - lr: 5.0000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0824 - accuracy: 0.9705 - val_loss: 0.0439 - val_accuracy: 0.9835 - lr: 5.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0799 - accuracy: 0.9716 - val_loss: 0.0467 - val_accuracy: 0.9846 - lr: 5.0000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0533 - accuracy: 0.9804 - val_loss: 0.0178 - val_accuracy: 0.9935 - lr: 2.5000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0511 - accuracy: 0.9814 - val_loss: 0.0178 - val_accuracy: 0.9936 - lr: 2.5000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0502 - accuracy: 0.9817 - val_loss: 0.0206 - val_accuracy: 0.9927 - lr: 2.5000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0484 - accuracy: 0.9825 - val_loss: 0.0214 - val_accuracy: 0.9925 - lr: 2.5000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0378 - accuracy: 0.9865 - val_loss: 0.0145 - val_accuracy: 0.9955 - lr: 1.2500e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0362 - accuracy: 0.9866 - val_loss: 0.0130 - val_accuracy: 0.9952 - lr: 1.2500e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0339 - accuracy: 0.9879 - val_loss: 0.0112 - val_accuracy: 0.9963 - lr: 1.2500e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 29s 32ms/step - loss: 0.0341 - accuracy: 0.9875 - val_loss: 0.0140 - val_accuracy: 0.9955 - lr: 1.2500e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0314 - accuracy: 0.9888 - val_loss: 0.0112 - val_accuracy: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0336 - accuracy: 0.9881 - val_loss: 0.0114 - val_accuracy: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0295 - accuracy: 0.9894 - val_loss: 0.0105 - val_accuracy: 0.9964 - lr: 6.2500e-05\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0277 - accuracy: 0.9899 - val_loss: 0.0099 - val_accuracy: 0.9968 - lr: 6.2500e-05\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 30s 33ms/step - loss: 0.0268 - accuracy: 0.9904 - val_loss: 0.0093 - val_accuracy: 0.9966 - lr: 6.2500e-05\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 43s 46ms/step - loss: 0.0262 - accuracy: 0.9904 - val_loss: 0.0101 - val_accuracy: 0.9963 - lr: 6.2500e-05\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0252 - accuracy: 0.9908 - val_loss: 0.0103 - val_accuracy: 0.9969 - lr: 6.2500e-05\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0256 - accuracy: 0.9911 - val_loss: 0.0099 - val_accuracy: 0.9970 - lr: 6.2500e-05\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0236 - accuracy: 0.9915 - val_loss: 0.0089 - val_accuracy: 0.9971 - lr: 3.1250e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0228 - accuracy: 0.9916 - val_loss: 0.0090 - val_accuracy: 0.9975 - lr: 3.1250e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 30s 33ms/step - loss: 0.0228 - accuracy: 0.9918 - val_loss: 0.0088 - val_accuracy: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0237 - accuracy: 0.9916 - val_loss: 0.0087 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0233 - accuracy: 0.9916 - val_loss: 0.0089 - val_accuracy: 0.9973 - lr: 3.1250e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0232 - accuracy: 0.9917 - val_loss: 0.0089 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 43s 46ms/step - loss: 0.0213 - accuracy: 0.9925 - val_loss: 0.0082 - val_accuracy: 0.9976 - lr: 1.5625e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 32s 35ms/step - loss: 0.0216 - accuracy: 0.9922 - val_loss: 0.0083 - val_accuracy: 0.9976 - lr: 1.5625e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 36s 38ms/step - loss: 0.0199 - accuracy: 0.9927 - val_loss: 0.0085 - val_accuracy: 0.9975 - lr: 1.5625e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0205 - accuracy: 0.9925 - val_loss: 0.0082 - val_accuracy: 0.9978 - lr: 1.5625e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0209 - accuracy: 0.9925 - val_loss: 0.0084 - val_accuracy: 0.9979 - lr: 7.8125e-06\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0196 - accuracy: 0.9928 - val_loss: 0.0082 - val_accuracy: 0.9977 - lr: 7.8125e-06\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0200 - accuracy: 0.9925 - val_loss: 0.0084 - val_accuracy: 0.9976 - lr: 7.8125e-06\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0211 - accuracy: 0.9925 - val_loss: 0.0081 - val_accuracy: 0.9979 - lr: 3.9063e-06\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0203 - accuracy: 0.9924 - val_loss: 0.0082 - val_accuracy: 0.9977 - lr: 3.9063e-06\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0202 - accuracy: 0.9926 - val_loss: 0.0082 - val_accuracy: 0.9979 - lr: 3.9063e-06\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0195 - accuracy: 0.9930 - val_loss: 0.0083 - val_accuracy: 0.9978 - lr: 3.9063e-06\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0192 - accuracy: 0.9929 - val_loss: 0.0081 - val_accuracy: 0.9978 - lr: 1.9531e-06\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0192 - accuracy: 0.9929 - val_loss: 0.0084 - val_accuracy: 0.9977 - lr: 1.9531e-06\n",
      "1033/1033 [==============================] - 11s 11ms/step - loss: 0.0089 - accuracy: 0.9971\n",
      "\n",
      "── Fold 8/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 38s 35ms/step - loss: 1.1132 - accuracy: 0.6175 - val_loss: 0.8874 - val_accuracy: 0.7027 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 26s 27ms/step - loss: 0.6398 - accuracy: 0.7786 - val_loss: 0.5563 - val_accuracy: 0.8013 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 26s 27ms/step - loss: 0.4853 - accuracy: 0.8291 - val_loss: 0.5858 - val_accuracy: 0.8110 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.4034 - accuracy: 0.8578 - val_loss: 0.3484 - val_accuracy: 0.8787 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.3537 - accuracy: 0.8742 - val_loss: 0.3370 - val_accuracy: 0.8837 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.3119 - accuracy: 0.8892 - val_loss: 0.2395 - val_accuracy: 0.9129 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.2847 - accuracy: 0.8979 - val_loss: 0.3331 - val_accuracy: 0.8908 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.2661 - accuracy: 0.9052 - val_loss: 0.3332 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.2489 - accuracy: 0.9107 - val_loss: 0.1830 - val_accuracy: 0.9368 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.2318 - accuracy: 0.9168 - val_loss: 0.2179 - val_accuracy: 0.9206 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.2177 - accuracy: 0.9223 - val_loss: 0.1797 - val_accuracy: 0.9369 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 26s 27ms/step - loss: 0.2044 - accuracy: 0.9272 - val_loss: 0.1559 - val_accuracy: 0.9458 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 26s 27ms/step - loss: 0.1974 - accuracy: 0.9297 - val_loss: 0.1946 - val_accuracy: 0.9340 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.1881 - accuracy: 0.9336 - val_loss: 0.1441 - val_accuracy: 0.9498 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.1770 - accuracy: 0.9368 - val_loss: 0.1360 - val_accuracy: 0.9523 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.1777 - accuracy: 0.9370 - val_loss: 0.1348 - val_accuracy: 0.9508 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.1703 - accuracy: 0.9396 - val_loss: 0.1123 - val_accuracy: 0.9619 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.1579 - accuracy: 0.9443 - val_loss: 0.1394 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.1545 - accuracy: 0.9455 - val_loss: 0.1095 - val_accuracy: 0.9619 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.1507 - accuracy: 0.9462 - val_loss: 0.0930 - val_accuracy: 0.9663 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.1498 - accuracy: 0.9471 - val_loss: 0.1170 - val_accuracy: 0.9604 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.1410 - accuracy: 0.9502 - val_loss: 0.1043 - val_accuracy: 0.9649 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.1382 - accuracy: 0.9508 - val_loss: 0.1126 - val_accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.0884 - accuracy: 0.9681 - val_loss: 0.0436 - val_accuracy: 0.9856 - lr: 5.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 26s 27ms/step - loss: 0.0798 - accuracy: 0.9711 - val_loss: 0.0434 - val_accuracy: 0.9859 - lr: 5.0000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0764 - accuracy: 0.9722 - val_loss: 0.0461 - val_accuracy: 0.9842 - lr: 5.0000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.0742 - accuracy: 0.9735 - val_loss: 0.0422 - val_accuracy: 0.9855 - lr: 5.0000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.0738 - accuracy: 0.9731 - val_loss: 0.0388 - val_accuracy: 0.9881 - lr: 5.0000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 26s 28ms/step - loss: 0.0740 - accuracy: 0.9733 - val_loss: 0.0389 - val_accuracy: 0.9866 - lr: 5.0000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0712 - accuracy: 0.9746 - val_loss: 0.0364 - val_accuracy: 0.9881 - lr: 5.0000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 26s 27ms/step - loss: 0.0683 - accuracy: 0.9755 - val_loss: 0.0617 - val_accuracy: 0.9793 - lr: 5.0000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0688 - accuracy: 0.9755 - val_loss: 0.0313 - val_accuracy: 0.9902 - lr: 5.0000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 26s 27ms/step - loss: 0.0670 - accuracy: 0.9758 - val_loss: 0.0320 - val_accuracy: 0.9890 - lr: 5.0000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 26s 27ms/step - loss: 0.0663 - accuracy: 0.9763 - val_loss: 0.0463 - val_accuracy: 0.9852 - lr: 5.0000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 26s 27ms/step - loss: 0.0653 - accuracy: 0.9765 - val_loss: 0.0343 - val_accuracy: 0.9891 - lr: 5.0000e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0461 - accuracy: 0.9834 - val_loss: 0.0221 - val_accuracy: 0.9931 - lr: 2.5000e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0410 - accuracy: 0.9852 - val_loss: 0.0226 - val_accuracy: 0.9933 - lr: 2.5000e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0411 - accuracy: 0.9852 - val_loss: 0.0196 - val_accuracy: 0.9946 - lr: 2.5000e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0413 - accuracy: 0.9850 - val_loss: 0.0193 - val_accuracy: 0.9936 - lr: 2.5000e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0393 - accuracy: 0.9859 - val_loss: 0.0194 - val_accuracy: 0.9938 - lr: 2.5000e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0400 - accuracy: 0.9855 - val_loss: 0.0224 - val_accuracy: 0.9939 - lr: 2.5000e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0381 - accuracy: 0.9861 - val_loss: 0.0179 - val_accuracy: 0.9944 - lr: 2.5000e-04\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0378 - accuracy: 0.9864 - val_loss: 0.0206 - val_accuracy: 0.9941 - lr: 2.5000e-04\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0382 - accuracy: 0.9862 - val_loss: 0.0181 - val_accuracy: 0.9955 - lr: 2.5000e-04\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0381 - accuracy: 0.9864 - val_loss: 0.0191 - val_accuracy: 0.9946 - lr: 2.5000e-04\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0289 - accuracy: 0.9895 - val_loss: 0.0138 - val_accuracy: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0287 - accuracy: 0.9897 - val_loss: 0.0141 - val_accuracy: 0.9969 - lr: 1.2500e-04\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0270 - accuracy: 0.9901 - val_loss: 0.0142 - val_accuracy: 0.9964 - lr: 1.2500e-04\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0255 - accuracy: 0.9912 - val_loss: 0.0148 - val_accuracy: 0.9964 - lr: 1.2500e-04\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0242 - accuracy: 0.9912 - val_loss: 0.0134 - val_accuracy: 0.9965 - lr: 6.2500e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0234 - accuracy: 0.9917 - val_loss: 0.0124 - val_accuracy: 0.9967 - lr: 6.2500e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0224 - accuracy: 0.9919 - val_loss: 0.0132 - val_accuracy: 0.9971 - lr: 6.2500e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0214 - accuracy: 0.9922 - val_loss: 0.0119 - val_accuracy: 0.9970 - lr: 6.2500e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0212 - accuracy: 0.9925 - val_loss: 0.0116 - val_accuracy: 0.9974 - lr: 6.2500e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0220 - accuracy: 0.9923 - val_loss: 0.0117 - val_accuracy: 0.9974 - lr: 6.2500e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0214 - accuracy: 0.9923 - val_loss: 0.0116 - val_accuracy: 0.9973 - lr: 6.2500e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0201 - accuracy: 0.9926 - val_loss: 0.0113 - val_accuracy: 0.9976 - lr: 6.2500e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0217 - accuracy: 0.9923 - val_loss: 0.0115 - val_accuracy: 0.9978 - lr: 6.2500e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0206 - accuracy: 0.9925 - val_loss: 0.0115 - val_accuracy: 0.9976 - lr: 6.2500e-05\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0211 - accuracy: 0.9924 - val_loss: 0.0120 - val_accuracy: 0.9974 - lr: 6.2500e-05\n",
      "1033/1033 [==============================] - 10s 9ms/step - loss: 0.0090 - accuracy: 0.9972\n",
      "\n",
      "── Fold 9/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 33s 30ms/step - loss: 1.1030 - accuracy: 0.6220 - val_loss: 0.7330 - val_accuracy: 0.7549 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.6240 - accuracy: 0.7832 - val_loss: 0.4630 - val_accuracy: 0.8345 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.4738 - accuracy: 0.8331 - val_loss: 0.3858 - val_accuracy: 0.8639 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.3902 - accuracy: 0.8616 - val_loss: 0.3123 - val_accuracy: 0.8946 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.3418 - accuracy: 0.8787 - val_loss: 0.2932 - val_accuracy: 0.8982 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.3036 - accuracy: 0.8919 - val_loss: 0.3005 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.2716 - accuracy: 0.9037 - val_loss: 0.2914 - val_accuracy: 0.9046 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.2513 - accuracy: 0.9109 - val_loss: 0.2533 - val_accuracy: 0.9110 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.2363 - accuracy: 0.9169 - val_loss: 0.1944 - val_accuracy: 0.9315 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.2240 - accuracy: 0.9202 - val_loss: 0.2725 - val_accuracy: 0.9068 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.2109 - accuracy: 0.9252 - val_loss: 0.1691 - val_accuracy: 0.9389 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.1982 - accuracy: 0.9293 - val_loss: 0.1414 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.1911 - accuracy: 0.9328 - val_loss: 0.1349 - val_accuracy: 0.9536 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.1833 - accuracy: 0.9348 - val_loss: 0.1271 - val_accuracy: 0.9569 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.1761 - accuracy: 0.9383 - val_loss: 0.1734 - val_accuracy: 0.9387 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.1675 - accuracy: 0.9400 - val_loss: 0.1471 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.1606 - accuracy: 0.9429 - val_loss: 0.1362 - val_accuracy: 0.9516 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.1015 - accuracy: 0.9632 - val_loss: 0.0467 - val_accuracy: 0.9824 - lr: 5.0000e-04\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0914 - accuracy: 0.9669 - val_loss: 0.0499 - val_accuracy: 0.9818 - lr: 5.0000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0902 - accuracy: 0.9675 - val_loss: 0.0497 - val_accuracy: 0.9810 - lr: 5.0000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.0874 - accuracy: 0.9679 - val_loss: 0.0367 - val_accuracy: 0.9867 - lr: 5.0000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.0829 - accuracy: 0.9698 - val_loss: 0.0414 - val_accuracy: 0.9843 - lr: 5.0000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0822 - accuracy: 0.9701 - val_loss: 0.0462 - val_accuracy: 0.9827 - lr: 5.0000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0809 - accuracy: 0.9711 - val_loss: 0.0375 - val_accuracy: 0.9862 - lr: 5.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.0568 - accuracy: 0.9795 - val_loss: 0.0210 - val_accuracy: 0.9929 - lr: 2.5000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0537 - accuracy: 0.9804 - val_loss: 0.0210 - val_accuracy: 0.9931 - lr: 2.5000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 26s 28ms/step - loss: 0.0511 - accuracy: 0.9812 - val_loss: 0.0214 - val_accuracy: 0.9927 - lr: 2.5000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 26s 27ms/step - loss: 0.0490 - accuracy: 0.9819 - val_loss: 0.0167 - val_accuracy: 0.9946 - lr: 2.5000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0518 - accuracy: 0.9817 - val_loss: 0.0354 - val_accuracy: 0.9882 - lr: 2.5000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 27s 29ms/step - loss: 0.0466 - accuracy: 0.9827 - val_loss: 0.0221 - val_accuracy: 0.9928 - lr: 2.5000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 26s 28ms/step - loss: 0.0469 - accuracy: 0.9831 - val_loss: 0.0234 - val_accuracy: 0.9929 - lr: 2.5000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0363 - accuracy: 0.9869 - val_loss: 0.0139 - val_accuracy: 0.9953 - lr: 1.2500e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 27s 28ms/step - loss: 0.0341 - accuracy: 0.9876 - val_loss: 0.0142 - val_accuracy: 0.9948 - lr: 1.2500e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 26s 27ms/step - loss: 0.0341 - accuracy: 0.9876 - val_loss: 0.0142 - val_accuracy: 0.9949 - lr: 1.2500e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 26s 28ms/step - loss: 0.0342 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9958 - lr: 1.2500e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0326 - accuracy: 0.9883 - val_loss: 0.0132 - val_accuracy: 0.9956 - lr: 1.2500e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0317 - accuracy: 0.9886 - val_loss: 0.0119 - val_accuracy: 0.9963 - lr: 1.2500e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0318 - accuracy: 0.9880 - val_loss: 0.0115 - val_accuracy: 0.9964 - lr: 1.2500e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0311 - accuracy: 0.9882 - val_loss: 0.0121 - val_accuracy: 0.9960 - lr: 1.2500e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.0322 - accuracy: 0.9885 - val_loss: 0.0104 - val_accuracy: 0.9969 - lr: 1.2500e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.0306 - accuracy: 0.9890 - val_loss: 0.0099 - val_accuracy: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.0312 - accuracy: 0.9888 - val_loss: 0.0111 - val_accuracy: 0.9963 - lr: 1.2500e-04\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0288 - accuracy: 0.9896 - val_loss: 0.0108 - val_accuracy: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0302 - accuracy: 0.9885 - val_loss: 0.0115 - val_accuracy: 0.9958 - lr: 1.2500e-04\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0268 - accuracy: 0.9903 - val_loss: 0.0098 - val_accuracy: 0.9967 - lr: 6.2500e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0253 - accuracy: 0.9910 - val_loss: 0.0094 - val_accuracy: 0.9972 - lr: 6.2500e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0249 - accuracy: 0.9910 - val_loss: 0.0089 - val_accuracy: 0.9973 - lr: 6.2500e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0248 - accuracy: 0.9911 - val_loss: 0.0086 - val_accuracy: 0.9978 - lr: 6.2500e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0234 - accuracy: 0.9915 - val_loss: 0.0092 - val_accuracy: 0.9971 - lr: 6.2500e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0231 - accuracy: 0.9915 - val_loss: 0.0097 - val_accuracy: 0.9963 - lr: 6.2500e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 23s 24ms/step - loss: 0.0233 - accuracy: 0.9913 - val_loss: 0.0079 - val_accuracy: 0.9977 - lr: 6.2500e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0245 - accuracy: 0.9912 - val_loss: 0.0078 - val_accuracy: 0.9978 - lr: 6.2500e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0234 - accuracy: 0.9917 - val_loss: 0.0074 - val_accuracy: 0.9975 - lr: 6.2500e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.0232 - accuracy: 0.9918 - val_loss: 0.0080 - val_accuracy: 0.9977 - lr: 6.2500e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0238 - accuracy: 0.9916 - val_loss: 0.0088 - val_accuracy: 0.9972 - lr: 6.2500e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0223 - accuracy: 0.9920 - val_loss: 0.0073 - val_accuracy: 0.9980 - lr: 6.2500e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 0.0073 - val_accuracy: 0.9976 - lr: 3.1250e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0204 - accuracy: 0.9925 - val_loss: 0.0070 - val_accuracy: 0.9980 - lr: 3.1250e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0206 - accuracy: 0.9924 - val_loss: 0.0067 - val_accuracy: 0.9980 - lr: 3.1250e-05\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.0199 - accuracy: 0.9927 - val_loss: 0.0073 - val_accuracy: 0.9977 - lr: 3.1250e-05\n",
      "1033/1033 [==============================] - 10s 9ms/step - loss: 0.0069 - accuracy: 0.9976\n",
      "\n",
      "── Fold 10/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 30s 27ms/step - loss: 1.1070 - accuracy: 0.6207 - val_loss: 0.8349 - val_accuracy: 0.7171 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.6296 - accuracy: 0.7819 - val_loss: 0.6039 - val_accuracy: 0.7972 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.4788 - accuracy: 0.8317 - val_loss: 0.3645 - val_accuracy: 0.8703 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.3955 - accuracy: 0.8602 - val_loss: 0.5096 - val_accuracy: 0.8312 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.3415 - accuracy: 0.8792 - val_loss: 0.3426 - val_accuracy: 0.8821 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.3070 - accuracy: 0.8920 - val_loss: 0.2259 - val_accuracy: 0.9178 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.2776 - accuracy: 0.9021 - val_loss: 0.5141 - val_accuracy: 0.8483 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.2542 - accuracy: 0.9096 - val_loss: 0.3091 - val_accuracy: 0.8997 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.2418 - accuracy: 0.9143 - val_loss: 0.2373 - val_accuracy: 0.9197 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.1494 - accuracy: 0.9460 - val_loss: 0.0942 - val_accuracy: 0.9645 - lr: 5.0000e-04\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.1356 - accuracy: 0.9511 - val_loss: 0.0833 - val_accuracy: 0.9711 - lr: 5.0000e-04\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.1263 - accuracy: 0.9544 - val_loss: 0.0881 - val_accuracy: 0.9676 - lr: 5.0000e-04\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.1220 - accuracy: 0.9558 - val_loss: 0.0603 - val_accuracy: 0.9777 - lr: 5.0000e-04\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.1181 - accuracy: 0.9565 - val_loss: 0.0641 - val_accuracy: 0.9762 - lr: 5.0000e-04\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.1136 - accuracy: 0.9588 - val_loss: 0.0662 - val_accuracy: 0.9755 - lr: 5.0000e-04\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 22s 24ms/step - loss: 0.1092 - accuracy: 0.9615 - val_loss: 0.0840 - val_accuracy: 0.9706 - lr: 5.0000e-04\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0755 - accuracy: 0.9725 - val_loss: 0.0414 - val_accuracy: 0.9849 - lr: 2.5000e-04\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0675 - accuracy: 0.9747 - val_loss: 0.0390 - val_accuracy: 0.9867 - lr: 2.5000e-04\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0692 - accuracy: 0.9748 - val_loss: 0.0324 - val_accuracy: 0.9880 - lr: 2.5000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0650 - accuracy: 0.9764 - val_loss: 0.0308 - val_accuracy: 0.9899 - lr: 2.5000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0641 - accuracy: 0.9766 - val_loss: 0.0319 - val_accuracy: 0.9889 - lr: 2.5000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0602 - accuracy: 0.9781 - val_loss: 0.0347 - val_accuracy: 0.9883 - lr: 2.5000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0619 - accuracy: 0.9777 - val_loss: 0.0294 - val_accuracy: 0.9904 - lr: 2.5000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0588 - accuracy: 0.9787 - val_loss: 0.0324 - val_accuracy: 0.9883 - lr: 2.5000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0587 - accuracy: 0.9785 - val_loss: 0.0308 - val_accuracy: 0.9894 - lr: 2.5000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0567 - accuracy: 0.9792 - val_loss: 0.0296 - val_accuracy: 0.9891 - lr: 2.5000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0433 - accuracy: 0.9838 - val_loss: 0.0164 - val_accuracy: 0.9951 - lr: 1.2500e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0412 - accuracy: 0.9856 - val_loss: 0.0179 - val_accuracy: 0.9943 - lr: 1.2500e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0394 - accuracy: 0.9857 - val_loss: 0.0181 - val_accuracy: 0.9943 - lr: 1.2500e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0399 - accuracy: 0.9856 - val_loss: 0.0167 - val_accuracy: 0.9936 - lr: 1.2500e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0336 - accuracy: 0.9878 - val_loss: 0.0131 - val_accuracy: 0.9957 - lr: 6.2500e-05\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0327 - accuracy: 0.9883 - val_loss: 0.0135 - val_accuracy: 0.9955 - lr: 6.2500e-05\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0316 - accuracy: 0.9883 - val_loss: 0.0130 - val_accuracy: 0.9958 - lr: 6.2500e-05\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0303 - accuracy: 0.9893 - val_loss: 0.0128 - val_accuracy: 0.9961 - lr: 6.2500e-05\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0314 - accuracy: 0.9888 - val_loss: 0.0129 - val_accuracy: 0.9964 - lr: 6.2500e-05\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0294 - accuracy: 0.9895 - val_loss: 0.0132 - val_accuracy: 0.9956 - lr: 6.2500e-05\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0298 - accuracy: 0.9891 - val_loss: 0.0126 - val_accuracy: 0.9958 - lr: 6.2500e-05\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0279 - accuracy: 0.9899 - val_loss: 0.0124 - val_accuracy: 0.9963 - lr: 6.2500e-05\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0289 - accuracy: 0.9896 - val_loss: 0.0130 - val_accuracy: 0.9959 - lr: 6.2500e-05\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0290 - accuracy: 0.9897 - val_loss: 0.0135 - val_accuracy: 0.9958 - lr: 6.2500e-05\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 26s 27ms/step - loss: 0.0291 - accuracy: 0.9896 - val_loss: 0.0121 - val_accuracy: 0.9960 - lr: 6.2500e-05\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.0272 - accuracy: 0.9900 - val_loss: 0.0141 - val_accuracy: 0.9958 - lr: 6.2500e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 25s 27ms/step - loss: 0.0271 - accuracy: 0.9903 - val_loss: 0.0132 - val_accuracy: 0.9965 - lr: 6.2500e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0266 - accuracy: 0.9906 - val_loss: 0.0122 - val_accuracy: 0.9961 - lr: 6.2500e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0254 - accuracy: 0.9910 - val_loss: 0.0119 - val_accuracy: 0.9968 - lr: 3.1250e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 25s 26ms/step - loss: 0.0241 - accuracy: 0.9911 - val_loss: 0.0110 - val_accuracy: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0244 - accuracy: 0.9913 - val_loss: 0.0110 - val_accuracy: 0.9971 - lr: 3.1250e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0238 - accuracy: 0.9911 - val_loss: 0.0105 - val_accuracy: 0.9967 - lr: 3.1250e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0233 - accuracy: 0.9917 - val_loss: 0.0107 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0243 - accuracy: 0.9913 - val_loss: 0.0109 - val_accuracy: 0.9973 - lr: 3.1250e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0223 - accuracy: 0.9919 - val_loss: 0.0119 - val_accuracy: 0.9969 - lr: 3.1250e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0239 - accuracy: 0.9916 - val_loss: 0.0110 - val_accuracy: 0.9973 - lr: 1.5625e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0227 - accuracy: 0.9917 - val_loss: 0.0111 - val_accuracy: 0.9969 - lr: 1.5625e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0223 - accuracy: 0.9918 - val_loss: 0.0104 - val_accuracy: 0.9973 - lr: 1.5625e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0197 - accuracy: 0.9929 - val_loss: 0.0105 - val_accuracy: 0.9970 - lr: 7.8125e-06\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0209 - accuracy: 0.9926 - val_loss: 0.0108 - val_accuracy: 0.9971 - lr: 7.8125e-06\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 23s 25ms/step - loss: 0.0211 - accuracy: 0.9925 - val_loss: 0.0107 - val_accuracy: 0.9969 - lr: 7.8125e-06\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0199 - accuracy: 0.9927 - val_loss: 0.0106 - val_accuracy: 0.9970 - lr: 3.9063e-06\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 24s 26ms/step - loss: 0.0204 - accuracy: 0.9927 - val_loss: 0.0106 - val_accuracy: 0.9970 - lr: 3.9063e-06\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 24s 25ms/step - loss: 0.0222 - accuracy: 0.9919 - val_loss: 0.0106 - val_accuracy: 0.9970 - lr: 3.9063e-06\n",
      "1033/1033 [==============================] - 10s 9ms/step - loss: 0.0090 - accuracy: 0.9971\n",
      "\n",
      "################ HyT-Net_Propuesto – 10-fold CV ################\n",
      "\n",
      "── Fold 1/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 32s 32ms/step - loss: 1.7042 - accuracy: 0.4165 - val_loss: 1.1532 - val_accuracy: 0.6001 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 1.0176 - accuracy: 0.6534 - val_loss: 0.6947 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.6919 - accuracy: 0.7666 - val_loss: 0.6244 - val_accuracy: 0.7879 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.5151 - accuracy: 0.8248 - val_loss: 0.3861 - val_accuracy: 0.8682 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.4150 - accuracy: 0.8592 - val_loss: 0.3894 - val_accuracy: 0.8620 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.3454 - accuracy: 0.8821 - val_loss: 0.2360 - val_accuracy: 0.9182 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.2973 - accuracy: 0.8998 - val_loss: 0.2725 - val_accuracy: 0.9096 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.2601 - accuracy: 0.9115 - val_loss: 0.5233 - val_accuracy: 0.8575 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.2344 - accuracy: 0.9206 - val_loss: 0.1677 - val_accuracy: 0.9415 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.2106 - accuracy: 0.9277 - val_loss: 0.1529 - val_accuracy: 0.9457 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1919 - accuracy: 0.9351 - val_loss: 0.1871 - val_accuracy: 0.9356 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.1785 - accuracy: 0.9384 - val_loss: 0.3092 - val_accuracy: 0.8964 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1676 - accuracy: 0.9428 - val_loss: 0.1969 - val_accuracy: 0.9350 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0906 - accuracy: 0.9686 - val_loss: 0.0586 - val_accuracy: 0.9802 - lr: 5.0000e-04\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0832 - accuracy: 0.9716 - val_loss: 0.0824 - val_accuracy: 0.9740 - lr: 5.0000e-04\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0782 - accuracy: 0.9730 - val_loss: 0.0513 - val_accuracy: 0.9800 - lr: 5.0000e-04\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0768 - accuracy: 0.9736 - val_loss: 0.0565 - val_accuracy: 0.9805 - lr: 5.0000e-04\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0720 - accuracy: 0.9747 - val_loss: 0.0557 - val_accuracy: 0.9813 - lr: 5.0000e-04\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0699 - accuracy: 0.9763 - val_loss: 0.0459 - val_accuracy: 0.9841 - lr: 5.0000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0660 - accuracy: 0.9777 - val_loss: 0.0408 - val_accuracy: 0.9865 - lr: 5.0000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0678 - accuracy: 0.9766 - val_loss: 0.0385 - val_accuracy: 0.9865 - lr: 5.0000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0607 - accuracy: 0.9791 - val_loss: 0.0483 - val_accuracy: 0.9826 - lr: 5.0000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0642 - accuracy: 0.9782 - val_loss: 0.0510 - val_accuracy: 0.9835 - lr: 5.0000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0575 - accuracy: 0.9807 - val_loss: 0.0369 - val_accuracy: 0.9868 - lr: 5.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0575 - accuracy: 0.9803 - val_loss: 0.0536 - val_accuracy: 0.9816 - lr: 5.0000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0585 - accuracy: 0.9804 - val_loss: 0.0338 - val_accuracy: 0.9886 - lr: 5.0000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0539 - accuracy: 0.9818 - val_loss: 0.0415 - val_accuracy: 0.9860 - lr: 5.0000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0563 - accuracy: 0.9812 - val_loss: 0.0303 - val_accuracy: 0.9908 - lr: 5.0000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0530 - accuracy: 0.9822 - val_loss: 0.0362 - val_accuracy: 0.9883 - lr: 5.0000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0523 - accuracy: 0.9824 - val_loss: 0.0406 - val_accuracy: 0.9877 - lr: 5.0000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0504 - accuracy: 0.9826 - val_loss: 0.0439 - val_accuracy: 0.9870 - lr: 5.0000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0271 - accuracy: 0.9910 - val_loss: 0.0172 - val_accuracy: 0.9943 - lr: 2.5000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0239 - accuracy: 0.9918 - val_loss: 0.0188 - val_accuracy: 0.9944 - lr: 2.5000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 0.0192 - val_accuracy: 0.9936 - lr: 2.5000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 29s 30ms/step - loss: 0.0227 - accuracy: 0.9923 - val_loss: 0.0229 - val_accuracy: 0.9936 - lr: 2.5000e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0156 - accuracy: 0.9946 - val_loss: 0.0139 - val_accuracy: 0.9958 - lr: 1.2500e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.0137 - val_accuracy: 0.9964 - lr: 1.2500e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0123 - val_accuracy: 0.9970 - lr: 1.2500e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.0125 - val_accuracy: 0.9965 - lr: 1.2500e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.0142 - val_accuracy: 0.9966 - lr: 1.2500e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.0125 - val_accuracy: 0.9968 - lr: 1.2500e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.0100 - val_accuracy: 0.9976 - lr: 6.2500e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.0105 - val_accuracy: 0.9977 - lr: 6.2500e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0109 - val_accuracy: 0.9973 - lr: 6.2500e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.0120 - val_accuracy: 0.9974 - lr: 6.2500e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0101 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0096 - val_accuracy: 0.9977 - lr: 3.1250e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0097 - val_accuracy: 0.9977 - lr: 3.1250e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0095 - val_accuracy: 0.9981 - lr: 3.1250e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.0099 - val_accuracy: 0.9978 - lr: 3.1250e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0097 - val_accuracy: 0.9978 - lr: 1.5625e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0094 - val_accuracy: 0.9979 - lr: 1.5625e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 29s 30ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0090 - val_accuracy: 0.9978 - lr: 1.5625e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0091 - val_accuracy: 0.9981 - lr: 1.5625e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.0088 - val_accuracy: 0.9981 - lr: 1.5625e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0084 - val_accuracy: 0.9981 - lr: 1.5625e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0085 - val_accuracy: 0.9981 - lr: 1.5625e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0086 - val_accuracy: 0.9981 - lr: 1.5625e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0086 - val_accuracy: 0.9980 - lr: 1.5625e-05\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0087 - val_accuracy: 0.9980 - lr: 7.8125e-06\n",
      "1033/1033 [==============================] - 8s 8ms/step - loss: 0.0232 - accuracy: 0.9976\n",
      "\n",
      "── Fold 2/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 31s 31ms/step - loss: 1.7252 - accuracy: 0.4092 - val_loss: 1.1938 - val_accuracy: 0.5990 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 1.0606 - accuracy: 0.6386 - val_loss: 0.8937 - val_accuracy: 0.7020 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.7191 - accuracy: 0.7571 - val_loss: 0.4713 - val_accuracy: 0.8365 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.5367 - accuracy: 0.8193 - val_loss: 0.4584 - val_accuracy: 0.8438 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.4266 - accuracy: 0.8554 - val_loss: 0.4570 - val_accuracy: 0.8444 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.3551 - accuracy: 0.8801 - val_loss: 0.3268 - val_accuracy: 0.8918 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.3054 - accuracy: 0.8959 - val_loss: 0.2246 - val_accuracy: 0.9221 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.2684 - accuracy: 0.9093 - val_loss: 0.1782 - val_accuracy: 0.9386 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.2414 - accuracy: 0.9177 - val_loss: 0.3410 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.2206 - accuracy: 0.9248 - val_loss: 0.1592 - val_accuracy: 0.9437 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.2023 - accuracy: 0.9316 - val_loss: 0.2462 - val_accuracy: 0.9256 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1888 - accuracy: 0.9364 - val_loss: 0.1313 - val_accuracy: 0.9531 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1760 - accuracy: 0.9404 - val_loss: 0.1268 - val_accuracy: 0.9554 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1671 - accuracy: 0.9441 - val_loss: 0.1131 - val_accuracy: 0.9597 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1589 - accuracy: 0.9463 - val_loss: 0.1101 - val_accuracy: 0.9596 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.1482 - accuracy: 0.9499 - val_loss: 0.1535 - val_accuracy: 0.9534 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1394 - accuracy: 0.9529 - val_loss: 0.1414 - val_accuracy: 0.9559 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1342 - accuracy: 0.9552 - val_loss: 0.0998 - val_accuracy: 0.9654 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1328 - accuracy: 0.9553 - val_loss: 0.1090 - val_accuracy: 0.9638 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1248 - accuracy: 0.9589 - val_loss: 0.0787 - val_accuracy: 0.9725 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1198 - accuracy: 0.9601 - val_loss: 0.0952 - val_accuracy: 0.9666 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1184 - accuracy: 0.9604 - val_loss: 0.0814 - val_accuracy: 0.9709 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1127 - accuracy: 0.9629 - val_loss: 0.0927 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0551 - accuracy: 0.9814 - val_loss: 0.0424 - val_accuracy: 0.9858 - lr: 5.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0511 - accuracy: 0.9821 - val_loss: 0.0381 - val_accuracy: 0.9870 - lr: 5.0000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 29s 30ms/step - loss: 0.0533 - accuracy: 0.9814 - val_loss: 0.0393 - val_accuracy: 0.9874 - lr: 5.0000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0497 - accuracy: 0.9833 - val_loss: 0.0316 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0492 - accuracy: 0.9834 - val_loss: 0.0331 - val_accuracy: 0.9882 - lr: 5.0000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 28s 30ms/step - loss: 0.0459 - accuracy: 0.9843 - val_loss: 0.0327 - val_accuracy: 0.9886 - lr: 5.0000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0455 - accuracy: 0.9845 - val_loss: 0.0315 - val_accuracy: 0.9898 - lr: 5.0000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0257 - accuracy: 0.9910 - val_loss: 0.0196 - val_accuracy: 0.9936 - lr: 2.5000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0220 - accuracy: 0.9922 - val_loss: 0.0227 - val_accuracy: 0.9927 - lr: 2.5000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0234 - accuracy: 0.9920 - val_loss: 0.0226 - val_accuracy: 0.9934 - lr: 2.5000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0213 - accuracy: 0.9928 - val_loss: 0.0194 - val_accuracy: 0.9948 - lr: 2.5000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 0.0226 - val_accuracy: 0.9930 - lr: 2.5000e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 29s 30ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 0.0210 - val_accuracy: 0.9930 - lr: 2.5000e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0216 - accuracy: 0.9927 - val_loss: 0.0182 - val_accuracy: 0.9942 - lr: 2.5000e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0197 - accuracy: 0.9934 - val_loss: 0.0182 - val_accuracy: 0.9944 - lr: 2.5000e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0199 - accuracy: 0.9932 - val_loss: 0.0158 - val_accuracy: 0.9954 - lr: 2.5000e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0181 - accuracy: 0.9938 - val_loss: 0.0175 - val_accuracy: 0.9952 - lr: 2.5000e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0193 - accuracy: 0.9935 - val_loss: 0.0199 - val_accuracy: 0.9946 - lr: 2.5000e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0203 - accuracy: 0.9931 - val_loss: 0.0202 - val_accuracy: 0.9943 - lr: 2.5000e-04\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.0151 - val_accuracy: 0.9959 - lr: 1.2500e-04\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.0165 - val_accuracy: 0.9957 - lr: 1.2500e-04\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.0169 - val_accuracy: 0.9955 - lr: 1.2500e-04\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0143 - val_accuracy: 0.9961 - lr: 1.2500e-04\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.0131 - val_accuracy: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.0130 - val_accuracy: 0.9968 - lr: 1.2500e-04\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.0138 - val_accuracy: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.0147 - val_accuracy: 0.9963 - lr: 1.2500e-04\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0151 - val_accuracy: 0.9957 - lr: 1.2500e-04\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.0143 - val_accuracy: 0.9972 - lr: 6.2500e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0135 - val_accuracy: 0.9971 - lr: 6.2500e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0126 - val_accuracy: 0.9978 - lr: 6.2500e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.0125 - val_accuracy: 0.9973 - lr: 6.2500e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0115 - val_accuracy: 0.9974 - lr: 6.2500e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: 0.0118 - val_accuracy: 0.9974 - lr: 6.2500e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0118 - val_accuracy: 0.9971 - lr: 6.2500e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0121 - val_accuracy: 0.9973 - lr: 6.2500e-05\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0111 - val_accuracy: 0.9975 - lr: 3.1250e-05\n",
      "1033/1033 [==============================] - 8s 8ms/step - loss: 0.0297 - accuracy: 0.9975\n",
      "\n",
      "── Fold 3/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 33s 32ms/step - loss: 1.7146 - accuracy: 0.4122 - val_loss: 1.1040 - val_accuracy: 0.6239 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 1.0386 - accuracy: 0.6444 - val_loss: 0.7259 - val_accuracy: 0.7550 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.7138 - accuracy: 0.7572 - val_loss: 0.5868 - val_accuracy: 0.8015 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.5412 - accuracy: 0.8162 - val_loss: 0.3840 - val_accuracy: 0.8649 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.4348 - accuracy: 0.8532 - val_loss: 0.2824 - val_accuracy: 0.8996 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.3643 - accuracy: 0.8761 - val_loss: 0.2693 - val_accuracy: 0.9054 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.3082 - accuracy: 0.8948 - val_loss: 0.2262 - val_accuracy: 0.9198 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.2711 - accuracy: 0.9066 - val_loss: 0.2462 - val_accuracy: 0.9154 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.2422 - accuracy: 0.9174 - val_loss: 0.1842 - val_accuracy: 0.9334 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.2222 - accuracy: 0.9242 - val_loss: 0.1866 - val_accuracy: 0.9359 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.2025 - accuracy: 0.9308 - val_loss: 0.1821 - val_accuracy: 0.9344 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1845 - accuracy: 0.9373 - val_loss: 0.1301 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.1746 - accuracy: 0.9405 - val_loss: 0.1335 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1646 - accuracy: 0.9439 - val_loss: 0.1326 - val_accuracy: 0.9559 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1592 - accuracy: 0.9457 - val_loss: 0.1288 - val_accuracy: 0.9545 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.1516 - accuracy: 0.9486 - val_loss: 0.1112 - val_accuracy: 0.9623 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1400 - accuracy: 0.9529 - val_loss: 0.1144 - val_accuracy: 0.9604 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1367 - accuracy: 0.9543 - val_loss: 0.0868 - val_accuracy: 0.9697 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1306 - accuracy: 0.9557 - val_loss: 0.1005 - val_accuracy: 0.9673 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1265 - accuracy: 0.9572 - val_loss: 0.0795 - val_accuracy: 0.9727 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1191 - accuracy: 0.9591 - val_loss: 0.0936 - val_accuracy: 0.9704 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1177 - accuracy: 0.9599 - val_loss: 0.0827 - val_accuracy: 0.9716 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1093 - accuracy: 0.9632 - val_loss: 0.0852 - val_accuracy: 0.9722 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0575 - accuracy: 0.9805 - val_loss: 0.0414 - val_accuracy: 0.9886 - lr: 5.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0516 - accuracy: 0.9824 - val_loss: 0.0418 - val_accuracy: 0.9872 - lr: 5.0000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0514 - accuracy: 0.9824 - val_loss: 0.0490 - val_accuracy: 0.9843 - lr: 5.0000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0496 - accuracy: 0.9832 - val_loss: 0.0541 - val_accuracy: 0.9833 - lr: 5.0000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 29s 30ms/step - loss: 0.0282 - accuracy: 0.9899 - val_loss: 0.0267 - val_accuracy: 0.9913 - lr: 2.5000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0257 - accuracy: 0.9909 - val_loss: 0.0215 - val_accuracy: 0.9930 - lr: 2.5000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0248 - accuracy: 0.9913 - val_loss: 0.0272 - val_accuracy: 0.9919 - lr: 2.5000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0245 - accuracy: 0.9916 - val_loss: 0.0185 - val_accuracy: 0.9949 - lr: 2.5000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0241 - accuracy: 0.9919 - val_loss: 0.0226 - val_accuracy: 0.9936 - lr: 2.5000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0227 - accuracy: 0.9924 - val_loss: 0.0259 - val_accuracy: 0.9919 - lr: 2.5000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0224 - accuracy: 0.9923 - val_loss: 0.0225 - val_accuracy: 0.9933 - lr: 2.5000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0147 - accuracy: 0.9949 - val_loss: 0.0153 - val_accuracy: 0.9963 - lr: 1.2500e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.0170 - val_accuracy: 0.9952 - lr: 1.2500e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.0146 - val_accuracy: 0.9960 - lr: 1.2500e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.0141 - val_accuracy: 0.9961 - lr: 1.2500e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.0167 - val_accuracy: 0.9955 - lr: 1.2500e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0115 - accuracy: 0.9958 - val_loss: 0.0174 - val_accuracy: 0.9948 - lr: 1.2500e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.0166 - val_accuracy: 0.9956 - lr: 1.2500e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.0134 - val_accuracy: 0.9963 - lr: 6.2500e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.0138 - val_accuracy: 0.9961 - lr: 6.2500e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.0134 - val_accuracy: 0.9969 - lr: 6.2500e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.0154 - val_accuracy: 0.9966 - lr: 6.2500e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0063 - accuracy: 0.9977 - val_loss: 0.0133 - val_accuracy: 0.9971 - lr: 3.1250e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0131 - val_accuracy: 0.9971 - lr: 3.1250e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0130 - val_accuracy: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0125 - val_accuracy: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0125 - val_accuracy: 0.9971 - lr: 3.1250e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.0122 - val_accuracy: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.0126 - val_accuracy: 0.9972 - lr: 3.1250e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0126 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 30s 31ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0125 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0116 - val_accuracy: 0.9976 - lr: 1.5625e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0118 - val_accuracy: 0.9974 - lr: 1.5625e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 30s 33ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0120 - val_accuracy: 0.9975 - lr: 1.5625e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0124 - val_accuracy: 0.9975 - lr: 1.5625e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 30s 33ms/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 0.0124 - val_accuracy: 0.9977 - lr: 7.8125e-06\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.0124 - val_accuracy: 0.9975 - lr: 7.8125e-06\n",
      "1033/1033 [==============================] - 9s 9ms/step - loss: 0.0351 - accuracy: 0.9977\n",
      "\n",
      "── Fold 4/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 32s 32ms/step - loss: 1.6972 - accuracy: 0.4192 - val_loss: 1.2596 - val_accuracy: 0.5664 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 30s 33ms/step - loss: 1.0329 - accuracy: 0.6466 - val_loss: 0.8235 - val_accuracy: 0.7234 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.7146 - accuracy: 0.7580 - val_loss: 0.5071 - val_accuracy: 0.8192 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.5370 - accuracy: 0.8184 - val_loss: 0.3789 - val_accuracy: 0.8678 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.4296 - accuracy: 0.8537 - val_loss: 0.3594 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.3566 - accuracy: 0.8782 - val_loss: 0.3035 - val_accuracy: 0.8941 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.3060 - accuracy: 0.8965 - val_loss: 0.2409 - val_accuracy: 0.9120 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.2677 - accuracy: 0.9088 - val_loss: 0.2211 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.2350 - accuracy: 0.9193 - val_loss: 0.1965 - val_accuracy: 0.9312 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.2179 - accuracy: 0.9262 - val_loss: 0.1590 - val_accuracy: 0.9440 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1955 - accuracy: 0.9333 - val_loss: 0.3281 - val_accuracy: 0.9092 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.1835 - accuracy: 0.9380 - val_loss: 0.1553 - val_accuracy: 0.9452 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.1750 - accuracy: 0.9410 - val_loss: 0.1242 - val_accuracy: 0.9554 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1633 - accuracy: 0.9447 - val_loss: 0.1348 - val_accuracy: 0.9538 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1510 - accuracy: 0.9482 - val_loss: 0.1216 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1469 - accuracy: 0.9507 - val_loss: 0.1347 - val_accuracy: 0.9551 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1377 - accuracy: 0.9540 - val_loss: 0.1220 - val_accuracy: 0.9607 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1325 - accuracy: 0.9554 - val_loss: 0.1343 - val_accuracy: 0.9544 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0697 - accuracy: 0.9759 - val_loss: 0.0427 - val_accuracy: 0.9865 - lr: 5.0000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0621 - accuracy: 0.9785 - val_loss: 0.0990 - val_accuracy: 0.9685 - lr: 5.0000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0595 - accuracy: 0.9796 - val_loss: 0.0523 - val_accuracy: 0.9828 - lr: 5.0000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0584 - accuracy: 0.9802 - val_loss: 0.0686 - val_accuracy: 0.9774 - lr: 5.0000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0348 - accuracy: 0.9877 - val_loss: 0.0245 - val_accuracy: 0.9926 - lr: 2.5000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0297 - accuracy: 0.9898 - val_loss: 0.0345 - val_accuracy: 0.9890 - lr: 2.5000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0292 - accuracy: 0.9897 - val_loss: 0.0261 - val_accuracy: 0.9924 - lr: 2.5000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0276 - accuracy: 0.9903 - val_loss: 0.0370 - val_accuracy: 0.9894 - lr: 2.5000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0198 - accuracy: 0.9932 - val_loss: 0.0211 - val_accuracy: 0.9936 - lr: 1.2500e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0170 - accuracy: 0.9941 - val_loss: 0.0197 - val_accuracy: 0.9946 - lr: 1.2500e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 0.0231 - val_accuracy: 0.9940 - lr: 1.2500e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 0.0212 - val_accuracy: 0.9945 - lr: 1.2500e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.0212 - val_accuracy: 0.9941 - lr: 1.2500e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.0182 - val_accuracy: 0.9955 - lr: 6.2500e-05\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0106 - accuracy: 0.9961 - val_loss: 0.0191 - val_accuracy: 0.9950 - lr: 6.2500e-05\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: 0.0197 - val_accuracy: 0.9949 - lr: 6.2500e-05\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.0183 - val_accuracy: 0.9964 - lr: 6.2500e-05\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.0185 - val_accuracy: 0.9960 - lr: 3.1250e-05\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0089 - accuracy: 0.9968 - val_loss: 0.0175 - val_accuracy: 0.9962 - lr: 3.1250e-05\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.0176 - val_accuracy: 0.9962 - lr: 3.1250e-05\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.0171 - val_accuracy: 0.9961 - lr: 3.1250e-05\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.0166 - val_accuracy: 0.9962 - lr: 3.1250e-05\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.0182 - val_accuracy: 0.9955 - lr: 3.1250e-05\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 0.0171 - val_accuracy: 0.9959 - lr: 3.1250e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.0163 - val_accuracy: 0.9959 - lr: 3.1250e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0174 - val_accuracy: 0.9963 - lr: 3.1250e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.0165 - val_accuracy: 0.9964 - lr: 3.1250e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0175 - val_accuracy: 0.9961 - lr: 3.1250e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0160 - val_accuracy: 0.9965 - lr: 1.5625e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.0165 - val_accuracy: 0.9966 - lr: 1.5625e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0164 - val_accuracy: 0.9964 - lr: 1.5625e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.0165 - val_accuracy: 0.9967 - lr: 1.5625e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0163 - val_accuracy: 0.9965 - lr: 7.8125e-06\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0164 - val_accuracy: 0.9964 - lr: 7.8125e-06\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0163 - val_accuracy: 0.9964 - lr: 7.8125e-06\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0162 - val_accuracy: 0.9964 - lr: 3.9063e-06\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0162 - val_accuracy: 0.9965 - lr: 3.9063e-06\n",
      "1033/1033 [==============================] - 10s 10ms/step - loss: 0.0368 - accuracy: 0.9972\n",
      "\n",
      "── Fold 5/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 33s 33ms/step - loss: 1.7031 - accuracy: 0.4176 - val_loss: 1.1528 - val_accuracy: 0.6067 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 1.0437 - accuracy: 0.6429 - val_loss: 0.7889 - val_accuracy: 0.7305 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.7159 - accuracy: 0.7583 - val_loss: 0.5096 - val_accuracy: 0.8265 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.5387 - accuracy: 0.8182 - val_loss: 0.3802 - val_accuracy: 0.8649 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.4318 - accuracy: 0.8523 - val_loss: 0.4000 - val_accuracy: 0.8725 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.3615 - accuracy: 0.8771 - val_loss: 0.6772 - val_accuracy: 0.8121 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.3118 - accuracy: 0.8949 - val_loss: 0.3785 - val_accuracy: 0.8856 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 34s 37ms/step - loss: 0.2736 - accuracy: 0.9067 - val_loss: 0.1895 - val_accuracy: 0.9325 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 36s 38ms/step - loss: 0.2462 - accuracy: 0.9159 - val_loss: 0.1852 - val_accuracy: 0.9381 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.2185 - accuracy: 0.9250 - val_loss: 0.2653 - val_accuracy: 0.9145 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.2023 - accuracy: 0.9313 - val_loss: 0.1568 - val_accuracy: 0.9473 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.1884 - accuracy: 0.9357 - val_loss: 0.1413 - val_accuracy: 0.9511 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 30s 33ms/step - loss: 0.1771 - accuracy: 0.9399 - val_loss: 0.1580 - val_accuracy: 0.9448 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.1625 - accuracy: 0.9460 - val_loss: 0.3313 - val_accuracy: 0.9018 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.1562 - accuracy: 0.9478 - val_loss: 0.2809 - val_accuracy: 0.9179 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0831 - accuracy: 0.9712 - val_loss: 0.0840 - val_accuracy: 0.9738 - lr: 5.0000e-04\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0733 - accuracy: 0.9744 - val_loss: 0.0609 - val_accuracy: 0.9811 - lr: 5.0000e-04\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0747 - accuracy: 0.9746 - val_loss: 0.0615 - val_accuracy: 0.9810 - lr: 5.0000e-04\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0706 - accuracy: 0.9754 - val_loss: 0.0567 - val_accuracy: 0.9831 - lr: 5.0000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 30s 33ms/step - loss: 0.0653 - accuracy: 0.9777 - val_loss: 0.0474 - val_accuracy: 0.9837 - lr: 5.0000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0654 - accuracy: 0.9777 - val_loss: 0.1009 - val_accuracy: 0.9690 - lr: 5.0000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0622 - accuracy: 0.9796 - val_loss: 0.0420 - val_accuracy: 0.9867 - lr: 5.0000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0599 - accuracy: 0.9797 - val_loss: 0.0696 - val_accuracy: 0.9783 - lr: 5.0000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0603 - accuracy: 0.9792 - val_loss: 0.0751 - val_accuracy: 0.9772 - lr: 5.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0582 - accuracy: 0.9804 - val_loss: 0.0580 - val_accuracy: 0.9830 - lr: 5.0000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0311 - accuracy: 0.9893 - val_loss: 0.0302 - val_accuracy: 0.9917 - lr: 2.5000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0284 - accuracy: 0.9901 - val_loss: 0.0558 - val_accuracy: 0.9860 - lr: 2.5000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0274 - accuracy: 0.9905 - val_loss: 0.0291 - val_accuracy: 0.9914 - lr: 2.5000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0288 - accuracy: 0.9903 - val_loss: 0.0285 - val_accuracy: 0.9924 - lr: 2.5000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0269 - accuracy: 0.9909 - val_loss: 0.0260 - val_accuracy: 0.9931 - lr: 2.5000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0269 - accuracy: 0.9909 - val_loss: 0.0252 - val_accuracy: 0.9929 - lr: 2.5000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0264 - accuracy: 0.9908 - val_loss: 0.0271 - val_accuracy: 0.9932 - lr: 2.5000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0256 - accuracy: 0.9914 - val_loss: 0.0242 - val_accuracy: 0.9941 - lr: 2.5000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0246 - accuracy: 0.9915 - val_loss: 0.0377 - val_accuracy: 0.9893 - lr: 2.5000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 0.0222 - val_accuracy: 0.9934 - lr: 2.5000e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0240 - accuracy: 0.9919 - val_loss: 0.0204 - val_accuracy: 0.9947 - lr: 2.5000e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0247 - accuracy: 0.9919 - val_loss: 0.0268 - val_accuracy: 0.9921 - lr: 2.5000e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0226 - accuracy: 0.9924 - val_loss: 0.0259 - val_accuracy: 0.9927 - lr: 2.5000e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0216 - accuracy: 0.9929 - val_loss: 0.0250 - val_accuracy: 0.9924 - lr: 2.5000e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0146 - accuracy: 0.9949 - val_loss: 0.0184 - val_accuracy: 0.9954 - lr: 1.2500e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0129 - accuracy: 0.9955 - val_loss: 0.0180 - val_accuracy: 0.9961 - lr: 1.2500e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.0173 - val_accuracy: 0.9962 - lr: 1.2500e-04\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0161 - val_accuracy: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.0169 - val_accuracy: 0.9961 - lr: 1.2500e-04\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 33s 36ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0192 - val_accuracy: 0.9961 - lr: 1.2500e-04\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 34s 37ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.0162 - val_accuracy: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0141 - val_accuracy: 0.9969 - lr: 6.2500e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.0151 - val_accuracy: 0.9969 - lr: 6.2500e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 32s 35ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0153 - val_accuracy: 0.9967 - lr: 6.2500e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.0163 - val_accuracy: 0.9964 - lr: 6.2500e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 31s 34ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.0138 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.0140 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0135 - val_accuracy: 0.9976 - lr: 3.1250e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0125 - val_accuracy: 0.9977 - lr: 3.1250e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0128 - val_accuracy: 0.9977 - lr: 3.1250e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0132 - val_accuracy: 0.9976 - lr: 3.1250e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.0125 - val_accuracy: 0.9976 - lr: 3.1250e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0130 - val_accuracy: 0.9976 - lr: 1.5625e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0128 - val_accuracy: 0.9977 - lr: 1.5625e-05\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0125 - val_accuracy: 0.9974 - lr: 1.5625e-05\n",
      "1033/1033 [==============================] - 9s 9ms/step - loss: 0.0270 - accuracy: 0.9975\n",
      "\n",
      "── Fold 6/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 32s 32ms/step - loss: 1.7018 - accuracy: 0.4173 - val_loss: 1.1301 - val_accuracy: 0.6071 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 1.0418 - accuracy: 0.6442 - val_loss: 0.7070 - val_accuracy: 0.7568 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.7092 - accuracy: 0.7601 - val_loss: 0.5383 - val_accuracy: 0.8144 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.5345 - accuracy: 0.8180 - val_loss: 0.4636 - val_accuracy: 0.8382 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.4260 - accuracy: 0.8552 - val_loss: 0.3768 - val_accuracy: 0.8744 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.3547 - accuracy: 0.8784 - val_loss: 0.2930 - val_accuracy: 0.9019 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.3055 - accuracy: 0.8964 - val_loss: 0.3579 - val_accuracy: 0.8766 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.2678 - accuracy: 0.9088 - val_loss: 0.2134 - val_accuracy: 0.9272 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.2348 - accuracy: 0.9194 - val_loss: 0.2270 - val_accuracy: 0.9233 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.2182 - accuracy: 0.9254 - val_loss: 0.1791 - val_accuracy: 0.9408 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.1971 - accuracy: 0.9325 - val_loss: 0.1849 - val_accuracy: 0.9394 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.1879 - accuracy: 0.9354 - val_loss: 0.1482 - val_accuracy: 0.9491 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.1709 - accuracy: 0.9427 - val_loss: 0.1338 - val_accuracy: 0.9530 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.1621 - accuracy: 0.9456 - val_loss: 0.1520 - val_accuracy: 0.9471 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.1539 - accuracy: 0.9478 - val_loss: 0.2214 - val_accuracy: 0.9323 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.1485 - accuracy: 0.9504 - val_loss: 0.0982 - val_accuracy: 0.9649 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.1393 - accuracy: 0.9533 - val_loss: 0.1469 - val_accuracy: 0.9507 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.1329 - accuracy: 0.9555 - val_loss: 0.1130 - val_accuracy: 0.9624 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.1313 - accuracy: 0.9563 - val_loss: 0.1151 - val_accuracy: 0.9618 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0665 - accuracy: 0.9773 - val_loss: 0.0475 - val_accuracy: 0.9834 - lr: 5.0000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0610 - accuracy: 0.9794 - val_loss: 0.0496 - val_accuracy: 0.9839 - lr: 5.0000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0592 - accuracy: 0.9799 - val_loss: 0.0506 - val_accuracy: 0.9827 - lr: 5.0000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0580 - accuracy: 0.9802 - val_loss: 0.0561 - val_accuracy: 0.9823 - lr: 5.0000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0326 - accuracy: 0.9882 - val_loss: 0.0261 - val_accuracy: 0.9908 - lr: 2.5000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0301 - accuracy: 0.9895 - val_loss: 0.0256 - val_accuracy: 0.9921 - lr: 2.5000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0279 - accuracy: 0.9903 - val_loss: 0.0296 - val_accuracy: 0.9908 - lr: 2.5000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0283 - accuracy: 0.9902 - val_loss: 0.0251 - val_accuracy: 0.9922 - lr: 2.5000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0256 - accuracy: 0.9911 - val_loss: 0.0223 - val_accuracy: 0.9935 - lr: 2.5000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0274 - accuracy: 0.9905 - val_loss: 0.0246 - val_accuracy: 0.9922 - lr: 2.5000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0247 - accuracy: 0.9918 - val_loss: 0.0267 - val_accuracy: 0.9926 - lr: 2.5000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0247 - accuracy: 0.9914 - val_loss: 0.0225 - val_accuracy: 0.9926 - lr: 2.5000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0165 - accuracy: 0.9944 - val_loss: 0.0160 - val_accuracy: 0.9956 - lr: 1.2500e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0140 - accuracy: 0.9950 - val_loss: 0.0178 - val_accuracy: 0.9952 - lr: 1.2500e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 0.0170 - val_accuracy: 0.9950 - lr: 1.2500e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0133 - accuracy: 0.9952 - val_loss: 0.0201 - val_accuracy: 0.9948 - lr: 1.2500e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0163 - val_accuracy: 0.9956 - lr: 6.2500e-05\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0163 - val_accuracy: 0.9956 - lr: 6.2500e-05\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.0154 - val_accuracy: 0.9955 - lr: 6.2500e-05\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.0161 - val_accuracy: 0.9961 - lr: 6.2500e-05\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 0.0150 - val_accuracy: 0.9965 - lr: 6.2500e-05\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.0170 - val_accuracy: 0.9964 - lr: 6.2500e-05\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.0153 - val_accuracy: 0.9964 - lr: 6.2500e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.0164 - val_accuracy: 0.9959 - lr: 6.2500e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0155 - val_accuracy: 0.9963 - lr: 3.1250e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.0150 - val_accuracy: 0.9964 - lr: 3.1250e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0143 - val_accuracy: 0.9967 - lr: 3.1250e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0148 - val_accuracy: 0.9964 - lr: 3.1250e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0152 - val_accuracy: 0.9964 - lr: 3.1250e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0141 - val_accuracy: 0.9967 - lr: 3.1250e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.0149 - val_accuracy: 0.9964 - lr: 3.1250e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.0151 - val_accuracy: 0.9967 - lr: 3.1250e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 30s 31ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.0156 - val_accuracy: 0.9967 - lr: 3.1250e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0153 - val_accuracy: 0.9969 - lr: 1.5625e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.0148 - val_accuracy: 0.9967 - lr: 1.5625e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.0146 - val_accuracy: 0.9968 - lr: 1.5625e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0142 - val_accuracy: 0.9970 - lr: 7.8125e-06\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0142 - val_accuracy: 0.9969 - lr: 7.8125e-06\n",
      "1033/1033 [==============================] - 9s 9ms/step - loss: 0.0291 - accuracy: 0.9974\n",
      "\n",
      "── Fold 7/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 34s 33ms/step - loss: 1.6940 - accuracy: 0.4227 - val_loss: 1.1930 - val_accuracy: 0.5913 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 1.0001 - accuracy: 0.6601 - val_loss: 0.7573 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.6806 - accuracy: 0.7697 - val_loss: 0.4708 - val_accuracy: 0.8327 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.5111 - accuracy: 0.8261 - val_loss: 0.3795 - val_accuracy: 0.8701 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.4133 - accuracy: 0.8598 - val_loss: 0.2766 - val_accuracy: 0.9029 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.3419 - accuracy: 0.8835 - val_loss: 0.3232 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.2920 - accuracy: 0.9004 - val_loss: 0.2179 - val_accuracy: 0.9209 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.2568 - accuracy: 0.9123 - val_loss: 0.1929 - val_accuracy: 0.9325 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.2336 - accuracy: 0.9198 - val_loss: 0.1454 - val_accuracy: 0.9498 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.2143 - accuracy: 0.9278 - val_loss: 0.1559 - val_accuracy: 0.9476 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 30s 33ms/step - loss: 0.1909 - accuracy: 0.9352 - val_loss: 0.1372 - val_accuracy: 0.9517 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.1793 - accuracy: 0.9395 - val_loss: 0.1193 - val_accuracy: 0.9581 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.1684 - accuracy: 0.9431 - val_loss: 0.1696 - val_accuracy: 0.9449 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.1590 - accuracy: 0.9455 - val_loss: 0.1160 - val_accuracy: 0.9587 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.1477 - accuracy: 0.9508 - val_loss: 0.0984 - val_accuracy: 0.9636 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.1451 - accuracy: 0.9512 - val_loss: 0.0906 - val_accuracy: 0.9682 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.1347 - accuracy: 0.9549 - val_loss: 0.1034 - val_accuracy: 0.9626 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.1331 - accuracy: 0.9554 - val_loss: 0.1068 - val_accuracy: 0.9644 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.1274 - accuracy: 0.9575 - val_loss: 0.1376 - val_accuracy: 0.9505 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0639 - accuracy: 0.9775 - val_loss: 0.0484 - val_accuracy: 0.9842 - lr: 5.0000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0544 - accuracy: 0.9811 - val_loss: 0.1173 - val_accuracy: 0.9696 - lr: 5.0000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0567 - accuracy: 0.9807 - val_loss: 0.0376 - val_accuracy: 0.9872 - lr: 5.0000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0549 - accuracy: 0.9816 - val_loss: 0.0580 - val_accuracy: 0.9803 - lr: 5.0000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0545 - accuracy: 0.9812 - val_loss: 0.0394 - val_accuracy: 0.9868 - lr: 5.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0514 - accuracy: 0.9825 - val_loss: 0.0421 - val_accuracy: 0.9859 - lr: 5.0000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0286 - accuracy: 0.9902 - val_loss: 0.0184 - val_accuracy: 0.9943 - lr: 2.5000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0253 - accuracy: 0.9912 - val_loss: 0.0244 - val_accuracy: 0.9930 - lr: 2.5000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 29s 31ms/step - loss: 0.0259 - accuracy: 0.9914 - val_loss: 0.0191 - val_accuracy: 0.9948 - lr: 2.5000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0253 - accuracy: 0.9913 - val_loss: 0.0158 - val_accuracy: 0.9959 - lr: 2.5000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0241 - accuracy: 0.9916 - val_loss: 0.0173 - val_accuracy: 0.9945 - lr: 2.5000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0233 - accuracy: 0.9918 - val_loss: 0.0207 - val_accuracy: 0.9941 - lr: 2.5000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 31s 34ms/step - loss: 0.0214 - accuracy: 0.9926 - val_loss: 0.0203 - val_accuracy: 0.9952 - lr: 2.5000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0150 - accuracy: 0.9950 - val_loss: 0.0148 - val_accuracy: 0.9961 - lr: 1.2500e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.0139 - val_accuracy: 0.9972 - lr: 1.2500e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.0163 - val_accuracy: 0.9962 - lr: 1.2500e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.0161 - val_accuracy: 0.9960 - lr: 1.2500e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 0.0115 - val_accuracy: 0.9977 - lr: 1.2500e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.0143 - val_accuracy: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.0117 - val_accuracy: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.0141 - val_accuracy: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0124 - val_accuracy: 0.9978 - lr: 6.2500e-05\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 0.0126 - val_accuracy: 0.9977 - lr: 6.2500e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0117 - val_accuracy: 0.9980 - lr: 6.2500e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.0106 - val_accuracy: 0.9983 - lr: 3.1250e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0107 - val_accuracy: 0.9983 - lr: 3.1250e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.0109 - val_accuracy: 0.9983 - lr: 3.1250e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 30s 32ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 0.0106 - val_accuracy: 0.9983 - lr: 3.1250e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 31s 33ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0107 - val_accuracy: 0.9982 - lr: 1.5625e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 32s 35ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.0103 - val_accuracy: 0.9980 - lr: 1.5625e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0106 - val_accuracy: 0.9983 - lr: 1.5625e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0107 - val_accuracy: 0.9985 - lr: 1.5625e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 33s 36ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0105 - val_accuracy: 0.9984 - lr: 1.5625e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0104 - val_accuracy: 0.9983 - lr: 7.8125e-06\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0100 - val_accuracy: 0.9982 - lr: 7.8125e-06\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 32s 35ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.0100 - val_accuracy: 0.9983 - lr: 7.8125e-06\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0102 - val_accuracy: 0.9984 - lr: 7.8125e-06\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0102 - val_accuracy: 0.9983 - lr: 7.8125e-06\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0101 - val_accuracy: 0.9983 - lr: 3.9063e-06\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 32s 35ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.0100 - val_accuracy: 0.9983 - lr: 3.9063e-06\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0099 - val_accuracy: 0.9983 - lr: 3.9063e-06\n",
      "1033/1033 [==============================] - 11s 10ms/step - loss: 0.0239 - accuracy: 0.9980\n",
      "\n",
      "── Fold 8/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 36s 36ms/step - loss: 1.7272 - accuracy: 0.4076 - val_loss: 1.2028 - val_accuracy: 0.5862 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 1.0713 - accuracy: 0.6354 - val_loss: 0.7903 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.7385 - accuracy: 0.7509 - val_loss: 0.4925 - val_accuracy: 0.8272 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.5497 - accuracy: 0.8141 - val_loss: 0.4846 - val_accuracy: 0.8330 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.4404 - accuracy: 0.8509 - val_loss: 0.3888 - val_accuracy: 0.8670 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.3631 - accuracy: 0.8768 - val_loss: 0.2630 - val_accuracy: 0.9079 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 32s 35ms/step - loss: 0.3141 - accuracy: 0.8926 - val_loss: 0.2301 - val_accuracy: 0.9198 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.2752 - accuracy: 0.9062 - val_loss: 0.1856 - val_accuracy: 0.9360 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.2434 - accuracy: 0.9162 - val_loss: 0.1864 - val_accuracy: 0.9342 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 32s 35ms/step - loss: 0.2220 - accuracy: 0.9243 - val_loss: 0.2032 - val_accuracy: 0.9309 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 32s 35ms/step - loss: 0.2009 - accuracy: 0.9311 - val_loss: 0.2440 - val_accuracy: 0.9192 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.1136 - accuracy: 0.9602 - val_loss: 0.0804 - val_accuracy: 0.9713 - lr: 5.0000e-04\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0995 - accuracy: 0.9654 - val_loss: 0.0731 - val_accuracy: 0.9764 - lr: 5.0000e-04\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0974 - accuracy: 0.9665 - val_loss: 0.0705 - val_accuracy: 0.9764 - lr: 5.0000e-04\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 34s 37ms/step - loss: 0.0919 - accuracy: 0.9685 - val_loss: 0.0816 - val_accuracy: 0.9746 - lr: 5.0000e-04\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 35s 38ms/step - loss: 0.0861 - accuracy: 0.9703 - val_loss: 0.0637 - val_accuracy: 0.9789 - lr: 5.0000e-04\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0810 - accuracy: 0.9719 - val_loss: 0.0553 - val_accuracy: 0.9815 - lr: 5.0000e-04\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0794 - accuracy: 0.9727 - val_loss: 0.0566 - val_accuracy: 0.9815 - lr: 5.0000e-04\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 34s 37ms/step - loss: 0.0770 - accuracy: 0.9735 - val_loss: 0.0588 - val_accuracy: 0.9809 - lr: 5.0000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 32s 35ms/step - loss: 0.0746 - accuracy: 0.9744 - val_loss: 0.0539 - val_accuracy: 0.9825 - lr: 5.0000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0712 - accuracy: 0.9757 - val_loss: 0.0592 - val_accuracy: 0.9823 - lr: 5.0000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0701 - accuracy: 0.9762 - val_loss: 0.0534 - val_accuracy: 0.9836 - lr: 5.0000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 38s 40ms/step - loss: 0.0667 - accuracy: 0.9767 - val_loss: 0.0535 - val_accuracy: 0.9823 - lr: 5.0000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0657 - accuracy: 0.9777 - val_loss: 0.0613 - val_accuracy: 0.9801 - lr: 5.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0612 - accuracy: 0.9789 - val_loss: 0.0483 - val_accuracy: 0.9836 - lr: 5.0000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0621 - accuracy: 0.9792 - val_loss: 0.0579 - val_accuracy: 0.9821 - lr: 5.0000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0606 - accuracy: 0.9799 - val_loss: 0.0459 - val_accuracy: 0.9862 - lr: 5.0000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0583 - accuracy: 0.9801 - val_loss: 0.0464 - val_accuracy: 0.9867 - lr: 5.0000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 33s 36ms/step - loss: 0.0565 - accuracy: 0.9807 - val_loss: 0.0585 - val_accuracy: 0.9835 - lr: 5.0000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0558 - accuracy: 0.9811 - val_loss: 0.0473 - val_accuracy: 0.9856 - lr: 5.0000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0294 - accuracy: 0.9899 - val_loss: 0.0311 - val_accuracy: 0.9921 - lr: 2.5000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 36s 38ms/step - loss: 0.0274 - accuracy: 0.9908 - val_loss: 0.0280 - val_accuracy: 0.9929 - lr: 2.5000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0267 - accuracy: 0.9911 - val_loss: 0.0259 - val_accuracy: 0.9935 - lr: 2.5000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 34s 37ms/step - loss: 0.0252 - accuracy: 0.9911 - val_loss: 0.0236 - val_accuracy: 0.9936 - lr: 2.5000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0255 - accuracy: 0.9915 - val_loss: 0.0198 - val_accuracy: 0.9952 - lr: 2.5000e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 33s 36ms/step - loss: 0.0253 - accuracy: 0.9917 - val_loss: 0.0234 - val_accuracy: 0.9943 - lr: 2.5000e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 35s 37ms/step - loss: 0.0252 - accuracy: 0.9918 - val_loss: 0.0331 - val_accuracy: 0.9919 - lr: 2.5000e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 0.0336 - val_accuracy: 0.9930 - lr: 2.5000e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 35s 38ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.0209 - val_accuracy: 0.9956 - lr: 1.2500e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.0200 - val_accuracy: 0.9964 - lr: 1.2500e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 35s 37ms/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.0214 - val_accuracy: 0.9959 - lr: 1.2500e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.0194 - val_accuracy: 0.9966 - lr: 6.2500e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.0194 - val_accuracy: 0.9970 - lr: 6.2500e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.0195 - val_accuracy: 0.9970 - lr: 6.2500e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 33s 36ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.0178 - val_accuracy: 0.9970 - lr: 6.2500e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.0165 - val_accuracy: 0.9972 - lr: 6.2500e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 34s 37ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.0171 - val_accuracy: 0.9970 - lr: 6.2500e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 34s 37ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.0174 - val_accuracy: 0.9970 - lr: 6.2500e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0160 - val_accuracy: 0.9971 - lr: 6.2500e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 34s 37ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.0152 - val_accuracy: 0.9975 - lr: 6.2500e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 34s 37ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.0149 - val_accuracy: 0.9980 - lr: 6.2500e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0171 - val_accuracy: 0.9973 - lr: 6.2500e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0164 - val_accuracy: 0.9976 - lr: 6.2500e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 0.0169 - val_accuracy: 0.9973 - lr: 6.2500e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.0167 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.0155 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 32s 35ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.0154 - val_accuracy: 0.9973 - lr: 3.1250e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0152 - val_accuracy: 0.9975 - lr: 1.5625e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0155 - val_accuracy: 0.9974 - lr: 1.5625e-05\n",
      "1033/1033 [==============================] - 15s 15ms/step - loss: 0.0274 - accuracy: 0.9978\n",
      "\n",
      "── Fold 9/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 39s 36ms/step - loss: 1.6987 - accuracy: 0.4211 - val_loss: 1.1277 - val_accuracy: 0.6105 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 33s 36ms/step - loss: 1.0254 - accuracy: 0.6512 - val_loss: 0.7690 - val_accuracy: 0.7430 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 33s 36ms/step - loss: 0.6968 - accuracy: 0.7641 - val_loss: 0.5245 - val_accuracy: 0.8196 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.5253 - accuracy: 0.8211 - val_loss: 0.4198 - val_accuracy: 0.8564 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.4179 - accuracy: 0.8577 - val_loss: 0.2795 - val_accuracy: 0.9041 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 39s 42ms/step - loss: 0.3508 - accuracy: 0.8806 - val_loss: 0.2796 - val_accuracy: 0.9020 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 41s 44ms/step - loss: 0.3033 - accuracy: 0.8966 - val_loss: 0.2200 - val_accuracy: 0.9225 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 41s 43ms/step - loss: 0.2637 - accuracy: 0.9103 - val_loss: 0.2103 - val_accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 35s 38ms/step - loss: 0.2397 - accuracy: 0.9186 - val_loss: 0.1570 - val_accuracy: 0.9446 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.2136 - accuracy: 0.9270 - val_loss: 0.1651 - val_accuracy: 0.9416 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 36s 38ms/step - loss: 0.1957 - accuracy: 0.9334 - val_loss: 0.1292 - val_accuracy: 0.9551 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 33s 36ms/step - loss: 0.1837 - accuracy: 0.9381 - val_loss: 0.1197 - val_accuracy: 0.9577 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.1691 - accuracy: 0.9431 - val_loss: 0.1172 - val_accuracy: 0.9585 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 33s 36ms/step - loss: 0.1626 - accuracy: 0.9448 - val_loss: 0.1314 - val_accuracy: 0.9544 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.1474 - accuracy: 0.9506 - val_loss: 0.1064 - val_accuracy: 0.9629 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.1451 - accuracy: 0.9506 - val_loss: 0.1233 - val_accuracy: 0.9592 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 33s 36ms/step - loss: 0.1400 - accuracy: 0.9522 - val_loss: 0.0936 - val_accuracy: 0.9679 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.1317 - accuracy: 0.9558 - val_loss: 0.1111 - val_accuracy: 0.9626 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.1302 - accuracy: 0.9558 - val_loss: 0.1005 - val_accuracy: 0.9668 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.1213 - accuracy: 0.9594 - val_loss: 0.1142 - val_accuracy: 0.9644 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0610 - accuracy: 0.9793 - val_loss: 0.0392 - val_accuracy: 0.9868 - lr: 5.0000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 33s 36ms/step - loss: 0.0557 - accuracy: 0.9807 - val_loss: 0.0426 - val_accuracy: 0.9880 - lr: 5.0000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0548 - accuracy: 0.9815 - val_loss: 0.0428 - val_accuracy: 0.9862 - lr: 5.0000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 35s 37ms/step - loss: 0.0550 - accuracy: 0.9812 - val_loss: 0.0410 - val_accuracy: 0.9873 - lr: 5.0000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 35s 38ms/step - loss: 0.0299 - accuracy: 0.9894 - val_loss: 0.0228 - val_accuracy: 0.9927 - lr: 2.5000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 34s 37ms/step - loss: 0.0280 - accuracy: 0.9902 - val_loss: 0.0261 - val_accuracy: 0.9927 - lr: 2.5000e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 36s 38ms/step - loss: 0.0258 - accuracy: 0.9913 - val_loss: 0.0226 - val_accuracy: 0.9945 - lr: 2.5000e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 33s 36ms/step - loss: 0.0260 - accuracy: 0.9913 - val_loss: 0.0230 - val_accuracy: 0.9936 - lr: 2.5000e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 35s 37ms/step - loss: 0.0251 - accuracy: 0.9912 - val_loss: 0.0210 - val_accuracy: 0.9940 - lr: 2.5000e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0255 - accuracy: 0.9912 - val_loss: 0.0223 - val_accuracy: 0.9940 - lr: 2.5000e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0233 - accuracy: 0.9919 - val_loss: 0.0343 - val_accuracy: 0.9902 - lr: 2.5000e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0230 - accuracy: 0.9919 - val_loss: 0.0184 - val_accuracy: 0.9941 - lr: 2.5000e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 34s 37ms/step - loss: 0.0216 - accuracy: 0.9922 - val_loss: 0.0267 - val_accuracy: 0.9927 - lr: 2.5000e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 33s 36ms/step - loss: 0.0225 - accuracy: 0.9920 - val_loss: 0.0225 - val_accuracy: 0.9945 - lr: 2.5000e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0219 - accuracy: 0.9927 - val_loss: 0.0222 - val_accuracy: 0.9943 - lr: 2.5000e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0144 - accuracy: 0.9950 - val_loss: 0.0147 - val_accuracy: 0.9966 - lr: 1.2500e-04\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 0.0147 - val_accuracy: 0.9965 - lr: 1.2500e-04\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.0132 - val_accuracy: 0.9975 - lr: 1.2500e-04\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.0131 - val_accuracy: 0.9968 - lr: 1.2500e-04\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.0123 - val_accuracy: 0.9973 - lr: 1.2500e-04\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 34s 37ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0158 - val_accuracy: 0.9961 - lr: 1.2500e-04\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 0.0158 - val_accuracy: 0.9978 - lr: 1.2500e-04\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 35s 37ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0146 - val_accuracy: 0.9965 - lr: 1.2500e-04\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 35s 37ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.0111 - val_accuracy: 0.9980 - lr: 6.2500e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0123 - val_accuracy: 0.9978 - lr: 6.2500e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.0119 - val_accuracy: 0.9977 - lr: 6.2500e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.0103 - val_accuracy: 0.9979 - lr: 6.2500e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 35s 37ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.0104 - val_accuracy: 0.9982 - lr: 6.2500e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0112 - val_accuracy: 0.9978 - lr: 6.2500e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 35s 37ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.0121 - val_accuracy: 0.9977 - lr: 6.2500e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 33s 36ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.0107 - val_accuracy: 0.9980 - lr: 3.1250e-05\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 33s 36ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0107 - val_accuracy: 0.9982 - lr: 3.1250e-05\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 33s 36ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0101 - val_accuracy: 0.9981 - lr: 3.1250e-05\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.0097 - val_accuracy: 0.9983 - lr: 3.1250e-05\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0102 - val_accuracy: 0.9980 - lr: 3.1250e-05\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 34s 37ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0104 - val_accuracy: 0.9979 - lr: 3.1250e-05\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 34s 37ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0106 - val_accuracy: 0.9979 - lr: 3.1250e-05\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 33s 36ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0098 - val_accuracy: 0.9982 - lr: 1.5625e-05\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0105 - val_accuracy: 0.9982 - lr: 1.5625e-05\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 34s 37ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0099 - val_accuracy: 0.9983 - lr: 1.5625e-05\n",
      "1033/1033 [==============================] - 12s 12ms/step - loss: 0.0268 - accuracy: 0.9978\n",
      "\n",
      "── Fold 10/10\n",
      "Epoch 1/60\n",
      "930/930 [==============================] - 41s 40ms/step - loss: 1.7235 - accuracy: 0.4110 - val_loss: 1.1897 - val_accuracy: 0.5917 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "930/930 [==============================] - 36s 39ms/step - loss: 1.0421 - accuracy: 0.6449 - val_loss: 0.7575 - val_accuracy: 0.7365 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "930/930 [==============================] - 36s 38ms/step - loss: 0.7134 - accuracy: 0.7586 - val_loss: 0.5055 - val_accuracy: 0.8253 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.5330 - accuracy: 0.8198 - val_loss: 0.3674 - val_accuracy: 0.8719 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.4249 - accuracy: 0.8572 - val_loss: 0.3662 - val_accuracy: 0.8777 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "930/930 [==============================] - 40s 42ms/step - loss: 0.3548 - accuracy: 0.8795 - val_loss: 0.3080 - val_accuracy: 0.8930 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "930/930 [==============================] - 37s 40ms/step - loss: 0.3007 - accuracy: 0.8978 - val_loss: 0.3941 - val_accuracy: 0.8778 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.2608 - accuracy: 0.9117 - val_loss: 0.2005 - val_accuracy: 0.9318 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "930/930 [==============================] - 36s 38ms/step - loss: 0.2370 - accuracy: 0.9200 - val_loss: 0.1667 - val_accuracy: 0.9413 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "930/930 [==============================] - 36s 38ms/step - loss: 0.2175 - accuracy: 0.9264 - val_loss: 0.1732 - val_accuracy: 0.9416 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "930/930 [==============================] - 36s 38ms/step - loss: 0.1947 - accuracy: 0.9340 - val_loss: 0.1929 - val_accuracy: 0.9358 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "930/930 [==============================] - 35s 37ms/step - loss: 0.1804 - accuracy: 0.9380 - val_loss: 0.2985 - val_accuracy: 0.9132 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "930/930 [==============================] - 35s 37ms/step - loss: 0.1018 - accuracy: 0.9651 - val_loss: 0.0721 - val_accuracy: 0.9753 - lr: 5.0000e-04\n",
      "Epoch 14/60\n",
      "930/930 [==============================] - 36s 38ms/step - loss: 0.0864 - accuracy: 0.9703 - val_loss: 0.0852 - val_accuracy: 0.9719 - lr: 5.0000e-04\n",
      "Epoch 15/60\n",
      "930/930 [==============================] - 37s 39ms/step - loss: 0.0869 - accuracy: 0.9704 - val_loss: 0.0666 - val_accuracy: 0.9800 - lr: 5.0000e-04\n",
      "Epoch 16/60\n",
      "930/930 [==============================] - 35s 37ms/step - loss: 0.0808 - accuracy: 0.9714 - val_loss: 0.0896 - val_accuracy: 0.9718 - lr: 5.0000e-04\n",
      "Epoch 17/60\n",
      "930/930 [==============================] - 34s 37ms/step - loss: 0.0795 - accuracy: 0.9729 - val_loss: 0.0682 - val_accuracy: 0.9784 - lr: 5.0000e-04\n",
      "Epoch 18/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0739 - accuracy: 0.9744 - val_loss: 0.0675 - val_accuracy: 0.9776 - lr: 5.0000e-04\n",
      "Epoch 19/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0440 - accuracy: 0.9849 - val_loss: 0.0343 - val_accuracy: 0.9896 - lr: 2.5000e-04\n",
      "Epoch 20/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0386 - accuracy: 0.9866 - val_loss: 0.0359 - val_accuracy: 0.9894 - lr: 2.5000e-04\n",
      "Epoch 21/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0387 - accuracy: 0.9868 - val_loss: 0.0340 - val_accuracy: 0.9902 - lr: 2.5000e-04\n",
      "Epoch 22/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0361 - accuracy: 0.9876 - val_loss: 0.0311 - val_accuracy: 0.9898 - lr: 2.5000e-04\n",
      "Epoch 23/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0371 - accuracy: 0.9871 - val_loss: 0.0355 - val_accuracy: 0.9900 - lr: 2.5000e-04\n",
      "Epoch 24/60\n",
      "930/930 [==============================] - 33s 36ms/step - loss: 0.0346 - accuracy: 0.9881 - val_loss: 0.0367 - val_accuracy: 0.9889 - lr: 2.5000e-04\n",
      "Epoch 25/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0331 - accuracy: 0.9884 - val_loss: 0.0438 - val_accuracy: 0.9874 - lr: 2.5000e-04\n",
      "Epoch 26/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0231 - accuracy: 0.9920 - val_loss: 0.0202 - val_accuracy: 0.9956 - lr: 1.2500e-04\n",
      "Epoch 27/60\n",
      "930/930 [==============================] - 36s 38ms/step - loss: 0.0195 - accuracy: 0.9930 - val_loss: 0.0228 - val_accuracy: 0.9949 - lr: 1.2500e-04\n",
      "Epoch 28/60\n",
      "930/930 [==============================] - 35s 38ms/step - loss: 0.0203 - accuracy: 0.9927 - val_loss: 0.0195 - val_accuracy: 0.9953 - lr: 1.2500e-04\n",
      "Epoch 29/60\n",
      "930/930 [==============================] - 33s 36ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.0190 - val_accuracy: 0.9956 - lr: 1.2500e-04\n",
      "Epoch 30/60\n",
      "930/930 [==============================] - 31s 34ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.0182 - val_accuracy: 0.9955 - lr: 1.2500e-04\n",
      "Epoch 31/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 0.0164 - val_accuracy: 0.9963 - lr: 1.2500e-04\n",
      "Epoch 32/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0176 - accuracy: 0.9941 - val_loss: 0.0162 - val_accuracy: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 33/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0171 - accuracy: 0.9941 - val_loss: 0.0172 - val_accuracy: 0.9964 - lr: 1.2500e-04\n",
      "Epoch 34/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0167 - accuracy: 0.9943 - val_loss: 0.0178 - val_accuracy: 0.9956 - lr: 1.2500e-04\n",
      "Epoch 35/60\n",
      "930/930 [==============================] - 33s 36ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.0203 - val_accuracy: 0.9956 - lr: 1.2500e-04\n",
      "Epoch 36/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.0164 - val_accuracy: 0.9966 - lr: 6.2500e-05\n",
      "Epoch 37/60\n",
      "930/930 [==============================] - 31s 34ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.0148 - val_accuracy: 0.9971 - lr: 6.2500e-05\n",
      "Epoch 38/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0139 - val_accuracy: 0.9979 - lr: 6.2500e-05\n",
      "Epoch 39/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0155 - val_accuracy: 0.9974 - lr: 6.2500e-05\n",
      "Epoch 40/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0168 - val_accuracy: 0.9968 - lr: 6.2500e-05\n",
      "Epoch 41/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 0.0152 - val_accuracy: 0.9970 - lr: 6.2500e-05\n",
      "Epoch 42/60\n",
      "930/930 [==============================] - 33s 36ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 0.0139 - val_accuracy: 0.9976 - lr: 3.1250e-05\n",
      "Epoch 43/60\n",
      "930/930 [==============================] - 32s 35ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.0139 - val_accuracy: 0.9977 - lr: 3.1250e-05\n",
      "Epoch 44/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0136 - val_accuracy: 0.9980 - lr: 3.1250e-05\n",
      "Epoch 45/60\n",
      "930/930 [==============================] - 32s 35ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0142 - val_accuracy: 0.9977 - lr: 3.1250e-05\n",
      "Epoch 46/60\n",
      "930/930 [==============================] - 33s 36ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.0143 - val_accuracy: 0.9974 - lr: 3.1250e-05\n",
      "Epoch 47/60\n",
      "930/930 [==============================] - 32s 34ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.0140 - val_accuracy: 0.9973 - lr: 3.1250e-05\n",
      "Epoch 48/60\n",
      "930/930 [==============================] - 33s 36ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.0141 - val_accuracy: 0.9977 - lr: 1.5625e-05\n",
      "Epoch 49/60\n",
      "930/930 [==============================] - 36s 38ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0144 - val_accuracy: 0.9972 - lr: 1.5625e-05\n",
      "Epoch 50/60\n",
      "930/930 [==============================] - 36s 38ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0136 - val_accuracy: 0.9980 - lr: 1.5625e-05\n",
      "Epoch 51/60\n",
      "930/930 [==============================] - 35s 37ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.0136 - val_accuracy: 0.9981 - lr: 7.8125e-06\n",
      "Epoch 52/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.0135 - val_accuracy: 0.9980 - lr: 7.8125e-06\n",
      "Epoch 53/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.0136 - val_accuracy: 0.9979 - lr: 7.8125e-06\n",
      "Epoch 54/60\n",
      "930/930 [==============================] - 34s 37ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.0134 - val_accuracy: 0.9981 - lr: 7.8125e-06\n",
      "Epoch 55/60\n",
      "930/930 [==============================] - 35s 37ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.0129 - val_accuracy: 0.9983 - lr: 7.8125e-06\n",
      "Epoch 56/60\n",
      "930/930 [==============================] - 34s 37ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0127 - val_accuracy: 0.9981 - lr: 7.8125e-06\n",
      "Epoch 57/60\n",
      "930/930 [==============================] - 33s 35ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.0129 - val_accuracy: 0.9980 - lr: 7.8125e-06\n",
      "Epoch 58/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.0130 - val_accuracy: 0.9982 - lr: 7.8125e-06\n",
      "Epoch 59/60\n",
      "930/930 [==============================] - 34s 36ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0131 - val_accuracy: 0.9977 - lr: 7.8125e-06\n",
      "Epoch 60/60\n",
      "930/930 [==============================] - 35s 37ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.0127 - val_accuracy: 0.9982 - lr: 3.9063e-06\n",
      "1033/1033 [==============================] - 11s 11ms/step - loss: 0.0233 - accuracy: 0.9977\n",
      "\n",
      "📊  Cross-validation summary\n",
      "              Model  Val_Acc_Mean  Val_Acc_SD  Test_Acc_Mean\n",
      "  HyT-Net_Propuesto        0.9976      0.0006         0.9976\n",
      "EMGHandNet_Original        0.9974      0.0004         0.9973\n",
      "EMGHandNet_Adaptado        0.9968      0.0004         0.9967\n",
      "   DualStr_Original        0.9963      0.0005         0.9966\n",
      "   DualStr_Adaptado        0.9930      0.0009         0.9926\n",
      "\n",
      "🏆  Mejor modelo según CV: HyT-Net_Propuesto (Val=0.998±0.001, Test≈0.998)\n"
     ]
    }
   ],
   "source": [
    "################ VAAAAAAAAAAL CRUZADAAAAAAAAA #########################\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# ---------- 6. CALLBACKS  & BUILDERS -----------------------------------------\n",
    "def make_callbacks(model_name, fold):\n",
    "    ts  = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tag = f\"{model_name}_F{fold}_{ts}\"\n",
    "    ck  = os.path.join(MODELS_DIR, f\"{tag}.keras\")\n",
    "    return [\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=8, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6),\n",
    "        ModelCheckpoint(ck, monitor=\"val_accuracy\", save_best_only=True, verbose=0),\n",
    "        TensorBoard(log_dir=os.path.join(RUNS_DIR, tag))\n",
    "    ]\n",
    "\n",
    "model_builders = {\n",
    "    \"DualStr_Adaptado\": (lambda: build_dualstream_adaptado(RAW_SHAPE, feat_dim, T_SUBWIN, NUM_CLASSES), True),\n",
    "    \"DualStr_Original\": (lambda: build_dualstream_original(RAW_SHAPE, feat_dim, T_SUBWIN, NUM_CLASSES), True),\n",
    "    \"EMGHandNet_Adaptado\": (lambda: build_emghandnet(RAW_SHAPE, T_SUBWIN, NUM_CLASSES), False),\n",
    "    \"EMGHandNet_Original\": (lambda: build_emghandnet_original(RAW_SHAPE, T_SUBWIN, NUM_CLASSES), False),\n",
    "    \"HyT-Net_Propuesto\": (lambda: build_hyt_net_propuesto(RAW_SHAPE, feat_dim, T_SUBWIN, NUM_CLASSES), True),\n",
    "    # Modelos antiguos (opcional):\n",
    "    \"DualStr_Adaptado_v1\": (lambda: build_dualstream(RAW_SHAPE, feat_dim, T_SUBWIN, NUM_CLASSES), True),\n",
    "    \"SOTA_trans\": (lambda: build_sota(RAW_SHAPE, feat_dim, T_SUBWIN, NUM_CLASSES), True),\n",
    "    \"Hybrid_A2\": (lambda: build_hybrid_v2(RAW_SHAPE, feat_dim, T_SUBWIN, NUM_CLASSES), True),   \n",
    "    \"EMGHand_Adaptado_v1\": (lambda: build_emghandnet(RAW_SHAPE, T_SUBWIN, NUM_CLASSES), False),\n",
    "}\n",
    "\n",
    "EPOCHS = 60\n",
    "KFOLDS = 10  # número de folds para CV\n",
    "\n",
    "# ---------- 7. CROSS-VALIDATION TRAINING -------------------------------------\n",
    "results = []   # acumula métricas por modelo\n",
    "skf = StratifiedKFold(n_splits=KFOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "for model_name, (builder, uses_feat) in model_builders.items():\n",
    "    print(f\"\\n################ {model_name} – {KFOLDS}-fold CV ################\")\n",
    "    fold_val_acc = []; fold_test_acc = []\n",
    "    # indices para CV: sobre TRAIN (X_tr_raw) y sus etiquetas originales\n",
    "    for fold, (idx_train, idx_val) in enumerate(skf.split(X_tr_raw, y_tr_lbl)):\n",
    "        print(f\"\\n── Fold {fold+1}/{KFOLDS}\")\n",
    "        # datos fold\n",
    "        Xtr_r, Xtr_f = X_tr_raw[idx_train], F_tr[idx_train]\n",
    "        Xvl_r, Xvl_f = X_tr_raw[idx_val],   F_tr[idx_val]\n",
    "        ytr,  yvl    = y_tr[idx_train],     y_tr[idx_val]\n",
    "\n",
    "        # datasets tf.data\n",
    "        if uses_feat:\n",
    "            ds_tr = dictify(make_ds((Xtr_r, Xtr_f), ytr, True))\n",
    "            ds_vl = dictify(make_ds((Xvl_r, Xvl_f), yvl))\n",
    "        else:\n",
    "            ds_tr = make_ds(Xtr_r, ytr, True)\n",
    "            ds_vl = make_ds(Xvl_r, yvl)\n",
    "\n",
    "        # construir y entrenar\n",
    "        K.clear_session()\n",
    "        model = builder()\n",
    "        model.fit(ds_tr, validation_data=ds_vl,\n",
    "                  epochs=EPOCHS, callbacks=make_callbacks(model_name, fold),\n",
    "                  verbose=1)\n",
    "\n",
    "        # evaluar fold-val\n",
    "        val_acc = model.evaluate(ds_vl, verbose=0)[1]\n",
    "        fold_val_acc.append(val_acc)\n",
    "\n",
    "        # evaluar en TEST global\n",
    "        test_acc = (model.evaluate({\"raw\":X_te_raw,\"feat\":F_te}, y_te, 0)[1]\n",
    "                    if uses_feat else model.evaluate(X_te_raw, y_te, 0)[1])\n",
    "        fold_test_acc.append(test_acc)\n",
    "\n",
    "    # Estadísticas del modelo\n",
    "    results.append([\n",
    "        model_name,\n",
    "        np.mean(fold_val_acc), np.std(fold_val_acc),\n",
    "        np.mean(fold_test_acc)\n",
    "    ])\n",
    "\n",
    "# ---------- 8. RESUMEN -------------------------------------------------------\n",
    "df = pd.DataFrame(results, columns=[\n",
    "    \"Model\", \"Val_Acc_Mean\", \"Val_Acc_SD\", \"Test_Acc_Mean\"\n",
    "]).sort_values(\"Val_Acc_Mean\", ascending=False)\n",
    "\n",
    "print(\"\\n📊  Cross-validation summary\")\n",
    "print(df.to_string(index=False, float_format=\"%.4f\"))\n",
    "\n",
    "best = df.iloc[0]\n",
    "print(f\"\\n🏆  Mejor modelo según CV: {best.Model} \"\n",
    "      f\"(Val={best.Val_Acc_Mean:.3f}±{best.Val_Acc_SD:.3f}, \"\n",
    "      f\"Test≈{best.Test_Acc_Mean:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5bf440",
   "metadata": {},
   "outputs": [],
   "source": [
    "📊  Cross-validation summary\n",
    "              Model  Val_Acc_Mean  Val_Acc_SD  Test_Acc_Mean\n",
    "  HyT-Net_Propuesto        0.9976      0.0006         0.9976\n",
    "EMGHandNet_Original        0.9974      0.0004         0.9973\n",
    "EMGHandNet_Adaptado        0.9968      0.0004         0.9967\n",
    "   DualStr_Original        0.9963      0.0005         0.9966\n",
    "   DualStr_Adaptado        0.9930      0.0009         0.9926\n",
    "\n",
    "🏆  Mejor modelo según CV: HyT-Net_Propuesto (Val=0.998±0.001, Test≈0.998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d87f7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df_12_05.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
